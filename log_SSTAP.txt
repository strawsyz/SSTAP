train subset video numbers: 966
unlabel unlabeled subset video numbers: 8683
validation subset video numbers: 4728
use 0.09999999999999998 label for training!!!
training batchsize : 8
unlabel_training batchsize : 24
use Semi !!!
training 1 (epoch 0): tem_loss: 1.389, pem class_loss: 0.693, pem reg_loss: 0.041, consistency_loss: 0.00025, consistency_loss_ema: 0.00000, total_loss: 2.490
training 11 (epoch 0): tem_loss: 1.407, pem class_loss: 0.576, pem reg_loss: 0.034, consistency_loss: 0.00013, consistency_loss_ema: 0.00007, total_loss: 2.328
training 21 (epoch 0): tem_loss: 1.381, pem class_loss: 0.540, pem reg_loss: 0.032, consistency_loss: 0.00012, consistency_loss_ema: 0.00009, total_loss: 2.246
training 31 (epoch 0): tem_loss: 1.355, pem class_loss: 0.513, pem reg_loss: 0.031, consistency_loss: 0.00013, consistency_loss_ema: 0.00011, total_loss: 2.178
training 41 (epoch 0): tem_loss: 1.339, pem class_loss: 0.503, pem reg_loss: 0.031, consistency_loss: 0.00017, consistency_loss_ema: 0.00015, total_loss: 2.148
training 51 (epoch 0): tem_loss: 1.328, pem class_loss: 0.480, pem reg_loss: 0.029, consistency_loss: 0.00025, consistency_loss_ema: 0.00022, total_loss: 2.102
training 61 (epoch 0): tem_loss: 1.322, pem class_loss: 0.461, pem reg_loss: 0.028, consistency_loss: 0.00028, consistency_loss_ema: 0.00026, total_loss: 2.064
training 71 (epoch 0): tem_loss: 1.308, pem class_loss: 0.451, pem reg_loss: 0.027, consistency_loss: 0.00029, consistency_loss_ema: 0.00028, total_loss: 2.032
training 81 (epoch 0): tem_loss: 1.302, pem class_loss: 0.448, pem reg_loss: 0.027, consistency_loss: 0.00030, consistency_loss_ema: 0.00028, total_loss: 2.017
training 91 (epoch 0): tem_loss: 1.307, pem class_loss: 0.443, pem reg_loss: 0.026, consistency_loss: 0.00035, consistency_loss_ema: 0.00034, total_loss: 2.012
training 101 (epoch 0): tem_loss: 1.307, pem class_loss: 0.437, pem reg_loss: 0.026, consistency_loss: 0.00038, consistency_loss_ema: 0.00037, total_loss: 2.004
training 111 (epoch 0): tem_loss: 1.300, pem class_loss: 0.436, pem reg_loss: 0.026, consistency_loss: 0.00037, consistency_loss_ema: 0.00037, total_loss: 1.994
[94mBMN training loss(epoch 0): tem_loss: 1.297, pem class_loss: 0.436, pem reg_loss: 0.026, total_loss: 1.990[0m
[94mBMN val loss(epoch 0): tem_loss: 1.255, pem class_loss: 0.380, pem reg_loss: 0.022, total_loss: 1.854[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.252, pem class_loss: 0.394, pem reg_loss: 0.022, total_loss: 1.864[0m
use Semi !!!
training 121 (epoch 1): tem_loss: 1.125, pem class_loss: 0.374, pem reg_loss: 0.023, consistency_loss: 0.00227, consistency_loss_ema: 0.00205, total_loss: 1.732
training 131 (epoch 1): tem_loss: 1.237, pem class_loss: 0.370, pem reg_loss: 0.022, consistency_loss: 0.00204, consistency_loss_ema: 0.00201, total_loss: 1.823
training 141 (epoch 1): tem_loss: 1.194, pem class_loss: 0.400, pem reg_loss: 0.023, consistency_loss: 0.00238, consistency_loss_ema: 0.00244, total_loss: 1.825
training 151 (epoch 1): tem_loss: 1.193, pem class_loss: 0.384, pem reg_loss: 0.022, consistency_loss: 0.00240, consistency_loss_ema: 0.00249, total_loss: 1.796
training 161 (epoch 1): tem_loss: 1.195, pem class_loss: 0.395, pem reg_loss: 0.022, consistency_loss: 0.00259, consistency_loss_ema: 0.00271, total_loss: 1.812
training 171 (epoch 1): tem_loss: 1.204, pem class_loss: 0.391, pem reg_loss: 0.022, consistency_loss: 0.00270, consistency_loss_ema: 0.00277, total_loss: 1.817
training 181 (epoch 1): tem_loss: 1.195, pem class_loss: 0.392, pem reg_loss: 0.022, consistency_loss: 0.00257, consistency_loss_ema: 0.00271, total_loss: 1.809
training 191 (epoch 1): tem_loss: 1.200, pem class_loss: 0.398, pem reg_loss: 0.023, consistency_loss: 0.00263, consistency_loss_ema: 0.00275, total_loss: 1.827
training 201 (epoch 1): tem_loss: 1.201, pem class_loss: 0.406, pem reg_loss: 0.023, consistency_loss: 0.00275, consistency_loss_ema: 0.00286, total_loss: 1.838
training 211 (epoch 1): tem_loss: 1.201, pem class_loss: 0.404, pem reg_loss: 0.023, consistency_loss: 0.00271, consistency_loss_ema: 0.00284, total_loss: 1.835
training 221 (epoch 1): tem_loss: 1.195, pem class_loss: 0.396, pem reg_loss: 0.022, consistency_loss: 0.00279, consistency_loss_ema: 0.00288, total_loss: 1.815
training 231 (epoch 1): tem_loss: 1.193, pem class_loss: 0.391, pem reg_loss: 0.022, consistency_loss: 0.00278, consistency_loss_ema: 0.00289, total_loss: 1.804
[94mBMN training loss(epoch 1): tem_loss: 1.194, pem class_loss: 0.392, pem reg_loss: 0.022, total_loss: 1.807[0m
[94mBMN val loss(epoch 1): tem_loss: 1.211, pem class_loss: 0.373, pem reg_loss: 0.021, total_loss: 1.796[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.210, pem class_loss: 0.371, pem reg_loss: 0.021, total_loss: 1.789[0m
use Semi !!!
training 241 (epoch 2): tem_loss: 1.208, pem class_loss: 0.739, pem reg_loss: 0.043, consistency_loss: 0.01210, consistency_loss_ema: 0.01554, total_loss: 2.382
training 251 (epoch 2): tem_loss: 1.109, pem class_loss: 0.402, pem reg_loss: 0.022, consistency_loss: 0.01205, consistency_loss_ema: 0.01191, total_loss: 1.735
training 261 (epoch 2): tem_loss: 1.113, pem class_loss: 0.388, pem reg_loss: 0.023, consistency_loss: 0.01077, consistency_loss_ema: 0.01030, total_loss: 1.726
training 271 (epoch 2): tem_loss: 1.111, pem class_loss: 0.399, pem reg_loss: 0.023, consistency_loss: 0.01127, consistency_loss_ema: 0.01093, total_loss: 1.742
training 281 (epoch 2): tem_loss: 1.126, pem class_loss: 0.396, pem reg_loss: 0.023, consistency_loss: 0.01226, consistency_loss_ema: 0.01221, total_loss: 1.755
training 291 (epoch 2): tem_loss: 1.139, pem class_loss: 0.394, pem reg_loss: 0.023, consistency_loss: 0.01201, consistency_loss_ema: 0.01205, total_loss: 1.758
training 301 (epoch 2): tem_loss: 1.145, pem class_loss: 0.388, pem reg_loss: 0.022, consistency_loss: 0.01181, consistency_loss_ema: 0.01200, total_loss: 1.752
training 311 (epoch 2): tem_loss: 1.140, pem class_loss: 0.381, pem reg_loss: 0.021, consistency_loss: 0.01160, consistency_loss_ema: 0.01204, total_loss: 1.735
training 321 (epoch 2): tem_loss: 1.136, pem class_loss: 0.377, pem reg_loss: 0.021, consistency_loss: 0.01140, consistency_loss_ema: 0.01187, total_loss: 1.724
training 331 (epoch 2): tem_loss: 1.141, pem class_loss: 0.374, pem reg_loss: 0.021, consistency_loss: 0.01128, consistency_loss_ema: 0.01171, total_loss: 1.725
training 341 (epoch 2): tem_loss: 1.136, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.01106, consistency_loss_ema: 0.01164, total_loss: 1.709
training 351 (epoch 2): tem_loss: 1.141, pem class_loss: 0.366, pem reg_loss: 0.021, consistency_loss: 0.01107, consistency_loss_ema: 0.01174, total_loss: 1.713
[94mBMN training loss(epoch 2): tem_loss: 1.140, pem class_loss: 0.369, pem reg_loss: 0.021, total_loss: 1.715[0m
[94mBMN val loss(epoch 2): tem_loss: 1.203, pem class_loss: 0.366, pem reg_loss: 0.020, total_loss: 1.771[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.195, pem class_loss: 0.361, pem reg_loss: 0.020, total_loss: 1.756[0m
use Semi !!!
training 361 (epoch 3): tem_loss: 1.195, pem class_loss: 0.459, pem reg_loss: 0.032, consistency_loss: 0.03124, consistency_loss_ema: 0.02197, total_loss: 1.971
training 371 (epoch 3): tem_loss: 1.159, pem class_loss: 0.359, pem reg_loss: 0.021, consistency_loss: 0.02493, consistency_loss_ema: 0.02423, total_loss: 1.723
training 381 (epoch 3): tem_loss: 1.133, pem class_loss: 0.342, pem reg_loss: 0.020, consistency_loss: 0.02280, consistency_loss_ema: 0.02300, total_loss: 1.672
training 391 (epoch 3): tem_loss: 1.119, pem class_loss: 0.354, pem reg_loss: 0.020, consistency_loss: 0.02207, consistency_loss_ema: 0.02248, total_loss: 1.675
training 401 (epoch 3): tem_loss: 1.114, pem class_loss: 0.354, pem reg_loss: 0.020, consistency_loss: 0.02159, consistency_loss_ema: 0.02179, total_loss: 1.669
training 411 (epoch 3): tem_loss: 1.116, pem class_loss: 0.343, pem reg_loss: 0.020, consistency_loss: 0.02180, consistency_loss_ema: 0.02235, total_loss: 1.654
training 421 (epoch 3): tem_loss: 1.114, pem class_loss: 0.344, pem reg_loss: 0.020, consistency_loss: 0.02192, consistency_loss_ema: 0.02264, total_loss: 1.654
training 431 (epoch 3): tem_loss: 1.123, pem class_loss: 0.346, pem reg_loss: 0.020, consistency_loss: 0.02178, consistency_loss_ema: 0.02250, total_loss: 1.668
training 441 (epoch 3): tem_loss: 1.121, pem class_loss: 0.347, pem reg_loss: 0.020, consistency_loss: 0.02116, consistency_loss_ema: 0.02207, total_loss: 1.668
training 451 (epoch 3): tem_loss: 1.110, pem class_loss: 0.341, pem reg_loss: 0.020, consistency_loss: 0.02161, consistency_loss_ema: 0.02221, total_loss: 1.649
training 461 (epoch 3): tem_loss: 1.110, pem class_loss: 0.344, pem reg_loss: 0.020, consistency_loss: 0.02196, consistency_loss_ema: 0.02230, total_loss: 1.653
training 471 (epoch 3): tem_loss: 1.110, pem class_loss: 0.343, pem reg_loss: 0.020, consistency_loss: 0.02237, consistency_loss_ema: 0.02274, total_loss: 1.650
[94mBMN training loss(epoch 3): tem_loss: 1.115, pem class_loss: 0.348, pem reg_loss: 0.020, total_loss: 1.662[0m
[94mBMN val loss(epoch 3): tem_loss: 1.192, pem class_loss: 0.379, pem reg_loss: 0.021, total_loss: 1.778[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.190, pem class_loss: 0.360, pem reg_loss: 0.020, total_loss: 1.750[0m
use Semi !!!
training 481 (epoch 4): tem_loss: 1.194, pem class_loss: 0.343, pem reg_loss: 0.017, consistency_loss: 0.03459, consistency_loss_ema: 0.04356, total_loss: 1.703
training 491 (epoch 4): tem_loss: 1.077, pem class_loss: 0.305, pem reg_loss: 0.018, consistency_loss: 0.03743, consistency_loss_ema: 0.03861, total_loss: 1.561
training 501 (epoch 4): tem_loss: 1.062, pem class_loss: 0.313, pem reg_loss: 0.018, consistency_loss: 0.03573, consistency_loss_ema: 0.03636, total_loss: 1.555
training 511 (epoch 4): tem_loss: 1.062, pem class_loss: 0.304, pem reg_loss: 0.018, consistency_loss: 0.03591, consistency_loss_ema: 0.03703, total_loss: 1.542
training 521 (epoch 4): tem_loss: 1.078, pem class_loss: 0.322, pem reg_loss: 0.018, consistency_loss: 0.03565, consistency_loss_ema: 0.03733, total_loss: 1.581
training 531 (epoch 4): tem_loss: 1.073, pem class_loss: 0.332, pem reg_loss: 0.019, consistency_loss: 0.03505, consistency_loss_ema: 0.03703, total_loss: 1.593
training 541 (epoch 4): tem_loss: 1.079, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.03506, consistency_loss_ema: 0.03681, total_loss: 1.605
training 551 (epoch 4): tem_loss: 1.087, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.03429, consistency_loss_ema: 0.03590, total_loss: 1.614
training 561 (epoch 4): tem_loss: 1.087, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.03398, consistency_loss_ema: 0.03563, total_loss: 1.616
training 571 (epoch 4): tem_loss: 1.088, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.03387, consistency_loss_ema: 0.03536, total_loss: 1.615
training 581 (epoch 4): tem_loss: 1.098, pem class_loss: 0.333, pem reg_loss: 0.019, consistency_loss: 0.03434, consistency_loss_ema: 0.03552, total_loss: 1.620
training 591 (epoch 4): tem_loss: 1.100, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.03476, consistency_loss_ema: 0.03563, total_loss: 1.625
[94mBMN training loss(epoch 4): tem_loss: 1.097, pem class_loss: 0.335, pem reg_loss: 0.019, total_loss: 1.620[0m
[94mBMN val loss(epoch 4): tem_loss: 1.193, pem class_loss: 0.361, pem reg_loss: 0.020, total_loss: 1.749[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.195, pem class_loss: 0.358, pem reg_loss: 0.020, total_loss: 1.752[0m
use Semi !!!
training 601 (epoch 5): tem_loss: 1.048, pem class_loss: 0.289, pem reg_loss: 0.013, consistency_loss: 0.03908, consistency_loss_ema: 0.04374, total_loss: 1.470
training 611 (epoch 5): tem_loss: 1.063, pem class_loss: 0.325, pem reg_loss: 0.019, consistency_loss: 0.04042, consistency_loss_ema: 0.03862, total_loss: 1.577
training 621 (epoch 5): tem_loss: 1.093, pem class_loss: 0.325, pem reg_loss: 0.019, consistency_loss: 0.03912, consistency_loss_ema: 0.03854, total_loss: 1.605
training 631 (epoch 5): tem_loss: 1.092, pem class_loss: 0.312, pem reg_loss: 0.018, consistency_loss: 0.03828, consistency_loss_ema: 0.03817, total_loss: 1.588
training 641 (epoch 5): tem_loss: 1.093, pem class_loss: 0.310, pem reg_loss: 0.018, consistency_loss: 0.03904, consistency_loss_ema: 0.03778, total_loss: 1.585
training 651 (epoch 5): tem_loss: 1.090, pem class_loss: 0.308, pem reg_loss: 0.018, consistency_loss: 0.03831, consistency_loss_ema: 0.03743, total_loss: 1.576
training 661 (epoch 5): tem_loss: 1.091, pem class_loss: 0.312, pem reg_loss: 0.018, consistency_loss: 0.03765, consistency_loss_ema: 0.03749, total_loss: 1.584
training 671 (epoch 5): tem_loss: 1.089, pem class_loss: 0.311, pem reg_loss: 0.018, consistency_loss: 0.03724, consistency_loss_ema: 0.03784, total_loss: 1.582
training 681 (epoch 5): tem_loss: 1.090, pem class_loss: 0.317, pem reg_loss: 0.018, consistency_loss: 0.03691, consistency_loss_ema: 0.03811, total_loss: 1.590
training 691 (epoch 5): tem_loss: 1.089, pem class_loss: 0.319, pem reg_loss: 0.018, consistency_loss: 0.03711, consistency_loss_ema: 0.03824, total_loss: 1.589
training 701 (epoch 5): tem_loss: 1.089, pem class_loss: 0.322, pem reg_loss: 0.018, consistency_loss: 0.03703, consistency_loss_ema: 0.03856, total_loss: 1.595
training 711 (epoch 5): tem_loss: 1.093, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.03723, consistency_loss_ema: 0.03869, total_loss: 1.595
[94mBMN training loss(epoch 5): tem_loss: 1.092, pem class_loss: 0.319, pem reg_loss: 0.018, total_loss: 1.593[0m
[94mBMN val loss(epoch 5): tem_loss: 1.198, pem class_loss: 0.370, pem reg_loss: 0.020, total_loss: 1.766[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.199, pem class_loss: 0.358, pem reg_loss: 0.020, total_loss: 1.752[0m
use Semi !!!
training 721 (epoch 6): tem_loss: 1.104, pem class_loss: 0.397, pem reg_loss: 0.019, consistency_loss: 0.04701, consistency_loss_ema: 0.05393, total_loss: 1.686
training 731 (epoch 6): tem_loss: 1.068, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.03672, consistency_loss_ema: 0.03947, total_loss: 1.555
training 741 (epoch 6): tem_loss: 1.062, pem class_loss: 0.289, pem reg_loss: 0.016, consistency_loss: 0.03660, consistency_loss_ema: 0.04031, total_loss: 1.512
training 751 (epoch 6): tem_loss: 1.070, pem class_loss: 0.300, pem reg_loss: 0.017, consistency_loss: 0.03650, consistency_loss_ema: 0.03967, total_loss: 1.537
training 761 (epoch 6): tem_loss: 1.057, pem class_loss: 0.306, pem reg_loss: 0.017, consistency_loss: 0.03698, consistency_loss_ema: 0.03963, total_loss: 1.535
training 771 (epoch 6): tem_loss: 1.057, pem class_loss: 0.310, pem reg_loss: 0.018, consistency_loss: 0.03707, consistency_loss_ema: 0.03917, total_loss: 1.546
training 781 (epoch 6): tem_loss: 1.056, pem class_loss: 0.310, pem reg_loss: 0.018, consistency_loss: 0.03697, consistency_loss_ema: 0.03855, total_loss: 1.544
training 791 (epoch 6): tem_loss: 1.050, pem class_loss: 0.308, pem reg_loss: 0.018, consistency_loss: 0.03656, consistency_loss_ema: 0.03867, total_loss: 1.535
training 801 (epoch 6): tem_loss: 1.055, pem class_loss: 0.310, pem reg_loss: 0.018, consistency_loss: 0.03726, consistency_loss_ema: 0.03955, total_loss: 1.543
training 811 (epoch 6): tem_loss: 1.056, pem class_loss: 0.306, pem reg_loss: 0.018, consistency_loss: 0.03763, consistency_loss_ema: 0.03976, total_loss: 1.537
training 821 (epoch 6): tem_loss: 1.060, pem class_loss: 0.305, pem reg_loss: 0.018, consistency_loss: 0.03739, consistency_loss_ema: 0.03944, total_loss: 1.542
training 831 (epoch 6): tem_loss: 1.065, pem class_loss: 0.303, pem reg_loss: 0.017, consistency_loss: 0.03682, consistency_loss_ema: 0.03963, total_loss: 1.543
[94mBMN training loss(epoch 6): tem_loss: 1.073, pem class_loss: 0.305, pem reg_loss: 0.017, total_loss: 1.552[0m
[94mBMN val loss(epoch 6): tem_loss: 1.203, pem class_loss: 0.356, pem reg_loss: 0.019, total_loss: 1.751[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.197, pem class_loss: 0.363, pem reg_loss: 0.019, total_loss: 1.755[0m
use Semi !!!
training 841 (epoch 7): tem_loss: 1.049, pem class_loss: 0.281, pem reg_loss: 0.019, consistency_loss: 0.07491, consistency_loss_ema: 0.05149, total_loss: 1.521
training 851 (epoch 7): tem_loss: 1.030, pem class_loss: 0.257, pem reg_loss: 0.015, consistency_loss: 0.04571, consistency_loss_ema: 0.04046, total_loss: 1.437
training 861 (epoch 7): tem_loss: 1.043, pem class_loss: 0.289, pem reg_loss: 0.017, consistency_loss: 0.03864, consistency_loss_ema: 0.03738, total_loss: 1.499
training 871 (epoch 7): tem_loss: 1.038, pem class_loss: 0.281, pem reg_loss: 0.016, consistency_loss: 0.03474, consistency_loss_ema: 0.03410, total_loss: 1.480
training 881 (epoch 7): tem_loss: 1.032, pem class_loss: 0.286, pem reg_loss: 0.016, consistency_loss: 0.03291, consistency_loss_ema: 0.03213, total_loss: 1.482
training 891 (epoch 7): tem_loss: 1.032, pem class_loss: 0.286, pem reg_loss: 0.016, consistency_loss: 0.03073, consistency_loss_ema: 0.03115, total_loss: 1.480
training 901 (epoch 7): tem_loss: 1.032, pem class_loss: 0.282, pem reg_loss: 0.016, consistency_loss: 0.03015, consistency_loss_ema: 0.03041, total_loss: 1.474
training 911 (epoch 7): tem_loss: 1.035, pem class_loss: 0.280, pem reg_loss: 0.016, consistency_loss: 0.02970, consistency_loss_ema: 0.02997, total_loss: 1.477
training 921 (epoch 7): tem_loss: 1.039, pem class_loss: 0.275, pem reg_loss: 0.016, consistency_loss: 0.02900, consistency_loss_ema: 0.02968, total_loss: 1.475
training 931 (epoch 7): tem_loss: 1.037, pem class_loss: 0.273, pem reg_loss: 0.016, consistency_loss: 0.02870, consistency_loss_ema: 0.02970, total_loss: 1.469
training 941 (epoch 7): tem_loss: 1.034, pem class_loss: 0.269, pem reg_loss: 0.016, consistency_loss: 0.02845, consistency_loss_ema: 0.02957, total_loss: 1.461
training 951 (epoch 7): tem_loss: 1.036, pem class_loss: 0.271, pem reg_loss: 0.016, consistency_loss: 0.02793, consistency_loss_ema: 0.02939, total_loss: 1.465
[94mBMN training loss(epoch 7): tem_loss: 1.036, pem class_loss: 0.273, pem reg_loss: 0.016, total_loss: 1.467[0m
[94mBMN val loss(epoch 7): tem_loss: 1.197, pem class_loss: 0.371, pem reg_loss: 0.019, total_loss: 1.762[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.199, pem class_loss: 0.366, pem reg_loss: 0.019, total_loss: 1.756[0m
use Semi !!!
training 961 (epoch 8): tem_loss: 0.972, pem class_loss: 0.242, pem reg_loss: 0.014, consistency_loss: 0.02581, consistency_loss_ema: 0.02944, total_loss: 1.350
training 971 (epoch 8): tem_loss: 0.995, pem class_loss: 0.240, pem reg_loss: 0.016, consistency_loss: 0.02441, consistency_loss_ema: 0.02783, total_loss: 1.396
training 981 (epoch 8): tem_loss: 1.023, pem class_loss: 0.256, pem reg_loss: 0.016, consistency_loss: 0.02420, consistency_loss_ema: 0.02768, total_loss: 1.438
training 991 (epoch 8): tem_loss: 1.000, pem class_loss: 0.251, pem reg_loss: 0.016, consistency_loss: 0.02585, consistency_loss_ema: 0.02850, total_loss: 1.406
training 1001 (epoch 8): tem_loss: 0.996, pem class_loss: 0.250, pem reg_loss: 0.015, consistency_loss: 0.02580, consistency_loss_ema: 0.02892, total_loss: 1.400
training 1011 (epoch 8): tem_loss: 0.991, pem class_loss: 0.255, pem reg_loss: 0.015, consistency_loss: 0.02594, consistency_loss_ema: 0.02944, total_loss: 1.400
training 1021 (epoch 8): tem_loss: 0.998, pem class_loss: 0.254, pem reg_loss: 0.015, consistency_loss: 0.02636, consistency_loss_ema: 0.02978, total_loss: 1.405
training 1031 (epoch 8): tem_loss: 1.000, pem class_loss: 0.250, pem reg_loss: 0.015, consistency_loss: 0.02686, consistency_loss_ema: 0.02984, total_loss: 1.400
training 1041 (epoch 8): tem_loss: 1.003, pem class_loss: 0.256, pem reg_loss: 0.015, consistency_loss: 0.02715, consistency_loss_ema: 0.02981, total_loss: 1.412
training 1051 (epoch 8): tem_loss: 1.008, pem class_loss: 0.259, pem reg_loss: 0.015, consistency_loss: 0.02781, consistency_loss_ema: 0.02971, total_loss: 1.418
training 1061 (epoch 8): tem_loss: 1.012, pem class_loss: 0.260, pem reg_loss: 0.015, consistency_loss: 0.02778, consistency_loss_ema: 0.02979, total_loss: 1.423
training 1071 (epoch 8): tem_loss: 1.013, pem class_loss: 0.263, pem reg_loss: 0.015, consistency_loss: 0.02785, consistency_loss_ema: 0.02988, total_loss: 1.431
[94mBMN training loss(epoch 8): tem_loss: 1.016, pem class_loss: 0.264, pem reg_loss: 0.015, total_loss: 1.434[0m
[94mBMN val loss(epoch 8): tem_loss: 1.198, pem class_loss: 0.380, pem reg_loss: 0.019, total_loss: 1.770[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.198, pem class_loss: 0.379, pem reg_loss: 0.019, total_loss: 1.768[0m
use Semi !!!
training 1081 (epoch 9): tem_loss: 0.932, pem class_loss: 0.195, pem reg_loss: 0.010, consistency_loss: 0.03730, consistency_loss_ema: 0.03202, total_loss: 1.222
training 1091 (epoch 9): tem_loss: 0.983, pem class_loss: 0.255, pem reg_loss: 0.015, consistency_loss: 0.02991, consistency_loss_ema: 0.03024, total_loss: 1.388
training 1101 (epoch 9): tem_loss: 1.006, pem class_loss: 0.268, pem reg_loss: 0.016, consistency_loss: 0.02917, consistency_loss_ema: 0.03073, total_loss: 1.439
training 1111 (epoch 9): tem_loss: 0.999, pem class_loss: 0.258, pem reg_loss: 0.017, consistency_loss: 0.02986, consistency_loss_ema: 0.03122, total_loss: 1.423
training 1121 (epoch 9): tem_loss: 0.995, pem class_loss: 0.258, pem reg_loss: 0.016, consistency_loss: 0.02993, consistency_loss_ema: 0.03120, total_loss: 1.417
training 1131 (epoch 9): tem_loss: 1.001, pem class_loss: 0.255, pem reg_loss: 0.016, consistency_loss: 0.02995, consistency_loss_ema: 0.03135, total_loss: 1.412
training 1141 (epoch 9): tem_loss: 1.005, pem class_loss: 0.259, pem reg_loss: 0.016, consistency_loss: 0.02993, consistency_loss_ema: 0.03191, total_loss: 1.420
training 1151 (epoch 9): tem_loss: 0.998, pem class_loss: 0.256, pem reg_loss: 0.015, consistency_loss: 0.02994, consistency_loss_ema: 0.03174, total_loss: 1.408
training 1161 (epoch 9): tem_loss: 1.002, pem class_loss: 0.256, pem reg_loss: 0.015, consistency_loss: 0.03006, consistency_loss_ema: 0.03185, total_loss: 1.411
training 1171 (epoch 9): tem_loss: 1.002, pem class_loss: 0.254, pem reg_loss: 0.015, consistency_loss: 0.03020, consistency_loss_ema: 0.03192, total_loss: 1.409
training 1181 (epoch 9): tem_loss: 1.003, pem class_loss: 0.253, pem reg_loss: 0.015, consistency_loss: 0.03020, consistency_loss_ema: 0.03195, total_loss: 1.408
training 1191 (epoch 9): tem_loss: 1.004, pem class_loss: 0.252, pem reg_loss: 0.015, consistency_loss: 0.03043, consistency_loss_ema: 0.03226, total_loss: 1.407
[94mBMN training loss(epoch 9): tem_loss: 1.004, pem class_loss: 0.252, pem reg_loss: 0.015, total_loss: 1.406[0m
[94mBMN val loss(epoch 9): tem_loss: 1.200, pem class_loss: 0.398, pem reg_loss: 0.019, total_loss: 1.790[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.200, pem class_loss: 0.391, pem reg_loss: 0.019, total_loss: 1.782[0m
unlabel percent:  0.9
eval student model !!
load : ./checkpoint/Semi-base-0.9/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472775
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 65.1337583984643%
AR@1 is 	 0.32665569724393256
AR@5 is 	 0.46319758672699846
AR@10 is 	 0.5390648567119156
AR@100 is 	 0.7337035513506103
eval teacher model !!
load : ./checkpoint/Semi-base-0.9/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472615
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 64.91984779925957%
AR@1 is 	 0.3252982311805841
AR@5 is 	 0.4589469354175236
AR@10 is 	 0.5341011929247222
AR@100 is 	 0.7323872206225148
#
train subset video numbers: 1925
unlabel unlabeled subset video numbers: 7724
validation subset video numbers: 4728
use 0.19999999999999996 label for training!!!
training batchsize : 8
unlabel_training batchsize : 24
use Semi !!!
training 1 (epoch 0): tem_loss: 1.379, pem class_loss: 0.693, pem reg_loss: 0.039, consistency_loss: 0.00064, consistency_loss_ema: 0.00000, total_loss: 2.462
training 11 (epoch 0): tem_loss: 1.370, pem class_loss: 0.843, pem reg_loss: 0.054, consistency_loss: 0.00019, consistency_loss_ema: 0.00004, total_loss: 2.755
training 21 (epoch 0): tem_loss: 1.353, pem class_loss: 0.715, pem reg_loss: 0.044, consistency_loss: 0.00015, consistency_loss_ema: 0.00008, total_loss: 2.512
training 31 (epoch 0): tem_loss: 1.358, pem class_loss: 0.654, pem reg_loss: 0.040, consistency_loss: 0.00017, consistency_loss_ema: 0.00013, total_loss: 2.415
training 41 (epoch 0): tem_loss: 1.349, pem class_loss: 0.596, pem reg_loss: 0.037, consistency_loss: 0.00017, consistency_loss_ema: 0.00015, total_loss: 2.310
training 51 (epoch 0): tem_loss: 1.342, pem class_loss: 0.572, pem reg_loss: 0.035, consistency_loss: 0.00017, consistency_loss_ema: 0.00015, total_loss: 2.262
training 61 (epoch 0): tem_loss: 1.335, pem class_loss: 0.536, pem reg_loss: 0.033, consistency_loss: 0.00019, consistency_loss_ema: 0.00017, total_loss: 2.198
training 71 (epoch 0): tem_loss: 1.328, pem class_loss: 0.512, pem reg_loss: 0.031, consistency_loss: 0.00024, consistency_loss_ema: 0.00023, total_loss: 2.152
training 81 (epoch 0): tem_loss: 1.325, pem class_loss: 0.501, pem reg_loss: 0.030, consistency_loss: 0.00026, consistency_loss_ema: 0.00025, total_loss: 2.130
training 91 (epoch 0): tem_loss: 1.319, pem class_loss: 0.492, pem reg_loss: 0.029, consistency_loss: 0.00027, consistency_loss_ema: 0.00026, total_loss: 2.105
training 101 (epoch 0): tem_loss: 1.309, pem class_loss: 0.481, pem reg_loss: 0.029, consistency_loss: 0.00028, consistency_loss_ema: 0.00027, total_loss: 2.077
training 111 (epoch 0): tem_loss: 1.302, pem class_loss: 0.476, pem reg_loss: 0.028, consistency_loss: 0.00028, consistency_loss_ema: 0.00028, total_loss: 2.063
training 121 (epoch 0): tem_loss: 1.296, pem class_loss: 0.471, pem reg_loss: 0.028, consistency_loss: 0.00030, consistency_loss_ema: 0.00029, total_loss: 2.047
training 131 (epoch 0): tem_loss: 1.294, pem class_loss: 0.469, pem reg_loss: 0.028, consistency_loss: 0.00031, consistency_loss_ema: 0.00031, total_loss: 2.041
training 141 (epoch 0): tem_loss: 1.292, pem class_loss: 0.461, pem reg_loss: 0.027, consistency_loss: 0.00033, consistency_loss_ema: 0.00032, total_loss: 2.024
training 151 (epoch 0): tem_loss: 1.288, pem class_loss: 0.457, pem reg_loss: 0.027, consistency_loss: 0.00033, consistency_loss_ema: 0.00032, total_loss: 2.014
training 161 (epoch 0): tem_loss: 1.285, pem class_loss: 0.455, pem reg_loss: 0.026, consistency_loss: 0.00033, consistency_loss_ema: 0.00032, total_loss: 2.004
training 171 (epoch 0): tem_loss: 1.284, pem class_loss: 0.450, pem reg_loss: 0.026, consistency_loss: 0.00033, consistency_loss_ema: 0.00033, total_loss: 1.995
training 181 (epoch 0): tem_loss: 1.283, pem class_loss: 0.448, pem reg_loss: 0.026, consistency_loss: 0.00034, consistency_loss_ema: 0.00033, total_loss: 1.990
training 191 (epoch 0): tem_loss: 1.280, pem class_loss: 0.447, pem reg_loss: 0.026, consistency_loss: 0.00034, consistency_loss_ema: 0.00033, total_loss: 1.985
training 201 (epoch 0): tem_loss: 1.278, pem class_loss: 0.445, pem reg_loss: 0.026, consistency_loss: 0.00034, consistency_loss_ema: 0.00033, total_loss: 1.979
training 211 (epoch 0): tem_loss: 1.274, pem class_loss: 0.442, pem reg_loss: 0.025, consistency_loss: 0.00035, consistency_loss_ema: 0.00034, total_loss: 1.968
training 221 (epoch 0): tem_loss: 1.270, pem class_loss: 0.438, pem reg_loss: 0.025, consistency_loss: 0.00035, consistency_loss_ema: 0.00034, total_loss: 1.960
training 231 (epoch 0): tem_loss: 1.266, pem class_loss: 0.437, pem reg_loss: 0.025, consistency_loss: 0.00036, consistency_loss_ema: 0.00035, total_loss: 1.953
[94mBMN training loss(epoch 0): tem_loss: 1.263, pem class_loss: 0.436, pem reg_loss: 0.025, total_loss: 1.949[0m
[94mBMN val loss(epoch 0): tem_loss: 1.211, pem class_loss: 0.392, pem reg_loss: 0.022, total_loss: 1.822[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.199, pem class_loss: 0.383, pem reg_loss: 0.021, total_loss: 1.787[0m
use Semi !!!
training 241 (epoch 1): tem_loss: 1.212, pem class_loss: 0.375, pem reg_loss: 0.020, consistency_loss: 0.00346, consistency_loss_ema: 0.00342, total_loss: 1.786
training 251 (epoch 1): tem_loss: 1.236, pem class_loss: 0.402, pem reg_loss: 0.023, consistency_loss: 0.00430, consistency_loss_ema: 0.00402, total_loss: 1.866
training 261 (epoch 1): tem_loss: 1.184, pem class_loss: 0.390, pem reg_loss: 0.022, consistency_loss: 0.00369, consistency_loss_ema: 0.00366, total_loss: 1.791
training 271 (epoch 1): tem_loss: 1.170, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00349, consistency_loss_ema: 0.00350, total_loss: 1.769
training 281 (epoch 1): tem_loss: 1.175, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00337, consistency_loss_ema: 0.00340, total_loss: 1.760
training 291 (epoch 1): tem_loss: 1.187, pem class_loss: 0.378, pem reg_loss: 0.021, consistency_loss: 0.00327, consistency_loss_ema: 0.00331, total_loss: 1.778
training 301 (epoch 1): tem_loss: 1.189, pem class_loss: 0.374, pem reg_loss: 0.021, consistency_loss: 0.00329, consistency_loss_ema: 0.00335, total_loss: 1.774
training 311 (epoch 1): tem_loss: 1.195, pem class_loss: 0.381, pem reg_loss: 0.021, consistency_loss: 0.00322, consistency_loss_ema: 0.00330, total_loss: 1.789
training 321 (epoch 1): tem_loss: 1.194, pem class_loss: 0.393, pem reg_loss: 0.022, consistency_loss: 0.00314, consistency_loss_ema: 0.00324, total_loss: 1.808
training 331 (epoch 1): tem_loss: 1.196, pem class_loss: 0.391, pem reg_loss: 0.022, consistency_loss: 0.00315, consistency_loss_ema: 0.00321, total_loss: 1.807
training 341 (epoch 1): tem_loss: 1.191, pem class_loss: 0.388, pem reg_loss: 0.022, consistency_loss: 0.00310, consistency_loss_ema: 0.00321, total_loss: 1.795
training 351 (epoch 1): tem_loss: 1.189, pem class_loss: 0.385, pem reg_loss: 0.022, consistency_loss: 0.00308, consistency_loss_ema: 0.00319, total_loss: 1.790
training 361 (epoch 1): tem_loss: 1.181, pem class_loss: 0.379, pem reg_loss: 0.021, consistency_loss: 0.00323, consistency_loss_ema: 0.00331, total_loss: 1.773
training 371 (epoch 1): tem_loss: 1.179, pem class_loss: 0.381, pem reg_loss: 0.021, consistency_loss: 0.00323, consistency_loss_ema: 0.00330, total_loss: 1.773
training 381 (epoch 1): tem_loss: 1.174, pem class_loss: 0.378, pem reg_loss: 0.021, consistency_loss: 0.00332, consistency_loss_ema: 0.00335, total_loss: 1.762
training 391 (epoch 1): tem_loss: 1.178, pem class_loss: 0.377, pem reg_loss: 0.021, consistency_loss: 0.00332, consistency_loss_ema: 0.00335, total_loss: 1.765
training 401 (epoch 1): tem_loss: 1.179, pem class_loss: 0.377, pem reg_loss: 0.021, consistency_loss: 0.00329, consistency_loss_ema: 0.00333, total_loss: 1.764
training 411 (epoch 1): tem_loss: 1.183, pem class_loss: 0.380, pem reg_loss: 0.021, consistency_loss: 0.00333, consistency_loss_ema: 0.00339, total_loss: 1.773
training 421 (epoch 1): tem_loss: 1.181, pem class_loss: 0.383, pem reg_loss: 0.021, consistency_loss: 0.00334, consistency_loss_ema: 0.00341, total_loss: 1.775
training 431 (epoch 1): tem_loss: 1.181, pem class_loss: 0.383, pem reg_loss: 0.021, consistency_loss: 0.00335, consistency_loss_ema: 0.00341, total_loss: 1.775
training 441 (epoch 1): tem_loss: 1.182, pem class_loss: 0.385, pem reg_loss: 0.021, consistency_loss: 0.00332, consistency_loss_ema: 0.00339, total_loss: 1.781
training 451 (epoch 1): tem_loss: 1.182, pem class_loss: 0.384, pem reg_loss: 0.021, consistency_loss: 0.00331, consistency_loss_ema: 0.00339, total_loss: 1.780
training 461 (epoch 1): tem_loss: 1.182, pem class_loss: 0.385, pem reg_loss: 0.021, consistency_loss: 0.00328, consistency_loss_ema: 0.00336, total_loss: 1.780
training 471 (epoch 1): tem_loss: 1.181, pem class_loss: 0.383, pem reg_loss: 0.021, consistency_loss: 0.00325, consistency_loss_ema: 0.00333, total_loss: 1.775
[94mBMN training loss(epoch 1): tem_loss: 1.179, pem class_loss: 0.382, pem reg_loss: 0.021, total_loss: 1.772[0m
[94mBMN val loss(epoch 1): tem_loss: 1.186, pem class_loss: 0.359, pem reg_loss: 0.020, total_loss: 1.744[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.179, pem class_loss: 0.361, pem reg_loss: 0.020, total_loss: 1.737[0m
use Semi !!!
training 481 (epoch 2): tem_loss: 1.118, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.01001, consistency_loss_ema: 0.00827, total_loss: 1.608
training 491 (epoch 2): tem_loss: 1.080, pem class_loss: 0.291, pem reg_loss: 0.016, consistency_loss: 0.01107, consistency_loss_ema: 0.01140, total_loss: 1.534
training 501 (epoch 2): tem_loss: 1.117, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00975, consistency_loss_ema: 0.01033, total_loss: 1.632
training 511 (epoch 2): tem_loss: 1.123, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00888, consistency_loss_ema: 0.00930, total_loss: 1.662
training 521 (epoch 2): tem_loss: 1.144, pem class_loss: 0.360, pem reg_loss: 0.020, consistency_loss: 0.00908, consistency_loss_ema: 0.01031, total_loss: 1.706
training 531 (epoch 2): tem_loss: 1.141, pem class_loss: 0.355, pem reg_loss: 0.020, consistency_loss: 0.00974, consistency_loss_ema: 0.01062, total_loss: 1.692
training 541 (epoch 2): tem_loss: 1.141, pem class_loss: 0.364, pem reg_loss: 0.020, consistency_loss: 0.00973, consistency_loss_ema: 0.01048, total_loss: 1.702
training 551 (epoch 2): tem_loss: 1.138, pem class_loss: 0.363, pem reg_loss: 0.020, consistency_loss: 0.00968, consistency_loss_ema: 0.01041, total_loss: 1.700
training 561 (epoch 2): tem_loss: 1.139, pem class_loss: 0.361, pem reg_loss: 0.020, consistency_loss: 0.01000, consistency_loss_ema: 0.01056, total_loss: 1.698
training 571 (epoch 2): tem_loss: 1.140, pem class_loss: 0.359, pem reg_loss: 0.020, consistency_loss: 0.00999, consistency_loss_ema: 0.01043, total_loss: 1.698
training 581 (epoch 2): tem_loss: 1.138, pem class_loss: 0.358, pem reg_loss: 0.020, consistency_loss: 0.01006, consistency_loss_ema: 0.01033, total_loss: 1.694
training 591 (epoch 2): tem_loss: 1.137, pem class_loss: 0.360, pem reg_loss: 0.020, consistency_loss: 0.01001, consistency_loss_ema: 0.01026, total_loss: 1.695
training 601 (epoch 2): tem_loss: 1.140, pem class_loss: 0.362, pem reg_loss: 0.020, consistency_loss: 0.01023, consistency_loss_ema: 0.01045, total_loss: 1.702
training 611 (epoch 2): tem_loss: 1.140, pem class_loss: 0.366, pem reg_loss: 0.020, consistency_loss: 0.01052, consistency_loss_ema: 0.01063, total_loss: 1.708
training 621 (epoch 2): tem_loss: 1.138, pem class_loss: 0.364, pem reg_loss: 0.020, consistency_loss: 0.01066, consistency_loss_ema: 0.01061, total_loss: 1.705
training 631 (epoch 2): tem_loss: 1.141, pem class_loss: 0.362, pem reg_loss: 0.020, consistency_loss: 0.01065, consistency_loss_ema: 0.01062, total_loss: 1.704
training 641 (epoch 2): tem_loss: 1.144, pem class_loss: 0.364, pem reg_loss: 0.020, consistency_loss: 0.01056, consistency_loss_ema: 0.01056, total_loss: 1.710
training 651 (epoch 2): tem_loss: 1.143, pem class_loss: 0.363, pem reg_loss: 0.020, consistency_loss: 0.01042, consistency_loss_ema: 0.01043, total_loss: 1.708
training 661 (epoch 2): tem_loss: 1.143, pem class_loss: 0.366, pem reg_loss: 0.020, consistency_loss: 0.01035, consistency_loss_ema: 0.01043, total_loss: 1.712
training 671 (epoch 2): tem_loss: 1.142, pem class_loss: 0.366, pem reg_loss: 0.020, consistency_loss: 0.01044, consistency_loss_ema: 0.01048, total_loss: 1.711
training 681 (epoch 2): tem_loss: 1.143, pem class_loss: 0.366, pem reg_loss: 0.020, consistency_loss: 0.01038, consistency_loss_ema: 0.01053, total_loss: 1.711
training 691 (epoch 2): tem_loss: 1.144, pem class_loss: 0.367, pem reg_loss: 0.020, consistency_loss: 0.01037, consistency_loss_ema: 0.01049, total_loss: 1.712
training 701 (epoch 2): tem_loss: 1.142, pem class_loss: 0.365, pem reg_loss: 0.020, consistency_loss: 0.01046, consistency_loss_ema: 0.01056, total_loss: 1.709
training 711 (epoch 2): tem_loss: 1.142, pem class_loss: 0.364, pem reg_loss: 0.020, consistency_loss: 0.01047, consistency_loss_ema: 0.01055, total_loss: 1.706
[94mBMN training loss(epoch 2): tem_loss: 1.141, pem class_loss: 0.362, pem reg_loss: 0.020, total_loss: 1.703[0m
[94mBMN val loss(epoch 2): tem_loss: 1.174, pem class_loss: 0.358, pem reg_loss: 0.020, total_loss: 1.730[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.167, pem class_loss: 0.351, pem reg_loss: 0.019, total_loss: 1.709[0m
use Semi !!!
training 721 (epoch 3): tem_loss: 1.203, pem class_loss: 0.294, pem reg_loss: 0.020, consistency_loss: 0.02527, consistency_loss_ema: 0.02820, total_loss: 1.702
training 731 (epoch 3): tem_loss: 1.053, pem class_loss: 0.321, pem reg_loss: 0.018, consistency_loss: 0.02152, consistency_loss_ema: 0.02362, total_loss: 1.553
training 741 (epoch 3): tem_loss: 1.072, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.02003, consistency_loss_ema: 0.02214, total_loss: 1.587
training 751 (epoch 3): tem_loss: 1.074, pem class_loss: 0.325, pem reg_loss: 0.018, consistency_loss: 0.02028, consistency_loss_ema: 0.02171, total_loss: 1.574
training 761 (epoch 3): tem_loss: 1.087, pem class_loss: 0.329, pem reg_loss: 0.017, consistency_loss: 0.01988, consistency_loss_ema: 0.02126, total_loss: 1.590
training 771 (epoch 3): tem_loss: 1.094, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.01989, consistency_loss_ema: 0.02125, total_loss: 1.604
training 781 (epoch 3): tem_loss: 1.096, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.02077, consistency_loss_ema: 0.02171, total_loss: 1.612
training 791 (epoch 3): tem_loss: 1.092, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.02141, consistency_loss_ema: 0.02210, total_loss: 1.598
training 801 (epoch 3): tem_loss: 1.100, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.02168, consistency_loss_ema: 0.02217, total_loss: 1.613
training 811 (epoch 3): tem_loss: 1.104, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.02144, consistency_loss_ema: 0.02180, total_loss: 1.625
training 821 (epoch 3): tem_loss: 1.109, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.02096, consistency_loss_ema: 0.02141, total_loss: 1.631
training 831 (epoch 3): tem_loss: 1.107, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.02059, consistency_loss_ema: 0.02089, total_loss: 1.626
training 841 (epoch 3): tem_loss: 1.106, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.02055, consistency_loss_ema: 0.02092, total_loss: 1.627
training 851 (epoch 3): tem_loss: 1.105, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.02049, consistency_loss_ema: 0.02088, total_loss: 1.626
training 861 (epoch 3): tem_loss: 1.110, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.02017, consistency_loss_ema: 0.02051, total_loss: 1.634
training 871 (epoch 3): tem_loss: 1.112, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.01998, consistency_loss_ema: 0.02034, total_loss: 1.643
training 881 (epoch 3): tem_loss: 1.113, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.02002, consistency_loss_ema: 0.02033, total_loss: 1.640
training 891 (epoch 3): tem_loss: 1.113, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.02001, consistency_loss_ema: 0.02040, total_loss: 1.645
training 901 (epoch 3): tem_loss: 1.114, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.02023, consistency_loss_ema: 0.02054, total_loss: 1.650
training 911 (epoch 3): tem_loss: 1.117, pem class_loss: 0.348, pem reg_loss: 0.019, consistency_loss: 0.02010, consistency_loss_ema: 0.02054, total_loss: 1.655
training 921 (epoch 3): tem_loss: 1.118, pem class_loss: 0.348, pem reg_loss: 0.019, consistency_loss: 0.02024, consistency_loss_ema: 0.02058, total_loss: 1.655
training 931 (epoch 3): tem_loss: 1.119, pem class_loss: 0.351, pem reg_loss: 0.019, consistency_loss: 0.02016, consistency_loss_ema: 0.02061, total_loss: 1.661
training 941 (epoch 3): tem_loss: 1.121, pem class_loss: 0.351, pem reg_loss: 0.019, consistency_loss: 0.02006, consistency_loss_ema: 0.02044, total_loss: 1.663
training 951 (epoch 3): tem_loss: 1.121, pem class_loss: 0.351, pem reg_loss: 0.019, consistency_loss: 0.02000, consistency_loss_ema: 0.02033, total_loss: 1.665
[94mBMN training loss(epoch 3): tem_loss: 1.120, pem class_loss: 0.350, pem reg_loss: 0.019, total_loss: 1.661[0m
[94mBMN val loss(epoch 3): tem_loss: 1.171, pem class_loss: 0.347, pem reg_loss: 0.020, total_loss: 1.713[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.168, pem class_loss: 0.354, pem reg_loss: 0.019, total_loss: 1.712[0m
use Semi !!!
training 961 (epoch 4): tem_loss: 1.049, pem class_loss: 0.424, pem reg_loss: 0.022, consistency_loss: 0.04395, consistency_loss_ema: 0.04596, total_loss: 1.696
training 971 (epoch 4): tem_loss: 1.090, pem class_loss: 0.380, pem reg_loss: 0.020, consistency_loss: 0.03241, consistency_loss_ema: 0.03183, total_loss: 1.671
training 981 (epoch 4): tem_loss: 1.126, pem class_loss: 0.383, pem reg_loss: 0.021, consistency_loss: 0.02892, consistency_loss_ema: 0.02966, total_loss: 1.716
training 991 (epoch 4): tem_loss: 1.129, pem class_loss: 0.371, pem reg_loss: 0.020, consistency_loss: 0.02861, consistency_loss_ema: 0.02894, total_loss: 1.703
training 1001 (epoch 4): tem_loss: 1.137, pem class_loss: 0.364, pem reg_loss: 0.020, consistency_loss: 0.02766, consistency_loss_ema: 0.02802, total_loss: 1.701
training 1011 (epoch 4): tem_loss: 1.127, pem class_loss: 0.354, pem reg_loss: 0.019, consistency_loss: 0.02645, consistency_loss_ema: 0.02712, total_loss: 1.673
training 1021 (epoch 4): tem_loss: 1.122, pem class_loss: 0.340, pem reg_loss: 0.018, consistency_loss: 0.02640, consistency_loss_ema: 0.02719, total_loss: 1.645
training 1031 (epoch 4): tem_loss: 1.121, pem class_loss: 0.343, pem reg_loss: 0.018, consistency_loss: 0.02664, consistency_loss_ema: 0.02735, total_loss: 1.648
training 1041 (epoch 4): tem_loss: 1.124, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.02686, consistency_loss_ema: 0.02747, total_loss: 1.655
training 1051 (epoch 4): tem_loss: 1.126, pem class_loss: 0.342, pem reg_loss: 0.018, consistency_loss: 0.02672, consistency_loss_ema: 0.02734, total_loss: 1.652
training 1061 (epoch 4): tem_loss: 1.124, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.02655, consistency_loss_ema: 0.02730, total_loss: 1.644
training 1071 (epoch 4): tem_loss: 1.124, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.02677, consistency_loss_ema: 0.02728, total_loss: 1.644
training 1081 (epoch 4): tem_loss: 1.119, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.02674, consistency_loss_ema: 0.02726, total_loss: 1.636
training 1091 (epoch 4): tem_loss: 1.119, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.02667, consistency_loss_ema: 0.02708, total_loss: 1.637
training 1101 (epoch 4): tem_loss: 1.118, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.02675, consistency_loss_ema: 0.02725, total_loss: 1.637
training 1111 (epoch 4): tem_loss: 1.118, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.02700, consistency_loss_ema: 0.02752, total_loss: 1.635
training 1121 (epoch 4): tem_loss: 1.120, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.02690, consistency_loss_ema: 0.02744, total_loss: 1.638
training 1131 (epoch 4): tem_loss: 1.120, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.02685, consistency_loss_ema: 0.02748, total_loss: 1.636
training 1141 (epoch 4): tem_loss: 1.120, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.02678, consistency_loss_ema: 0.02741, total_loss: 1.634
training 1151 (epoch 4): tem_loss: 1.121, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.02661, consistency_loss_ema: 0.02732, total_loss: 1.635
training 1161 (epoch 4): tem_loss: 1.120, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.02649, consistency_loss_ema: 0.02713, total_loss: 1.634
training 1171 (epoch 4): tem_loss: 1.120, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.02633, consistency_loss_ema: 0.02693, total_loss: 1.633
training 1181 (epoch 4): tem_loss: 1.120, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.02625, consistency_loss_ema: 0.02684, total_loss: 1.630
training 1191 (epoch 4): tem_loss: 1.119, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.02648, consistency_loss_ema: 0.02703, total_loss: 1.632
[94mBMN training loss(epoch 4): tem_loss: 1.119, pem class_loss: 0.333, pem reg_loss: 0.018, total_loss: 1.630[0m
[94mBMN val loss(epoch 4): tem_loss: 1.172, pem class_loss: 0.347, pem reg_loss: 0.019, total_loss: 1.705[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.174, pem class_loss: 0.344, pem reg_loss: 0.018, total_loss: 1.700[0m
use Semi !!!
training 1201 (epoch 5): tem_loss: 1.123, pem class_loss: 0.251, pem reg_loss: 0.017, consistency_loss: 0.05248, consistency_loss_ema: 0.03572, total_loss: 1.544
training 1211 (epoch 5): tem_loss: 1.125, pem class_loss: 0.317, pem reg_loss: 0.019, consistency_loss: 0.03433, consistency_loss_ema: 0.03325, total_loss: 1.629
training 1221 (epoch 5): tem_loss: 1.129, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.02998, consistency_loss_ema: 0.03027, total_loss: 1.660
training 1231 (epoch 5): tem_loss: 1.133, pem class_loss: 0.325, pem reg_loss: 0.018, consistency_loss: 0.02893, consistency_loss_ema: 0.02966, total_loss: 1.637
training 1241 (epoch 5): tem_loss: 1.136, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.02842, consistency_loss_ema: 0.02971, total_loss: 1.637
training 1251 (epoch 5): tem_loss: 1.131, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.02848, consistency_loss_ema: 0.03075, total_loss: 1.639
training 1261 (epoch 5): tem_loss: 1.127, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.02860, consistency_loss_ema: 0.03026, total_loss: 1.633
training 1271 (epoch 5): tem_loss: 1.128, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.02878, consistency_loss_ema: 0.02983, total_loss: 1.641
training 1281 (epoch 5): tem_loss: 1.129, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.02853, consistency_loss_ema: 0.02930, total_loss: 1.645
training 1291 (epoch 5): tem_loss: 1.132, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.02821, consistency_loss_ema: 0.02931, total_loss: 1.644
training 1301 (epoch 5): tem_loss: 1.130, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.02824, consistency_loss_ema: 0.02954, total_loss: 1.639
training 1311 (epoch 5): tem_loss: 1.130, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.02865, consistency_loss_ema: 0.03001, total_loss: 1.638
training 1321 (epoch 5): tem_loss: 1.129, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.02892, consistency_loss_ema: 0.03032, total_loss: 1.632
training 1331 (epoch 5): tem_loss: 1.130, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.02905, consistency_loss_ema: 0.03059, total_loss: 1.629
training 1341 (epoch 5): tem_loss: 1.130, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.02909, consistency_loss_ema: 0.03026, total_loss: 1.633
training 1351 (epoch 5): tem_loss: 1.130, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.02893, consistency_loss_ema: 0.03017, total_loss: 1.627
training 1361 (epoch 5): tem_loss: 1.129, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.02888, consistency_loss_ema: 0.03002, total_loss: 1.625
training 1371 (epoch 5): tem_loss: 1.125, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.02885, consistency_loss_ema: 0.03005, total_loss: 1.619
training 1381 (epoch 5): tem_loss: 1.123, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.02883, consistency_loss_ema: 0.02995, total_loss: 1.614
training 1391 (epoch 5): tem_loss: 1.123, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.02896, consistency_loss_ema: 0.03014, total_loss: 1.612
training 1401 (epoch 5): tem_loss: 1.121, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.02887, consistency_loss_ema: 0.03014, total_loss: 1.612
training 1411 (epoch 5): tem_loss: 1.121, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.02893, consistency_loss_ema: 0.03017, total_loss: 1.614
training 1421 (epoch 5): tem_loss: 1.119, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.02901, consistency_loss_ema: 0.03026, total_loss: 1.614
training 1431 (epoch 5): tem_loss: 1.118, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.02928, consistency_loss_ema: 0.03036, total_loss: 1.613
[94mBMN training loss(epoch 5): tem_loss: 1.116, pem class_loss: 0.322, pem reg_loss: 0.017, total_loss: 1.610[0m
[94mBMN val loss(epoch 5): tem_loss: 1.176, pem class_loss: 0.347, pem reg_loss: 0.018, total_loss: 1.706[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.177, pem class_loss: 0.345, pem reg_loss: 0.018, total_loss: 1.701[0m
use Semi !!!
training 1441 (epoch 6): tem_loss: 1.168, pem class_loss: 0.243, pem reg_loss: 0.012, consistency_loss: 0.03163, consistency_loss_ema: 0.03086, total_loss: 1.533
training 1451 (epoch 6): tem_loss: 1.076, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02929, consistency_loss_ema: 0.03013, total_loss: 1.549
training 1461 (epoch 6): tem_loss: 1.093, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.02771, consistency_loss_ema: 0.02843, total_loss: 1.584
training 1471 (epoch 6): tem_loss: 1.097, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02885, consistency_loss_ema: 0.02978, total_loss: 1.561
training 1481 (epoch 6): tem_loss: 1.102, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02888, consistency_loss_ema: 0.02982, total_loss: 1.570
training 1491 (epoch 6): tem_loss: 1.094, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02859, consistency_loss_ema: 0.03002, total_loss: 1.552
training 1501 (epoch 6): tem_loss: 1.090, pem class_loss: 0.298, pem reg_loss: 0.016, consistency_loss: 0.02882, consistency_loss_ema: 0.03017, total_loss: 1.546
training 1511 (epoch 6): tem_loss: 1.090, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02883, consistency_loss_ema: 0.02992, total_loss: 1.548
training 1521 (epoch 6): tem_loss: 1.101, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02847, consistency_loss_ema: 0.02993, total_loss: 1.572
training 1531 (epoch 6): tem_loss: 1.107, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02873, consistency_loss_ema: 0.03000, total_loss: 1.577
training 1541 (epoch 6): tem_loss: 1.107, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02901, consistency_loss_ema: 0.03010, total_loss: 1.584
training 1551 (epoch 6): tem_loss: 1.107, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02991, consistency_loss_ema: 0.03014, total_loss: 1.584
training 1561 (epoch 6): tem_loss: 1.112, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.02993, consistency_loss_ema: 0.03020, total_loss: 1.589
training 1571 (epoch 6): tem_loss: 1.113, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02991, consistency_loss_ema: 0.03033, total_loss: 1.586
training 1581 (epoch 6): tem_loss: 1.110, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02987, consistency_loss_ema: 0.03035, total_loss: 1.581
training 1591 (epoch 6): tem_loss: 1.105, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02999, consistency_loss_ema: 0.03029, total_loss: 1.577
training 1601 (epoch 6): tem_loss: 1.103, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03011, consistency_loss_ema: 0.03036, total_loss: 1.575
training 1611 (epoch 6): tem_loss: 1.108, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03031, consistency_loss_ema: 0.03042, total_loss: 1.579
training 1621 (epoch 6): tem_loss: 1.106, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03037, consistency_loss_ema: 0.03053, total_loss: 1.579
training 1631 (epoch 6): tem_loss: 1.110, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.03047, consistency_loss_ema: 0.03076, total_loss: 1.588
training 1641 (epoch 6): tem_loss: 1.111, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.03050, consistency_loss_ema: 0.03094, total_loss: 1.590
training 1651 (epoch 6): tem_loss: 1.112, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.03071, consistency_loss_ema: 0.03117, total_loss: 1.592
training 1661 (epoch 6): tem_loss: 1.112, pem class_loss: 0.316, pem reg_loss: 0.017, consistency_loss: 0.03081, consistency_loss_ema: 0.03140, total_loss: 1.595
training 1671 (epoch 6): tem_loss: 1.112, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.03082, consistency_loss_ema: 0.03147, total_loss: 1.593
[94mBMN training loss(epoch 6): tem_loss: 1.110, pem class_loss: 0.314, pem reg_loss: 0.017, total_loss: 1.590[0m
[94mBMN val loss(epoch 6): tem_loss: 1.178, pem class_loss: 0.363, pem reg_loss: 0.018, total_loss: 1.721[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.178, pem class_loss: 0.343, pem reg_loss: 0.018, total_loss: 1.697[0m
use Semi !!!
training 1681 (epoch 7): tem_loss: 1.278, pem class_loss: 0.365, pem reg_loss: 0.017, consistency_loss: 0.02709, consistency_loss_ema: 0.04367, total_loss: 1.809
training 1691 (epoch 7): tem_loss: 1.135, pem class_loss: 0.336, pem reg_loss: 0.017, consistency_loss: 0.02925, consistency_loss_ema: 0.03261, total_loss: 1.644
training 1701 (epoch 7): tem_loss: 1.108, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02810, consistency_loss_ema: 0.02940, total_loss: 1.560
training 1711 (epoch 7): tem_loss: 1.105, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02641, consistency_loss_ema: 0.02743, total_loss: 1.560
training 1721 (epoch 7): tem_loss: 1.104, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02536, consistency_loss_ema: 0.02614, total_loss: 1.570
training 1731 (epoch 7): tem_loss: 1.093, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02402, consistency_loss_ema: 0.02509, total_loss: 1.564
training 1741 (epoch 7): tem_loss: 1.092, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02321, consistency_loss_ema: 0.02455, total_loss: 1.553
training 1751 (epoch 7): tem_loss: 1.094, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02278, consistency_loss_ema: 0.02414, total_loss: 1.546
training 1761 (epoch 7): tem_loss: 1.095, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02265, consistency_loss_ema: 0.02382, total_loss: 1.548
training 1771 (epoch 7): tem_loss: 1.093, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02238, consistency_loss_ema: 0.02344, total_loss: 1.547
training 1781 (epoch 7): tem_loss: 1.090, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02215, consistency_loss_ema: 0.02319, total_loss: 1.542
training 1791 (epoch 7): tem_loss: 1.092, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02196, consistency_loss_ema: 0.02295, total_loss: 1.554
training 1801 (epoch 7): tem_loss: 1.093, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02176, consistency_loss_ema: 0.02270, total_loss: 1.557
training 1811 (epoch 7): tem_loss: 1.095, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02161, consistency_loss_ema: 0.02244, total_loss: 1.557
training 1821 (epoch 7): tem_loss: 1.098, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02138, consistency_loss_ema: 0.02225, total_loss: 1.561
training 1831 (epoch 7): tem_loss: 1.097, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02116, consistency_loss_ema: 0.02222, total_loss: 1.556
training 1841 (epoch 7): tem_loss: 1.095, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02104, consistency_loss_ema: 0.02211, total_loss: 1.549
training 1851 (epoch 7): tem_loss: 1.093, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02105, consistency_loss_ema: 0.02211, total_loss: 1.545
training 1861 (epoch 7): tem_loss: 1.092, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02090, consistency_loss_ema: 0.02213, total_loss: 1.547
training 1871 (epoch 7): tem_loss: 1.090, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02087, consistency_loss_ema: 0.02206, total_loss: 1.542
training 1881 (epoch 7): tem_loss: 1.091, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02087, consistency_loss_ema: 0.02202, total_loss: 1.542
training 1891 (epoch 7): tem_loss: 1.093, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02079, consistency_loss_ema: 0.02198, total_loss: 1.543
training 1901 (epoch 7): tem_loss: 1.093, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02086, consistency_loss_ema: 0.02197, total_loss: 1.542
training 1911 (epoch 7): tem_loss: 1.092, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02089, consistency_loss_ema: 0.02201, total_loss: 1.539
[94mBMN training loss(epoch 7): tem_loss: 1.092, pem class_loss: 0.293, pem reg_loss: 0.015, total_loss: 1.536[0m
[94mBMN val loss(epoch 7): tem_loss: 1.176, pem class_loss: 0.353, pem reg_loss: 0.017, total_loss: 1.701[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.176, pem class_loss: 0.348, pem reg_loss: 0.017, total_loss: 1.697[0m
use Semi !!!
training 1921 (epoch 8): tem_loss: 1.098, pem class_loss: 0.313, pem reg_loss: 0.017, consistency_loss: 0.01867, consistency_loss_ema: 0.02159, total_loss: 1.578
training 1931 (epoch 8): tem_loss: 1.048, pem class_loss: 0.294, pem reg_loss: 0.016, consistency_loss: 0.02198, consistency_loss_ema: 0.02189, total_loss: 1.499
training 1941 (epoch 8): tem_loss: 1.054, pem class_loss: 0.281, pem reg_loss: 0.015, consistency_loss: 0.02097, consistency_loss_ema: 0.02205, total_loss: 1.482
training 1951 (epoch 8): tem_loss: 1.060, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02100, consistency_loss_ema: 0.02208, total_loss: 1.477
training 1961 (epoch 8): tem_loss: 1.064, pem class_loss: 0.277, pem reg_loss: 0.015, consistency_loss: 0.02134, consistency_loss_ema: 0.02225, total_loss: 1.488
training 1971 (epoch 8): tem_loss: 1.071, pem class_loss: 0.280, pem reg_loss: 0.015, consistency_loss: 0.02119, consistency_loss_ema: 0.02226, total_loss: 1.499
training 1981 (epoch 8): tem_loss: 1.066, pem class_loss: 0.278, pem reg_loss: 0.015, consistency_loss: 0.02109, consistency_loss_ema: 0.02230, total_loss: 1.492
training 1991 (epoch 8): tem_loss: 1.069, pem class_loss: 0.279, pem reg_loss: 0.015, consistency_loss: 0.02101, consistency_loss_ema: 0.02248, total_loss: 1.493
training 2001 (epoch 8): tem_loss: 1.068, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02118, consistency_loss_ema: 0.02278, total_loss: 1.487
training 2011 (epoch 8): tem_loss: 1.072, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.02154, consistency_loss_ema: 0.02298, total_loss: 1.493
training 2021 (epoch 8): tem_loss: 1.073, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02132, consistency_loss_ema: 0.02304, total_loss: 1.491
training 2031 (epoch 8): tem_loss: 1.073, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02147, consistency_loss_ema: 0.02307, total_loss: 1.490
training 2041 (epoch 8): tem_loss: 1.077, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02172, consistency_loss_ema: 0.02304, total_loss: 1.499
training 2051 (epoch 8): tem_loss: 1.079, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02162, consistency_loss_ema: 0.02297, total_loss: 1.500
training 2061 (epoch 8): tem_loss: 1.077, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02168, consistency_loss_ema: 0.02293, total_loss: 1.500
training 2071 (epoch 8): tem_loss: 1.077, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.02163, consistency_loss_ema: 0.02293, total_loss: 1.498
training 2081 (epoch 8): tem_loss: 1.076, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02178, consistency_loss_ema: 0.02307, total_loss: 1.497
training 2091 (epoch 8): tem_loss: 1.078, pem class_loss: 0.277, pem reg_loss: 0.015, consistency_loss: 0.02173, consistency_loss_ema: 0.02307, total_loss: 1.501
training 2101 (epoch 8): tem_loss: 1.078, pem class_loss: 0.279, pem reg_loss: 0.015, consistency_loss: 0.02188, consistency_loss_ema: 0.02309, total_loss: 1.502
training 2111 (epoch 8): tem_loss: 1.079, pem class_loss: 0.280, pem reg_loss: 0.015, consistency_loss: 0.02181, consistency_loss_ema: 0.02313, total_loss: 1.504
training 2121 (epoch 8): tem_loss: 1.079, pem class_loss: 0.281, pem reg_loss: 0.015, consistency_loss: 0.02167, consistency_loss_ema: 0.02316, total_loss: 1.504
training 2131 (epoch 8): tem_loss: 1.078, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02165, consistency_loss_ema: 0.02315, total_loss: 1.502
training 2141 (epoch 8): tem_loss: 1.081, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02175, consistency_loss_ema: 0.02321, total_loss: 1.504
training 2151 (epoch 8): tem_loss: 1.081, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02170, consistency_loss_ema: 0.02325, total_loss: 1.504
[94mBMN training loss(epoch 8): tem_loss: 1.081, pem class_loss: 0.279, pem reg_loss: 0.014, total_loss: 1.505[0m
[94mBMN val loss(epoch 8): tem_loss: 1.176, pem class_loss: 0.355, pem reg_loss: 0.017, total_loss: 1.704[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.176, pem class_loss: 0.354, pem reg_loss: 0.017, total_loss: 1.702[0m
use Semi !!!
training 2161 (epoch 9): tem_loss: 1.249, pem class_loss: 0.431, pem reg_loss: 0.015, consistency_loss: 0.02610, consistency_loss_ema: 0.02576, total_loss: 1.834
training 2171 (epoch 9): tem_loss: 1.080, pem class_loss: 0.265, pem reg_loss: 0.012, consistency_loss: 0.02596, consistency_loss_ema: 0.02339, total_loss: 1.469
training 2181 (epoch 9): tem_loss: 1.095, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02463, consistency_loss_ema: 0.02385, total_loss: 1.516
training 2191 (epoch 9): tem_loss: 1.074, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.02382, consistency_loss_ema: 0.02393, total_loss: 1.483
training 2201 (epoch 9): tem_loss: 1.073, pem class_loss: 0.265, pem reg_loss: 0.013, consistency_loss: 0.02366, consistency_loss_ema: 0.02424, total_loss: 1.471
training 2211 (epoch 9): tem_loss: 1.071, pem class_loss: 0.259, pem reg_loss: 0.014, consistency_loss: 0.02406, consistency_loss_ema: 0.02430, total_loss: 1.465
training 2221 (epoch 9): tem_loss: 1.075, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02374, consistency_loss_ema: 0.02438, total_loss: 1.490
training 2231 (epoch 9): tem_loss: 1.070, pem class_loss: 0.267, pem reg_loss: 0.014, consistency_loss: 0.02396, consistency_loss_ema: 0.02462, total_loss: 1.481
training 2241 (epoch 9): tem_loss: 1.076, pem class_loss: 0.269, pem reg_loss: 0.014, consistency_loss: 0.02395, consistency_loss_ema: 0.02449, total_loss: 1.487
training 2251 (epoch 9): tem_loss: 1.081, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02378, consistency_loss_ema: 0.02440, total_loss: 1.499
training 2261 (epoch 9): tem_loss: 1.077, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02367, consistency_loss_ema: 0.02431, total_loss: 1.492
training 2271 (epoch 9): tem_loss: 1.077, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.02371, consistency_loss_ema: 0.02440, total_loss: 1.489
training 2281 (epoch 9): tem_loss: 1.073, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02368, consistency_loss_ema: 0.02443, total_loss: 1.483
training 2291 (epoch 9): tem_loss: 1.070, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.02349, consistency_loss_ema: 0.02443, total_loss: 1.481
training 2301 (epoch 9): tem_loss: 1.073, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02372, consistency_loss_ema: 0.02442, total_loss: 1.490
training 2311 (epoch 9): tem_loss: 1.071, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.02366, consistency_loss_ema: 0.02439, total_loss: 1.484
training 2321 (epoch 9): tem_loss: 1.070, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02393, consistency_loss_ema: 0.02440, total_loss: 1.488
training 2331 (epoch 9): tem_loss: 1.071, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02404, consistency_loss_ema: 0.02442, total_loss: 1.489
training 2341 (epoch 9): tem_loss: 1.068, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02407, consistency_loss_ema: 0.02445, total_loss: 1.485
training 2351 (epoch 9): tem_loss: 1.069, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02399, consistency_loss_ema: 0.02447, total_loss: 1.486
training 2361 (epoch 9): tem_loss: 1.074, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02406, consistency_loss_ema: 0.02458, total_loss: 1.490
training 2371 (epoch 9): tem_loss: 1.075, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02412, consistency_loss_ema: 0.02468, total_loss: 1.492
training 2381 (epoch 9): tem_loss: 1.075, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.02406, consistency_loss_ema: 0.02477, total_loss: 1.494
training 2391 (epoch 9): tem_loss: 1.077, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.02409, consistency_loss_ema: 0.02478, total_loss: 1.496
[94mBMN training loss(epoch 9): tem_loss: 1.076, pem class_loss: 0.275, pem reg_loss: 0.014, total_loss: 1.494[0m
[94mBMN val loss(epoch 9): tem_loss: 1.177, pem class_loss: 0.362, pem reg_loss: 0.017, total_loss: 1.711[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.176, pem class_loss: 0.358, pem reg_loss: 0.017, total_loss: 1.707[0m
unlabel percent:  0.8
eval student model !!
load : ./checkpoint/Semi-base-0.8/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472617
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.0927876045523%
AR@1 is 	 0.33226381461675575
AR@5 is 	 0.47631975867269993
AR@10 is 	 0.5507747154805978
AR@100 is 	 0.7420814479638009
load : ./checkpoint/Semi-base-0.8/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472608
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 65.81098313451254%
AR@1 is 	 0.33193473193473194
AR@5 is 	 0.47353626765391466
AR@10 is 	 0.5491841491841492
AR@100 is 	 0.7406828465651996
eval teacher model !!
load : ./checkpoint/Semi-base-0.8/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472707
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.14762100644454%
AR@1 is 	 0.332373508844097
AR@5 is 	 0.4773892773892775
AR@10 is 	 0.5522692993281229
AR@100 is 	 0.743123543123543
load : ./checkpoint/Semi-base-0.8/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472604
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 65.5870423693953%
AR@1 is 	 0.3298642533936652
AR@5 is 	 0.47046482928835875
AR@10 is 	 0.5448786507610037
AR@100 is 	 0.7394076511723571
#
train subset video numbers: 2885
unlabel unlabeled subset video numbers: 6764
validation subset video numbers: 4728
use 0.30000000000000004 label for training!!!
training batchsize : 24
unlabel_training batchsize : 24
use Semi !!!
training 1 (epoch 0): tem_loss: 1.403, pem class_loss: 0.693, pem reg_loss: 0.040, consistency_loss: 0.00047, consistency_loss_ema: 0.00000, total_loss: 2.502
training 11 (epoch 0): tem_loss: 1.354, pem class_loss: 0.516, pem reg_loss: 0.035, consistency_loss: 0.00013, consistency_loss_ema: 0.00008, total_loss: 2.218
training 21 (epoch 0): tem_loss: 1.325, pem class_loss: 0.467, pem reg_loss: 0.030, consistency_loss: 0.00014, consistency_loss_ema: 0.00012, total_loss: 2.092
training 31 (epoch 0): tem_loss: 1.308, pem class_loss: 0.447, pem reg_loss: 0.028, consistency_loss: 0.00016, consistency_loss_ema: 0.00016, total_loss: 2.031
training 41 (epoch 0): tem_loss: 1.288, pem class_loss: 0.431, pem reg_loss: 0.026, consistency_loss: 0.00019, consistency_loss_ema: 0.00019, total_loss: 1.979
training 51 (epoch 0): tem_loss: 1.273, pem class_loss: 0.413, pem reg_loss: 0.025, consistency_loss: 0.00022, consistency_loss_ema: 0.00021, total_loss: 1.934
training 61 (epoch 0): tem_loss: 1.272, pem class_loss: 0.409, pem reg_loss: 0.024, consistency_loss: 0.00024, consistency_loss_ema: 0.00024, total_loss: 1.925
training 71 (epoch 0): tem_loss: 1.265, pem class_loss: 0.407, pem reg_loss: 0.024, consistency_loss: 0.00025, consistency_loss_ema: 0.00025, total_loss: 1.913
training 81 (epoch 0): tem_loss: 1.259, pem class_loss: 0.403, pem reg_loss: 0.024, consistency_loss: 0.00026, consistency_loss_ema: 0.00026, total_loss: 1.900
training 91 (epoch 0): tem_loss: 1.251, pem class_loss: 0.400, pem reg_loss: 0.024, consistency_loss: 0.00028, consistency_loss_ema: 0.00028, total_loss: 1.887
training 101 (epoch 0): tem_loss: 1.244, pem class_loss: 0.395, pem reg_loss: 0.023, consistency_loss: 0.00029, consistency_loss_ema: 0.00029, total_loss: 1.872
training 111 (epoch 0): tem_loss: 1.240, pem class_loss: 0.391, pem reg_loss: 0.023, consistency_loss: 0.00029, consistency_loss_ema: 0.00030, total_loss: 1.861
[94mBMN training loss(epoch 0): tem_loss: 1.234, pem class_loss: 0.390, pem reg_loss: 0.023, total_loss: 1.853[0m
[94mBMN val loss(epoch 0): tem_loss: 1.198, pem class_loss: 0.360, pem reg_loss: 0.021, total_loss: 1.766[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.190, pem class_loss: 0.364, pem reg_loss: 0.020, total_loss: 1.758[0m
use Semi !!!
training 121 (epoch 1): tem_loss: 1.184, pem class_loss: 0.362, pem reg_loss: 0.022, consistency_loss: 0.00261, consistency_loss_ema: 0.00267, total_loss: 1.768
training 131 (epoch 1): tem_loss: 1.185, pem class_loss: 0.366, pem reg_loss: 0.020, consistency_loss: 0.00237, consistency_loss_ema: 0.00233, total_loss: 1.756
training 141 (epoch 1): tem_loss: 1.165, pem class_loss: 0.348, pem reg_loss: 0.020, consistency_loss: 0.00282, consistency_loss_ema: 0.00276, total_loss: 1.716
training 151 (epoch 1): tem_loss: 1.153, pem class_loss: 0.350, pem reg_loss: 0.020, consistency_loss: 0.00276, consistency_loss_ema: 0.00282, total_loss: 1.704
training 161 (epoch 1): tem_loss: 1.159, pem class_loss: 0.349, pem reg_loss: 0.020, consistency_loss: 0.00269, consistency_loss_ema: 0.00272, total_loss: 1.706
training 171 (epoch 1): tem_loss: 1.158, pem class_loss: 0.351, pem reg_loss: 0.020, consistency_loss: 0.00262, consistency_loss_ema: 0.00265, total_loss: 1.706
training 181 (epoch 1): tem_loss: 1.157, pem class_loss: 0.353, pem reg_loss: 0.020, consistency_loss: 0.00271, consistency_loss_ema: 0.00274, total_loss: 1.709
training 191 (epoch 1): tem_loss: 1.160, pem class_loss: 0.354, pem reg_loss: 0.020, consistency_loss: 0.00274, consistency_loss_ema: 0.00281, total_loss: 1.716
training 201 (epoch 1): tem_loss: 1.162, pem class_loss: 0.358, pem reg_loss: 0.020, consistency_loss: 0.00272, consistency_loss_ema: 0.00282, total_loss: 1.723
training 211 (epoch 1): tem_loss: 1.165, pem class_loss: 0.359, pem reg_loss: 0.020, consistency_loss: 0.00273, consistency_loss_ema: 0.00283, total_loss: 1.727
training 221 (epoch 1): tem_loss: 1.161, pem class_loss: 0.355, pem reg_loss: 0.020, consistency_loss: 0.00279, consistency_loss_ema: 0.00287, total_loss: 1.718
training 231 (epoch 1): tem_loss: 1.159, pem class_loss: 0.355, pem reg_loss: 0.020, consistency_loss: 0.00280, consistency_loss_ema: 0.00290, total_loss: 1.716
[94mBMN training loss(epoch 1): tem_loss: 1.158, pem class_loss: 0.354, pem reg_loss: 0.020, total_loss: 1.713[0m
[94mBMN val loss(epoch 1): tem_loss: 1.187, pem class_loss: 0.346, pem reg_loss: 0.021, total_loss: 1.747[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.179, pem class_loss: 0.346, pem reg_loss: 0.019, total_loss: 1.715[0m
use Semi !!!
training 241 (epoch 2): tem_loss: 1.059, pem class_loss: 0.288, pem reg_loss: 0.023, consistency_loss: 0.01336, consistency_loss_ema: 0.01352, total_loss: 1.572
training 251 (epoch 2): tem_loss: 1.102, pem class_loss: 0.361, pem reg_loss: 0.021, consistency_loss: 0.01069, consistency_loss_ema: 0.01150, total_loss: 1.678
training 261 (epoch 2): tem_loss: 1.112, pem class_loss: 0.365, pem reg_loss: 0.021, consistency_loss: 0.01001, consistency_loss_ema: 0.01018, total_loss: 1.689
training 271 (epoch 2): tem_loss: 1.111, pem class_loss: 0.357, pem reg_loss: 0.021, consistency_loss: 0.00986, consistency_loss_ema: 0.01001, total_loss: 1.678
training 281 (epoch 2): tem_loss: 1.113, pem class_loss: 0.353, pem reg_loss: 0.021, consistency_loss: 0.00956, consistency_loss_ema: 0.00973, total_loss: 1.672
training 291 (epoch 2): tem_loss: 1.116, pem class_loss: 0.353, pem reg_loss: 0.021, consistency_loss: 0.00937, consistency_loss_ema: 0.00972, total_loss: 1.674
training 301 (epoch 2): tem_loss: 1.120, pem class_loss: 0.354, pem reg_loss: 0.020, consistency_loss: 0.00911, consistency_loss_ema: 0.00947, total_loss: 1.677
training 311 (epoch 2): tem_loss: 1.123, pem class_loss: 0.352, pem reg_loss: 0.020, consistency_loss: 0.00892, consistency_loss_ema: 0.00931, total_loss: 1.676
training 321 (epoch 2): tem_loss: 1.125, pem class_loss: 0.348, pem reg_loss: 0.020, consistency_loss: 0.00884, consistency_loss_ema: 0.00916, total_loss: 1.671
training 331 (epoch 2): tem_loss: 1.125, pem class_loss: 0.348, pem reg_loss: 0.020, consistency_loss: 0.00873, consistency_loss_ema: 0.00911, total_loss: 1.672
training 341 (epoch 2): tem_loss: 1.126, pem class_loss: 0.348, pem reg_loss: 0.020, consistency_loss: 0.00869, consistency_loss_ema: 0.00906, total_loss: 1.673
training 351 (epoch 2): tem_loss: 1.122, pem class_loss: 0.346, pem reg_loss: 0.020, consistency_loss: 0.00877, consistency_loss_ema: 0.00914, total_loss: 1.665
[94mBMN training loss(epoch 2): tem_loss: 1.122, pem class_loss: 0.344, pem reg_loss: 0.020, total_loss: 1.663[0m
[94mBMN val loss(epoch 2): tem_loss: 1.166, pem class_loss: 0.352, pem reg_loss: 0.019, total_loss: 1.706[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.160, pem class_loss: 0.342, pem reg_loss: 0.019, total_loss: 1.690[0m
use Semi !!!
training 361 (epoch 3): tem_loss: 1.095, pem class_loss: 0.309, pem reg_loss: 0.018, consistency_loss: 0.02978, consistency_loss_ema: 0.02353, total_loss: 1.584
training 371 (epoch 3): tem_loss: 1.088, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.02374, consistency_loss_ema: 0.02412, total_loss: 1.604
training 381 (epoch 3): tem_loss: 1.092, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.02118, consistency_loss_ema: 0.02224, total_loss: 1.599
training 391 (epoch 3): tem_loss: 1.092, pem class_loss: 0.324, pem reg_loss: 0.018, consistency_loss: 0.02041, consistency_loss_ema: 0.02114, total_loss: 1.595
training 401 (epoch 3): tem_loss: 1.086, pem class_loss: 0.324, pem reg_loss: 0.018, consistency_loss: 0.01993, consistency_loss_ema: 0.02117, total_loss: 1.592
training 411 (epoch 3): tem_loss: 1.098, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.02042, consistency_loss_ema: 0.02111, total_loss: 1.606
training 421 (epoch 3): tem_loss: 1.099, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.01999, consistency_loss_ema: 0.02070, total_loss: 1.609
training 431 (epoch 3): tem_loss: 1.099, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.01974, consistency_loss_ema: 0.02044, total_loss: 1.610
training 441 (epoch 3): tem_loss: 1.099, pem class_loss: 0.324, pem reg_loss: 0.018, consistency_loss: 0.01948, consistency_loss_ema: 0.02027, total_loss: 1.604
training 451 (epoch 3): tem_loss: 1.104, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.01897, consistency_loss_ema: 0.02002, total_loss: 1.616
training 461 (epoch 3): tem_loss: 1.103, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.01885, consistency_loss_ema: 0.01999, total_loss: 1.613
training 471 (epoch 3): tem_loss: 1.106, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.01871, consistency_loss_ema: 0.01978, total_loss: 1.613
[94mBMN training loss(epoch 3): tem_loss: 1.105, pem class_loss: 0.327, pem reg_loss: 0.018, total_loss: 1.612[0m
[94mBMN val loss(epoch 3): tem_loss: 1.164, pem class_loss: 0.339, pem reg_loss: 0.018, total_loss: 1.685[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.161, pem class_loss: 0.339, pem reg_loss: 0.018, total_loss: 1.681[0m
use Semi !!!
training 481 (epoch 4): tem_loss: 0.965, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.03178, consistency_loss_ema: 0.03698, total_loss: 1.412
training 491 (epoch 4): tem_loss: 1.117, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.03128, consistency_loss_ema: 0.03323, total_loss: 1.595
training 501 (epoch 4): tem_loss: 1.111, pem class_loss: 0.313, pem reg_loss: 0.017, consistency_loss: 0.02905, consistency_loss_ema: 0.03153, total_loss: 1.593
training 511 (epoch 4): tem_loss: 1.100, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.02828, consistency_loss_ema: 0.03023, total_loss: 1.580
training 521 (epoch 4): tem_loss: 1.096, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.02758, consistency_loss_ema: 0.02942, total_loss: 1.581
training 531 (epoch 4): tem_loss: 1.093, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.02702, consistency_loss_ema: 0.02892, total_loss: 1.584
training 541 (epoch 4): tem_loss: 1.096, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.02627, consistency_loss_ema: 0.02822, total_loss: 1.585
training 551 (epoch 4): tem_loss: 1.095, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.02587, consistency_loss_ema: 0.02775, total_loss: 1.584
training 561 (epoch 4): tem_loss: 1.095, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.02588, consistency_loss_ema: 0.02790, total_loss: 1.580
training 571 (epoch 4): tem_loss: 1.096, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.02593, consistency_loss_ema: 0.02783, total_loss: 1.586
training 581 (epoch 4): tem_loss: 1.097, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.02581, consistency_loss_ema: 0.02756, total_loss: 1.584
training 591 (epoch 4): tem_loss: 1.101, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.02607, consistency_loss_ema: 0.02747, total_loss: 1.591
[94mBMN training loss(epoch 4): tem_loss: 1.100, pem class_loss: 0.316, pem reg_loss: 0.017, total_loss: 1.589[0m
[94mBMN val loss(epoch 4): tem_loss: 1.170, pem class_loss: 0.337, pem reg_loss: 0.017, total_loss: 1.681[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.167, pem class_loss: 0.335, pem reg_loss: 0.018, total_loss: 1.678[0m
use Semi !!!
training 601 (epoch 5): tem_loss: 1.051, pem class_loss: 0.310, pem reg_loss: 0.019, consistency_loss: 0.04011, consistency_loss_ema: 0.03335, total_loss: 1.554
training 611 (epoch 5): tem_loss: 1.076, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.03414, consistency_loss_ema: 0.03223, total_loss: 1.536
training 621 (epoch 5): tem_loss: 1.083, pem class_loss: 0.307, pem reg_loss: 0.017, consistency_loss: 0.03166, consistency_loss_ema: 0.03150, total_loss: 1.556
training 631 (epoch 5): tem_loss: 1.094, pem class_loss: 0.304, pem reg_loss: 0.017, consistency_loss: 0.03109, consistency_loss_ema: 0.03093, total_loss: 1.564
training 641 (epoch 5): tem_loss: 1.094, pem class_loss: 0.297, pem reg_loss: 0.016, consistency_loss: 0.03039, consistency_loss_ema: 0.03075, total_loss: 1.554
training 651 (epoch 5): tem_loss: 1.095, pem class_loss: 0.302, pem reg_loss: 0.017, consistency_loss: 0.03002, consistency_loss_ema: 0.03097, total_loss: 1.563
training 661 (epoch 5): tem_loss: 1.095, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02980, consistency_loss_ema: 0.03072, total_loss: 1.565
training 671 (epoch 5): tem_loss: 1.092, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02983, consistency_loss_ema: 0.03112, total_loss: 1.560
training 681 (epoch 5): tem_loss: 1.094, pem class_loss: 0.305, pem reg_loss: 0.017, consistency_loss: 0.02990, consistency_loss_ema: 0.03133, total_loss: 1.564
training 691 (epoch 5): tem_loss: 1.095, pem class_loss: 0.306, pem reg_loss: 0.017, consistency_loss: 0.02977, consistency_loss_ema: 0.03142, total_loss: 1.566
training 701 (epoch 5): tem_loss: 1.096, pem class_loss: 0.307, pem reg_loss: 0.017, consistency_loss: 0.02955, consistency_loss_ema: 0.03146, total_loss: 1.569
training 711 (epoch 5): tem_loss: 1.098, pem class_loss: 0.307, pem reg_loss: 0.017, consistency_loss: 0.02937, consistency_loss_ema: 0.03139, total_loss: 1.570
[94mBMN training loss(epoch 5): tem_loss: 1.100, pem class_loss: 0.306, pem reg_loss: 0.017, total_loss: 1.571[0m
[94mBMN val loss(epoch 5): tem_loss: 1.172, pem class_loss: 0.336, pem reg_loss: 0.018, total_loss: 1.684[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.170, pem class_loss: 0.335, pem reg_loss: 0.017, total_loss: 1.678[0m
use Semi !!!
training 721 (epoch 6): tem_loss: 1.029, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.02479, consistency_loss_ema: 0.02147, total_loss: 1.522
training 731 (epoch 6): tem_loss: 1.077, pem class_loss: 0.299, pem reg_loss: 0.017, consistency_loss: 0.02717, consistency_loss_ema: 0.02840, total_loss: 1.545
training 741 (epoch 6): tem_loss: 1.084, pem class_loss: 0.292, pem reg_loss: 0.016, consistency_loss: 0.02868, consistency_loss_ema: 0.03002, total_loss: 1.536
training 751 (epoch 6): tem_loss: 1.080, pem class_loss: 0.293, pem reg_loss: 0.016, consistency_loss: 0.02924, consistency_loss_ema: 0.03004, total_loss: 1.532
training 761 (epoch 6): tem_loss: 1.082, pem class_loss: 0.294, pem reg_loss: 0.016, consistency_loss: 0.02897, consistency_loss_ema: 0.02990, total_loss: 1.536
training 771 (epoch 6): tem_loss: 1.083, pem class_loss: 0.297, pem reg_loss: 0.016, consistency_loss: 0.02898, consistency_loss_ema: 0.03003, total_loss: 1.538
training 781 (epoch 6): tem_loss: 1.085, pem class_loss: 0.293, pem reg_loss: 0.016, consistency_loss: 0.02948, consistency_loss_ema: 0.03052, total_loss: 1.535
training 791 (epoch 6): tem_loss: 1.091, pem class_loss: 0.295, pem reg_loss: 0.016, consistency_loss: 0.02951, consistency_loss_ema: 0.03066, total_loss: 1.544
training 801 (epoch 6): tem_loss: 1.095, pem class_loss: 0.296, pem reg_loss: 0.016, consistency_loss: 0.02953, consistency_loss_ema: 0.03066, total_loss: 1.549
training 811 (epoch 6): tem_loss: 1.096, pem class_loss: 0.294, pem reg_loss: 0.016, consistency_loss: 0.02961, consistency_loss_ema: 0.03095, total_loss: 1.547
training 821 (epoch 6): tem_loss: 1.096, pem class_loss: 0.296, pem reg_loss: 0.016, consistency_loss: 0.02951, consistency_loss_ema: 0.03103, total_loss: 1.550
training 831 (epoch 6): tem_loss: 1.094, pem class_loss: 0.296, pem reg_loss: 0.016, consistency_loss: 0.02943, consistency_loss_ema: 0.03129, total_loss: 1.549
[94mBMN training loss(epoch 6): tem_loss: 1.096, pem class_loss: 0.298, pem reg_loss: 0.016, total_loss: 1.553[0m
[94mBMN val loss(epoch 6): tem_loss: 1.170, pem class_loss: 0.334, pem reg_loss: 0.017, total_loss: 1.678[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.172, pem class_loss: 0.335, pem reg_loss: 0.017, total_loss: 1.678[0m
use Semi !!!
training 841 (epoch 7): tem_loss: 1.060, pem class_loss: 0.315, pem reg_loss: 0.020, consistency_loss: 0.03567, consistency_loss_ema: 0.03098, total_loss: 1.574
training 851 (epoch 7): tem_loss: 1.076, pem class_loss: 0.291, pem reg_loss: 0.017, consistency_loss: 0.02615, consistency_loss_ema: 0.02822, total_loss: 1.533
training 861 (epoch 7): tem_loss: 1.073, pem class_loss: 0.284, pem reg_loss: 0.016, consistency_loss: 0.02404, consistency_loss_ema: 0.02701, total_loss: 1.519
training 871 (epoch 7): tem_loss: 1.070, pem class_loss: 0.288, pem reg_loss: 0.016, consistency_loss: 0.02286, consistency_loss_ema: 0.02559, total_loss: 1.518
training 881 (epoch 7): tem_loss: 1.079, pem class_loss: 0.290, pem reg_loss: 0.016, consistency_loss: 0.02252, consistency_loss_ema: 0.02497, total_loss: 1.527
training 891 (epoch 7): tem_loss: 1.072, pem class_loss: 0.285, pem reg_loss: 0.015, consistency_loss: 0.02228, consistency_loss_ema: 0.02468, total_loss: 1.511
training 901 (epoch 7): tem_loss: 1.072, pem class_loss: 0.284, pem reg_loss: 0.015, consistency_loss: 0.02185, consistency_loss_ema: 0.02434, total_loss: 1.511
training 911 (epoch 7): tem_loss: 1.074, pem class_loss: 0.281, pem reg_loss: 0.015, consistency_loss: 0.02176, consistency_loss_ema: 0.02404, total_loss: 1.507
training 921 (epoch 7): tem_loss: 1.075, pem class_loss: 0.283, pem reg_loss: 0.015, consistency_loss: 0.02170, consistency_loss_ema: 0.02396, total_loss: 1.511
training 931 (epoch 7): tem_loss: 1.079, pem class_loss: 0.284, pem reg_loss: 0.015, consistency_loss: 0.02152, consistency_loss_ema: 0.02365, total_loss: 1.515
training 941 (epoch 7): tem_loss: 1.078, pem class_loss: 0.281, pem reg_loss: 0.015, consistency_loss: 0.02150, consistency_loss_ema: 0.02356, total_loss: 1.510
training 951 (epoch 7): tem_loss: 1.078, pem class_loss: 0.280, pem reg_loss: 0.015, consistency_loss: 0.02154, consistency_loss_ema: 0.02355, total_loss: 1.508
[94mBMN training loss(epoch 7): tem_loss: 1.078, pem class_loss: 0.280, pem reg_loss: 0.015, total_loss: 1.506[0m
[94mBMN val loss(epoch 7): tem_loss: 1.169, pem class_loss: 0.341, pem reg_loss: 0.017, total_loss: 1.680[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.170, pem class_loss: 0.339, pem reg_loss: 0.017, total_loss: 1.678[0m
use Semi !!!
training 961 (epoch 8): tem_loss: 1.093, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01702, consistency_loss_ema: 0.02163, total_loss: 1.492
training 971 (epoch 8): tem_loss: 1.060, pem class_loss: 0.277, pem reg_loss: 0.015, consistency_loss: 0.02138, consistency_loss_ema: 0.02247, total_loss: 1.486
training 981 (epoch 8): tem_loss: 1.069, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.02103, consistency_loss_ema: 0.02284, total_loss: 1.486
training 991 (epoch 8): tem_loss: 1.077, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02075, consistency_loss_ema: 0.02327, total_loss: 1.494
training 1001 (epoch 8): tem_loss: 1.073, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02127, consistency_loss_ema: 0.02392, total_loss: 1.485
training 1011 (epoch 8): tem_loss: 1.071, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02161, consistency_loss_ema: 0.02395, total_loss: 1.484
training 1021 (epoch 8): tem_loss: 1.070, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02172, consistency_loss_ema: 0.02382, total_loss: 1.482
training 1031 (epoch 8): tem_loss: 1.075, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02157, consistency_loss_ema: 0.02397, total_loss: 1.486
training 1041 (epoch 8): tem_loss: 1.074, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.02157, consistency_loss_ema: 0.02400, total_loss: 1.487
training 1051 (epoch 8): tem_loss: 1.072, pem class_loss: 0.267, pem reg_loss: 0.014, consistency_loss: 0.02174, consistency_loss_ema: 0.02407, total_loss: 1.480
training 1061 (epoch 8): tem_loss: 1.073, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02187, consistency_loss_ema: 0.02422, total_loss: 1.486
training 1071 (epoch 8): tem_loss: 1.074, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.02202, consistency_loss_ema: 0.02432, total_loss: 1.489
[94mBMN training loss(epoch 8): tem_loss: 1.073, pem class_loss: 0.273, pem reg_loss: 0.014, total_loss: 1.490[0m
[94mBMN val loss(epoch 8): tem_loss: 1.171, pem class_loss: 0.343, pem reg_loss: 0.017, total_loss: 1.683[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.169, pem class_loss: 0.342, pem reg_loss: 0.017, total_loss: 1.679[0m
use Semi !!!
training 1081 (epoch 9): tem_loss: 1.052, pem class_loss: 0.245, pem reg_loss: 0.015, consistency_loss: 0.02485, consistency_loss_ema: 0.02282, total_loss: 1.447
training 1091 (epoch 9): tem_loss: 1.070, pem class_loss: 0.266, pem reg_loss: 0.014, consistency_loss: 0.02367, consistency_loss_ema: 0.02492, total_loss: 1.474
training 1101 (epoch 9): tem_loss: 1.068, pem class_loss: 0.267, pem reg_loss: 0.014, consistency_loss: 0.02321, consistency_loss_ema: 0.02510, total_loss: 1.478
training 1111 (epoch 9): tem_loss: 1.067, pem class_loss: 0.264, pem reg_loss: 0.014, consistency_loss: 0.02316, consistency_loss_ema: 0.02529, total_loss: 1.471
training 1121 (epoch 9): tem_loss: 1.069, pem class_loss: 0.267, pem reg_loss: 0.014, consistency_loss: 0.02327, consistency_loss_ema: 0.02559, total_loss: 1.478
training 1131 (epoch 9): tem_loss: 1.068, pem class_loss: 0.268, pem reg_loss: 0.014, consistency_loss: 0.02345, consistency_loss_ema: 0.02545, total_loss: 1.480
training 1141 (epoch 9): tem_loss: 1.069, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02343, consistency_loss_ema: 0.02552, total_loss: 1.483
training 1151 (epoch 9): tem_loss: 1.066, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02346, consistency_loss_ema: 0.02553, total_loss: 1.481
training 1161 (epoch 9): tem_loss: 1.065, pem class_loss: 0.269, pem reg_loss: 0.014, consistency_loss: 0.02336, consistency_loss_ema: 0.02559, total_loss: 1.477
training 1171 (epoch 9): tem_loss: 1.064, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02346, consistency_loss_ema: 0.02568, total_loss: 1.477
training 1181 (epoch 9): tem_loss: 1.066, pem class_loss: 0.269, pem reg_loss: 0.014, consistency_loss: 0.02351, consistency_loss_ema: 0.02577, total_loss: 1.479
training 1191 (epoch 9): tem_loss: 1.068, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02347, consistency_loss_ema: 0.02577, total_loss: 1.481
[94mBMN training loss(epoch 9): tem_loss: 1.068, pem class_loss: 0.269, pem reg_loss: 0.014, total_loss: 1.479[0m
[94mBMN val loss(epoch 9): tem_loss: 1.170, pem class_loss: 0.342, pem reg_loss: 0.017, total_loss: 1.680[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.170, pem class_loss: 0.344, pem reg_loss: 0.017, total_loss: 1.683[0m
unlabel percent:  0.7
eval student model !!
load : ./checkpoint/Semi-base-0.7/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472570
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.52904840257783%
AR@1 is 	 0.333305909776498
AR@5 is 	 0.48201014671602904
AR@10 is 	 0.5594954065542301
AR@100 is 	 0.7460441519265049
load : ./checkpoint/Semi-base-0.7/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472593
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.05156999862884%
AR@1 is 	 0.33105717811600166
AR@5 is 	 0.47823940765117234
AR@10 is 	 0.5522007404360345
AR@100 is 	 0.7419717537364596
eval teacher model !!
load : ./checkpoint/Semi-base-0.7/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472593
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.43150281091457%
AR@1 is 	 0.3334156040038393
AR@5 is 	 0.4840257781434253
AR@10 is 	 0.5598107774578363
AR@100 is 	 0.7447552447552448
load : ./checkpoint/Semi-base-0.7/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472605
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.26360208419034%
AR@1 is 	 0.3324832030714384
AR@5 is 	 0.47951460304401483
AR@10 is 	 0.5562731386260799
AR@100 is 	 0.7437954202660084
#
train subset video numbers: 3867
unlabel unlabeled subset video numbers: 5782
validation subset video numbers: 4728
use 0.4 label for training!!!
training batchsize : 24
unlabel_training batchsize : 24
use Semi !!!
training 1 (epoch 0): tem_loss: 1.391, pem class_loss: 0.693, pem reg_loss: 0.041, consistency_loss: 0.00032, consistency_loss_ema: 0.00000, total_loss: 2.491
training 11 (epoch 0): tem_loss: 1.363, pem class_loss: 0.504, pem reg_loss: 0.031, consistency_loss: 0.00012, consistency_loss_ema: 0.00007, total_loss: 2.180
training 21 (epoch 0): tem_loss: 1.323, pem class_loss: 0.437, pem reg_loss: 0.027, consistency_loss: 0.00014, consistency_loss_ema: 0.00011, total_loss: 2.033
training 31 (epoch 0): tem_loss: 1.304, pem class_loss: 0.438, pem reg_loss: 0.026, consistency_loss: 0.00017, consistency_loss_ema: 0.00016, total_loss: 2.004
training 41 (epoch 0): tem_loss: 1.282, pem class_loss: 0.424, pem reg_loss: 0.025, consistency_loss: 0.00019, consistency_loss_ema: 0.00018, total_loss: 1.960
training 51 (epoch 0): tem_loss: 1.273, pem class_loss: 0.416, pem reg_loss: 0.025, consistency_loss: 0.00022, consistency_loss_ema: 0.00022, total_loss: 1.938
training 61 (epoch 0): tem_loss: 1.266, pem class_loss: 0.417, pem reg_loss: 0.025, consistency_loss: 0.00025, consistency_loss_ema: 0.00025, total_loss: 1.930
training 71 (epoch 0): tem_loss: 1.259, pem class_loss: 0.407, pem reg_loss: 0.024, consistency_loss: 0.00026, consistency_loss_ema: 0.00026, total_loss: 1.908
training 81 (epoch 0): tem_loss: 1.253, pem class_loss: 0.400, pem reg_loss: 0.024, consistency_loss: 0.00028, consistency_loss_ema: 0.00028, total_loss: 1.890
training 91 (epoch 0): tem_loss: 1.247, pem class_loss: 0.395, pem reg_loss: 0.023, consistency_loss: 0.00028, consistency_loss_ema: 0.00029, total_loss: 1.875
training 101 (epoch 0): tem_loss: 1.243, pem class_loss: 0.390, pem reg_loss: 0.023, consistency_loss: 0.00029, consistency_loss_ema: 0.00029, total_loss: 1.862
training 111 (epoch 0): tem_loss: 1.238, pem class_loss: 0.388, pem reg_loss: 0.023, consistency_loss: 0.00030, consistency_loss_ema: 0.00031, total_loss: 1.854
training 121 (epoch 0): tem_loss: 1.234, pem class_loss: 0.384, pem reg_loss: 0.022, consistency_loss: 0.00031, consistency_loss_ema: 0.00032, total_loss: 1.842
training 131 (epoch 0): tem_loss: 1.232, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00032, consistency_loss_ema: 0.00032, total_loss: 1.837
training 141 (epoch 0): tem_loss: 1.232, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00032, consistency_loss_ema: 0.00033, total_loss: 1.838
training 151 (epoch 0): tem_loss: 1.228, pem class_loss: 0.382, pem reg_loss: 0.022, consistency_loss: 0.00033, consistency_loss_ema: 0.00034, total_loss: 1.831
training 161 (epoch 0): tem_loss: 1.224, pem class_loss: 0.381, pem reg_loss: 0.022, consistency_loss: 0.00033, consistency_loss_ema: 0.00034, total_loss: 1.826
[94mBMN training loss(epoch 0): tem_loss: 1.224, pem class_loss: 0.381, pem reg_loss: 0.022, total_loss: 1.826[0m
[94mBMN val loss(epoch 0): tem_loss: 1.187, pem class_loss: 0.356, pem reg_loss: 0.020, total_loss: 1.748[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.187, pem class_loss: 0.355, pem reg_loss: 0.020, total_loss: 1.738[0m
use Semi !!!
training 162 (epoch 1): tem_loss: 1.137, pem class_loss: 0.327, pem reg_loss: 0.017, consistency_loss: 0.00222, consistency_loss_ema: 0.00196, total_loss: 1.635
training 172 (epoch 1): tem_loss: 1.126, pem class_loss: 0.346, pem reg_loss: 0.020, consistency_loss: 0.00258, consistency_loss_ema: 0.00271, total_loss: 1.677
training 182 (epoch 1): tem_loss: 1.145, pem class_loss: 0.367, pem reg_loss: 0.021, consistency_loss: 0.00232, consistency_loss_ema: 0.00248, total_loss: 1.723
training 192 (epoch 1): tem_loss: 1.144, pem class_loss: 0.363, pem reg_loss: 0.021, consistency_loss: 0.00248, consistency_loss_ema: 0.00260, total_loss: 1.715
training 202 (epoch 1): tem_loss: 1.153, pem class_loss: 0.356, pem reg_loss: 0.020, consistency_loss: 0.00249, consistency_loss_ema: 0.00263, total_loss: 1.713
training 212 (epoch 1): tem_loss: 1.150, pem class_loss: 0.352, pem reg_loss: 0.020, consistency_loss: 0.00241, consistency_loss_ema: 0.00250, total_loss: 1.702
training 222 (epoch 1): tem_loss: 1.149, pem class_loss: 0.351, pem reg_loss: 0.020, consistency_loss: 0.00241, consistency_loss_ema: 0.00246, total_loss: 1.698
training 232 (epoch 1): tem_loss: 1.149, pem class_loss: 0.348, pem reg_loss: 0.020, consistency_loss: 0.00239, consistency_loss_ema: 0.00242, total_loss: 1.696
training 242 (epoch 1): tem_loss: 1.145, pem class_loss: 0.347, pem reg_loss: 0.020, consistency_loss: 0.00236, consistency_loss_ema: 0.00240, total_loss: 1.691
training 252 (epoch 1): tem_loss: 1.145, pem class_loss: 0.343, pem reg_loss: 0.020, consistency_loss: 0.00240, consistency_loss_ema: 0.00246, total_loss: 1.684
training 262 (epoch 1): tem_loss: 1.146, pem class_loss: 0.343, pem reg_loss: 0.020, consistency_loss: 0.00245, consistency_loss_ema: 0.00254, total_loss: 1.685
training 272 (epoch 1): tem_loss: 1.147, pem class_loss: 0.344, pem reg_loss: 0.020, consistency_loss: 0.00249, consistency_loss_ema: 0.00259, total_loss: 1.688
training 282 (epoch 1): tem_loss: 1.146, pem class_loss: 0.345, pem reg_loss: 0.020, consistency_loss: 0.00251, consistency_loss_ema: 0.00260, total_loss: 1.688
training 292 (epoch 1): tem_loss: 1.145, pem class_loss: 0.344, pem reg_loss: 0.020, consistency_loss: 0.00253, consistency_loss_ema: 0.00263, total_loss: 1.685
training 302 (epoch 1): tem_loss: 1.145, pem class_loss: 0.342, pem reg_loss: 0.020, consistency_loss: 0.00253, consistency_loss_ema: 0.00266, total_loss: 1.683
training 312 (epoch 1): tem_loss: 1.146, pem class_loss: 0.344, pem reg_loss: 0.020, consistency_loss: 0.00258, consistency_loss_ema: 0.00272, total_loss: 1.686
training 322 (epoch 1): tem_loss: 1.144, pem class_loss: 0.345, pem reg_loss: 0.020, consistency_loss: 0.00258, consistency_loss_ema: 0.00270, total_loss: 1.687
[94mBMN training loss(epoch 1): tem_loss: 1.144, pem class_loss: 0.345, pem reg_loss: 0.020, total_loss: 1.687[0m
[94mBMN val loss(epoch 1): tem_loss: 1.168, pem class_loss: 0.345, pem reg_loss: 0.019, total_loss: 1.705[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.158, pem class_loss: 0.345, pem reg_loss: 0.019, total_loss: 1.696[0m
use Semi !!!
training 323 (epoch 2): tem_loss: 1.071, pem class_loss: 0.303, pem reg_loss: 0.019, consistency_loss: 0.00863, consistency_loss_ema: 0.01096, total_loss: 1.564
training 333 (epoch 2): tem_loss: 1.105, pem class_loss: 0.341, pem reg_loss: 0.020, consistency_loss: 0.00890, consistency_loss_ema: 0.00926, total_loss: 1.645
training 343 (epoch 2): tem_loss: 1.101, pem class_loss: 0.350, pem reg_loss: 0.021, consistency_loss: 0.00871, consistency_loss_ema: 0.00944, total_loss: 1.658
training 353 (epoch 2): tem_loss: 1.100, pem class_loss: 0.338, pem reg_loss: 0.020, consistency_loss: 0.00860, consistency_loss_ema: 0.00935, total_loss: 1.636
training 363 (epoch 2): tem_loss: 1.101, pem class_loss: 0.336, pem reg_loss: 0.020, consistency_loss: 0.00849, consistency_loss_ema: 0.00910, total_loss: 1.633
training 373 (epoch 2): tem_loss: 1.095, pem class_loss: 0.328, pem reg_loss: 0.019, consistency_loss: 0.00856, consistency_loss_ema: 0.00909, total_loss: 1.615
training 383 (epoch 2): tem_loss: 1.093, pem class_loss: 0.327, pem reg_loss: 0.019, consistency_loss: 0.00837, consistency_loss_ema: 0.00890, total_loss: 1.612
training 393 (epoch 2): tem_loss: 1.101, pem class_loss: 0.327, pem reg_loss: 0.019, consistency_loss: 0.00846, consistency_loss_ema: 0.00888, total_loss: 1.619
training 403 (epoch 2): tem_loss: 1.099, pem class_loss: 0.324, pem reg_loss: 0.019, consistency_loss: 0.00873, consistency_loss_ema: 0.00894, total_loss: 1.614
training 413 (epoch 2): tem_loss: 1.103, pem class_loss: 0.326, pem reg_loss: 0.019, consistency_loss: 0.00897, consistency_loss_ema: 0.00913, total_loss: 1.620
training 423 (epoch 2): tem_loss: 1.105, pem class_loss: 0.327, pem reg_loss: 0.019, consistency_loss: 0.00887, consistency_loss_ema: 0.00905, total_loss: 1.623
training 433 (epoch 2): tem_loss: 1.101, pem class_loss: 0.327, pem reg_loss: 0.019, consistency_loss: 0.00879, consistency_loss_ema: 0.00899, total_loss: 1.617
training 443 (epoch 2): tem_loss: 1.102, pem class_loss: 0.328, pem reg_loss: 0.019, consistency_loss: 0.00888, consistency_loss_ema: 0.00910, total_loss: 1.619
training 453 (epoch 2): tem_loss: 1.104, pem class_loss: 0.328, pem reg_loss: 0.019, consistency_loss: 0.00894, consistency_loss_ema: 0.00928, total_loss: 1.620
training 463 (epoch 2): tem_loss: 1.108, pem class_loss: 0.330, pem reg_loss: 0.019, consistency_loss: 0.00891, consistency_loss_ema: 0.00929, total_loss: 1.627
training 473 (epoch 2): tem_loss: 1.110, pem class_loss: 0.330, pem reg_loss: 0.019, consistency_loss: 0.00887, consistency_loss_ema: 0.00923, total_loss: 1.628
training 483 (epoch 2): tem_loss: 1.111, pem class_loss: 0.331, pem reg_loss: 0.019, consistency_loss: 0.00894, consistency_loss_ema: 0.00927, total_loss: 1.631
[94mBMN training loss(epoch 2): tem_loss: 1.111, pem class_loss: 0.331, pem reg_loss: 0.019, total_loss: 1.631[0m
[94mBMN val loss(epoch 2): tem_loss: 1.154, pem class_loss: 0.343, pem reg_loss: 0.018, total_loss: 1.680[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.148, pem class_loss: 0.336, pem reg_loss: 0.018, total_loss: 1.668[0m
use Semi !!!
training 484 (epoch 3): tem_loss: 1.067, pem class_loss: 0.264, pem reg_loss: 0.014, consistency_loss: 0.01724, consistency_loss_ema: 0.02662, total_loss: 1.473
training 494 (epoch 3): tem_loss: 1.047, pem class_loss: 0.290, pem reg_loss: 0.016, consistency_loss: 0.02178, consistency_loss_ema: 0.02403, total_loss: 1.494
training 504 (epoch 3): tem_loss: 1.067, pem class_loss: 0.307, pem reg_loss: 0.017, consistency_loss: 0.02057, consistency_loss_ema: 0.02202, total_loss: 1.544
training 514 (epoch 3): tem_loss: 1.075, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.02031, consistency_loss_ema: 0.02136, total_loss: 1.556
training 524 (epoch 3): tem_loss: 1.076, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.02002, consistency_loss_ema: 0.02088, total_loss: 1.557
training 534 (epoch 3): tem_loss: 1.077, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.01950, consistency_loss_ema: 0.02039, total_loss: 1.557
training 544 (epoch 3): tem_loss: 1.079, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01896, consistency_loss_ema: 0.01969, total_loss: 1.567
training 554 (epoch 3): tem_loss: 1.084, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.01892, consistency_loss_ema: 0.01955, total_loss: 1.573
training 564 (epoch 3): tem_loss: 1.086, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01878, consistency_loss_ema: 0.01947, total_loss: 1.579
training 574 (epoch 3): tem_loss: 1.087, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.01885, consistency_loss_ema: 0.01966, total_loss: 1.582
training 584 (epoch 3): tem_loss: 1.092, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.01886, consistency_loss_ema: 0.01979, total_loss: 1.587
training 594 (epoch 3): tem_loss: 1.091, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.01864, consistency_loss_ema: 0.01961, total_loss: 1.586
training 604 (epoch 3): tem_loss: 1.091, pem class_loss: 0.321, pem reg_loss: 0.018, consistency_loss: 0.01871, consistency_loss_ema: 0.01950, total_loss: 1.589
training 614 (epoch 3): tem_loss: 1.093, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.01871, consistency_loss_ema: 0.01943, total_loss: 1.590
training 624 (epoch 3): tem_loss: 1.093, pem class_loss: 0.319, pem reg_loss: 0.018, consistency_loss: 0.01861, consistency_loss_ema: 0.01950, total_loss: 1.589
training 634 (epoch 3): tem_loss: 1.096, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.01848, consistency_loss_ema: 0.01931, total_loss: 1.594
training 644 (epoch 3): tem_loss: 1.097, pem class_loss: 0.319, pem reg_loss: 0.018, consistency_loss: 0.01855, consistency_loss_ema: 0.01932, total_loss: 1.594
[94mBMN training loss(epoch 3): tem_loss: 1.097, pem class_loss: 0.319, pem reg_loss: 0.018, total_loss: 1.594[0m
[94mBMN val loss(epoch 3): tem_loss: 1.150, pem class_loss: 0.339, pem reg_loss: 0.019, total_loss: 1.678[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.148, pem class_loss: 0.332, pem reg_loss: 0.018, total_loss: 1.659[0m
use Semi !!!
training 645 (epoch 4): tem_loss: 1.098, pem class_loss: 0.268, pem reg_loss: 0.017, consistency_loss: 0.03531, consistency_loss_ema: 0.02828, total_loss: 1.538
training 655 (epoch 4): tem_loss: 1.068, pem class_loss: 0.302, pem reg_loss: 0.017, consistency_loss: 0.03005, consistency_loss_ema: 0.03004, total_loss: 1.543
training 665 (epoch 4): tem_loss: 1.072, pem class_loss: 0.295, pem reg_loss: 0.017, consistency_loss: 0.02884, consistency_loss_ema: 0.02939, total_loss: 1.538
training 675 (epoch 4): tem_loss: 1.084, pem class_loss: 0.304, pem reg_loss: 0.017, consistency_loss: 0.02790, consistency_loss_ema: 0.02874, total_loss: 1.560
training 685 (epoch 4): tem_loss: 1.080, pem class_loss: 0.302, pem reg_loss: 0.017, consistency_loss: 0.02804, consistency_loss_ema: 0.02923, total_loss: 1.552
training 695 (epoch 4): tem_loss: 1.085, pem class_loss: 0.305, pem reg_loss: 0.017, consistency_loss: 0.02756, consistency_loss_ema: 0.02919, total_loss: 1.560
training 705 (epoch 4): tem_loss: 1.087, pem class_loss: 0.304, pem reg_loss: 0.017, consistency_loss: 0.02724, consistency_loss_ema: 0.02901, total_loss: 1.561
training 715 (epoch 4): tem_loss: 1.088, pem class_loss: 0.305, pem reg_loss: 0.017, consistency_loss: 0.02729, consistency_loss_ema: 0.02920, total_loss: 1.563
training 725 (epoch 4): tem_loss: 1.091, pem class_loss: 0.306, pem reg_loss: 0.017, consistency_loss: 0.02712, consistency_loss_ema: 0.02876, total_loss: 1.567
training 735 (epoch 4): tem_loss: 1.092, pem class_loss: 0.305, pem reg_loss: 0.017, consistency_loss: 0.02721, consistency_loss_ema: 0.02872, total_loss: 1.567
training 745 (epoch 4): tem_loss: 1.094, pem class_loss: 0.308, pem reg_loss: 0.017, consistency_loss: 0.02729, consistency_loss_ema: 0.02869, total_loss: 1.572
training 755 (epoch 4): tem_loss: 1.095, pem class_loss: 0.307, pem reg_loss: 0.017, consistency_loss: 0.02717, consistency_loss_ema: 0.02850, total_loss: 1.572
training 765 (epoch 4): tem_loss: 1.095, pem class_loss: 0.308, pem reg_loss: 0.017, consistency_loss: 0.02685, consistency_loss_ema: 0.02820, total_loss: 1.574
training 775 (epoch 4): tem_loss: 1.096, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.02666, consistency_loss_ema: 0.02801, total_loss: 1.579
training 785 (epoch 4): tem_loss: 1.095, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.02666, consistency_loss_ema: 0.02799, total_loss: 1.579
training 795 (epoch 4): tem_loss: 1.096, pem class_loss: 0.313, pem reg_loss: 0.017, consistency_loss: 0.02656, consistency_loss_ema: 0.02787, total_loss: 1.580
training 805 (epoch 4): tem_loss: 1.097, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.02638, consistency_loss_ema: 0.02773, total_loss: 1.579
[94mBMN training loss(epoch 4): tem_loss: 1.097, pem class_loss: 0.311, pem reg_loss: 0.017, total_loss: 1.579[0m
[94mBMN val loss(epoch 4): tem_loss: 1.154, pem class_loss: 0.337, pem reg_loss: 0.018, total_loss: 1.669[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.153, pem class_loss: 0.329, pem reg_loss: 0.017, total_loss: 1.657[0m
use Semi !!!
training 806 (epoch 5): tem_loss: 1.183, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.03205, consistency_loss_ema: 0.03401, total_loss: 1.760
training 816 (epoch 5): tem_loss: 1.107, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.02836, consistency_loss_ema: 0.02788, total_loss: 1.589
training 826 (epoch 5): tem_loss: 1.099, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02751, consistency_loss_ema: 0.02930, total_loss: 1.559
training 836 (epoch 5): tem_loss: 1.096, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02736, consistency_loss_ema: 0.02899, total_loss: 1.558
training 846 (epoch 5): tem_loss: 1.096, pem class_loss: 0.308, pem reg_loss: 0.017, consistency_loss: 0.02734, consistency_loss_ema: 0.02907, total_loss: 1.569
training 856 (epoch 5): tem_loss: 1.090, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02751, consistency_loss_ema: 0.02943, total_loss: 1.562
training 866 (epoch 5): tem_loss: 1.091, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02783, consistency_loss_ema: 0.03003, total_loss: 1.562
training 876 (epoch 5): tem_loss: 1.089, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02820, consistency_loss_ema: 0.03063, total_loss: 1.553
training 886 (epoch 5): tem_loss: 1.095, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02795, consistency_loss_ema: 0.03053, total_loss: 1.562
training 896 (epoch 5): tem_loss: 1.092, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.02796, consistency_loss_ema: 0.03056, total_loss: 1.559
training 906 (epoch 5): tem_loss: 1.092, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02808, consistency_loss_ema: 0.03060, total_loss: 1.554
training 916 (epoch 5): tem_loss: 1.093, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02811, consistency_loss_ema: 0.03068, total_loss: 1.558
training 926 (epoch 5): tem_loss: 1.094, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02825, consistency_loss_ema: 0.03065, total_loss: 1.559
training 936 (epoch 5): tem_loss: 1.097, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.02835, consistency_loss_ema: 0.03062, total_loss: 1.562
training 946 (epoch 5): tem_loss: 1.098, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02845, consistency_loss_ema: 0.03050, total_loss: 1.561
training 956 (epoch 5): tem_loss: 1.097, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02831, consistency_loss_ema: 0.03043, total_loss: 1.562
training 966 (epoch 5): tem_loss: 1.096, pem class_loss: 0.301, pem reg_loss: 0.016, consistency_loss: 0.02841, consistency_loss_ema: 0.03035, total_loss: 1.560
[94mBMN training loss(epoch 5): tem_loss: 1.096, pem class_loss: 0.301, pem reg_loss: 0.016, total_loss: 1.560[0m
[94mBMN val loss(epoch 5): tem_loss: 1.159, pem class_loss: 0.336, pem reg_loss: 0.018, total_loss: 1.671[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.157, pem class_loss: 0.329, pem reg_loss: 0.017, total_loss: 1.656[0m
use Semi !!!
training 967 (epoch 6): tem_loss: 1.042, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02652, consistency_loss_ema: 0.03131, total_loss: 1.495
training 977 (epoch 6): tem_loss: 1.068, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02877, consistency_loss_ema: 0.02939, total_loss: 1.490
training 987 (epoch 6): tem_loss: 1.084, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02835, consistency_loss_ema: 0.02926, total_loss: 1.528
training 997 (epoch 6): tem_loss: 1.092, pem class_loss: 0.290, pem reg_loss: 0.015, consistency_loss: 0.02847, consistency_loss_ema: 0.03059, total_loss: 1.528
training 1007 (epoch 6): tem_loss: 1.090, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02930, consistency_loss_ema: 0.03091, total_loss: 1.534
training 1017 (epoch 6): tem_loss: 1.086, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02912, consistency_loss_ema: 0.03082, total_loss: 1.533
training 1027 (epoch 6): tem_loss: 1.089, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02877, consistency_loss_ema: 0.03086, total_loss: 1.540
training 1037 (epoch 6): tem_loss: 1.088, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02917, consistency_loss_ema: 0.03076, total_loss: 1.537
training 1047 (epoch 6): tem_loss: 1.089, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02882, consistency_loss_ema: 0.03047, total_loss: 1.539
training 1057 (epoch 6): tem_loss: 1.092, pem class_loss: 0.297, pem reg_loss: 0.016, consistency_loss: 0.02910, consistency_loss_ema: 0.03065, total_loss: 1.546
training 1067 (epoch 6): tem_loss: 1.089, pem class_loss: 0.297, pem reg_loss: 0.016, consistency_loss: 0.02919, consistency_loss_ema: 0.03096, total_loss: 1.543
training 1077 (epoch 6): tem_loss: 1.092, pem class_loss: 0.296, pem reg_loss: 0.016, consistency_loss: 0.02922, consistency_loss_ema: 0.03088, total_loss: 1.545
training 1087 (epoch 6): tem_loss: 1.091, pem class_loss: 0.294, pem reg_loss: 0.016, consistency_loss: 0.02903, consistency_loss_ema: 0.03080, total_loss: 1.542
training 1097 (epoch 6): tem_loss: 1.091, pem class_loss: 0.294, pem reg_loss: 0.016, consistency_loss: 0.02892, consistency_loss_ema: 0.03065, total_loss: 1.542
training 1107 (epoch 6): tem_loss: 1.091, pem class_loss: 0.295, pem reg_loss: 0.016, consistency_loss: 0.02894, consistency_loss_ema: 0.03070, total_loss: 1.543
training 1117 (epoch 6): tem_loss: 1.090, pem class_loss: 0.294, pem reg_loss: 0.016, consistency_loss: 0.02891, consistency_loss_ema: 0.03058, total_loss: 1.541
training 1127 (epoch 6): tem_loss: 1.093, pem class_loss: 0.295, pem reg_loss: 0.016, consistency_loss: 0.02879, consistency_loss_ema: 0.03043, total_loss: 1.544
[94mBMN training loss(epoch 6): tem_loss: 1.093, pem class_loss: 0.295, pem reg_loss: 0.016, total_loss: 1.544[0m
[94mBMN val loss(epoch 6): tem_loss: 1.159, pem class_loss: 0.332, pem reg_loss: 0.017, total_loss: 1.657[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.159, pem class_loss: 0.328, pem reg_loss: 0.017, total_loss: 1.652[0m
use Semi !!!
training 1128 (epoch 7): tem_loss: 1.065, pem class_loss: 0.253, pem reg_loss: 0.012, consistency_loss: 0.02564, consistency_loss_ema: 0.02862, total_loss: 1.437
training 1138 (epoch 7): tem_loss: 1.093, pem class_loss: 0.286, pem reg_loss: 0.015, consistency_loss: 0.02588, consistency_loss_ema: 0.02792, total_loss: 1.532
training 1148 (epoch 7): tem_loss: 1.080, pem class_loss: 0.283, pem reg_loss: 0.015, consistency_loss: 0.02422, consistency_loss_ema: 0.02550, total_loss: 1.511
training 1158 (epoch 7): tem_loss: 1.075, pem class_loss: 0.271, pem reg_loss: 0.015, consistency_loss: 0.02263, consistency_loss_ema: 0.02444, total_loss: 1.491
training 1168 (epoch 7): tem_loss: 1.078, pem class_loss: 0.279, pem reg_loss: 0.015, consistency_loss: 0.02201, consistency_loss_ema: 0.02363, total_loss: 1.505
training 1178 (epoch 7): tem_loss: 1.080, pem class_loss: 0.279, pem reg_loss: 0.015, consistency_loss: 0.02134, consistency_loss_ema: 0.02305, total_loss: 1.506
training 1188 (epoch 7): tem_loss: 1.082, pem class_loss: 0.282, pem reg_loss: 0.015, consistency_loss: 0.02076, consistency_loss_ema: 0.02237, total_loss: 1.513
training 1198 (epoch 7): tem_loss: 1.083, pem class_loss: 0.284, pem reg_loss: 0.015, consistency_loss: 0.02058, consistency_loss_ema: 0.02202, total_loss: 1.515
training 1208 (epoch 7): tem_loss: 1.082, pem class_loss: 0.282, pem reg_loss: 0.015, consistency_loss: 0.02046, consistency_loss_ema: 0.02186, total_loss: 1.512
training 1218 (epoch 7): tem_loss: 1.081, pem class_loss: 0.282, pem reg_loss: 0.015, consistency_loss: 0.02041, consistency_loss_ema: 0.02178, total_loss: 1.510
training 1228 (epoch 7): tem_loss: 1.080, pem class_loss: 0.282, pem reg_loss: 0.015, consistency_loss: 0.02022, consistency_loss_ema: 0.02167, total_loss: 1.509
training 1238 (epoch 7): tem_loss: 1.080, pem class_loss: 0.281, pem reg_loss: 0.015, consistency_loss: 0.02014, consistency_loss_ema: 0.02162, total_loss: 1.508
training 1248 (epoch 7): tem_loss: 1.080, pem class_loss: 0.278, pem reg_loss: 0.015, consistency_loss: 0.02015, consistency_loss_ema: 0.02170, total_loss: 1.505
training 1258 (epoch 7): tem_loss: 1.080, pem class_loss: 0.277, pem reg_loss: 0.015, consistency_loss: 0.02010, consistency_loss_ema: 0.02166, total_loss: 1.503
training 1268 (epoch 7): tem_loss: 1.078, pem class_loss: 0.276, pem reg_loss: 0.015, consistency_loss: 0.02008, consistency_loss_ema: 0.02169, total_loss: 1.501
training 1278 (epoch 7): tem_loss: 1.077, pem class_loss: 0.276, pem reg_loss: 0.015, consistency_loss: 0.02007, consistency_loss_ema: 0.02161, total_loss: 1.498
training 1288 (epoch 7): tem_loss: 1.078, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02006, consistency_loss_ema: 0.02170, total_loss: 1.497
[94mBMN training loss(epoch 7): tem_loss: 1.078, pem class_loss: 0.274, pem reg_loss: 0.014, total_loss: 1.497[0m
[94mBMN val loss(epoch 7): tem_loss: 1.158, pem class_loss: 0.338, pem reg_loss: 0.016, total_loss: 1.659[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.158, pem class_loss: 0.333, pem reg_loss: 0.016, total_loss: 1.654[0m
use Semi !!!
training 1289 (epoch 8): tem_loss: 0.935, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.01962, consistency_loss_ema: 0.02348, total_loss: 1.323
training 1299 (epoch 8): tem_loss: 1.064, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02084, consistency_loss_ema: 0.02197, total_loss: 1.479
training 1309 (epoch 8): tem_loss: 1.061, pem class_loss: 0.267, pem reg_loss: 0.014, consistency_loss: 0.02026, consistency_loss_ema: 0.02235, total_loss: 1.466
training 1319 (epoch 8): tem_loss: 1.067, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02047, consistency_loss_ema: 0.02226, total_loss: 1.483
training 1329 (epoch 8): tem_loss: 1.078, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.02039, consistency_loss_ema: 0.02198, total_loss: 1.497
training 1339 (epoch 8): tem_loss: 1.072, pem class_loss: 0.276, pem reg_loss: 0.015, consistency_loss: 0.02007, consistency_loss_ema: 0.02197, total_loss: 1.494
training 1349 (epoch 8): tem_loss: 1.075, pem class_loss: 0.276, pem reg_loss: 0.015, consistency_loss: 0.02017, consistency_loss_ema: 0.02193, total_loss: 1.497
training 1359 (epoch 8): tem_loss: 1.074, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.02025, consistency_loss_ema: 0.02201, total_loss: 1.493
training 1369 (epoch 8): tem_loss: 1.075, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02043, consistency_loss_ema: 0.02193, total_loss: 1.494
training 1379 (epoch 8): tem_loss: 1.074, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02042, consistency_loss_ema: 0.02219, total_loss: 1.492
training 1389 (epoch 8): tem_loss: 1.072, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02041, consistency_loss_ema: 0.02231, total_loss: 1.486
training 1399 (epoch 8): tem_loss: 1.074, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.02043, consistency_loss_ema: 0.02237, total_loss: 1.490
training 1409 (epoch 8): tem_loss: 1.072, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.02045, consistency_loss_ema: 0.02243, total_loss: 1.486
training 1419 (epoch 8): tem_loss: 1.071, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02049, consistency_loss_ema: 0.02257, total_loss: 1.487
training 1429 (epoch 8): tem_loss: 1.072, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02064, consistency_loss_ema: 0.02266, total_loss: 1.486
training 1439 (epoch 8): tem_loss: 1.071, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.02071, consistency_loss_ema: 0.02273, total_loss: 1.484
training 1449 (epoch 8): tem_loss: 1.071, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.02080, consistency_loss_ema: 0.02277, total_loss: 1.485
[94mBMN training loss(epoch 8): tem_loss: 1.071, pem class_loss: 0.271, pem reg_loss: 0.014, total_loss: 1.485[0m
[94mBMN val loss(epoch 8): tem_loss: 1.158, pem class_loss: 0.335, pem reg_loss: 0.016, total_loss: 1.657[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.158, pem class_loss: 0.335, pem reg_loss: 0.016, total_loss: 1.656[0m
use Semi !!!
training 1450 (epoch 9): tem_loss: 1.198, pem class_loss: 0.303, pem reg_loss: 0.012, consistency_loss: 0.02099, consistency_loss_ema: 0.02149, total_loss: 1.622
training 1460 (epoch 9): tem_loss: 1.082, pem class_loss: 0.252, pem reg_loss: 0.013, consistency_loss: 0.02141, consistency_loss_ema: 0.02459, total_loss: 1.467
training 1470 (epoch 9): tem_loss: 1.063, pem class_loss: 0.247, pem reg_loss: 0.013, consistency_loss: 0.02164, consistency_loss_ema: 0.02406, total_loss: 1.437
training 1480 (epoch 9): tem_loss: 1.068, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02179, consistency_loss_ema: 0.02392, total_loss: 1.453
training 1490 (epoch 9): tem_loss: 1.075, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02178, consistency_loss_ema: 0.02368, total_loss: 1.459
training 1500 (epoch 9): tem_loss: 1.077, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02184, consistency_loss_ema: 0.02375, total_loss: 1.461
training 1510 (epoch 9): tem_loss: 1.074, pem class_loss: 0.257, pem reg_loss: 0.013, consistency_loss: 0.02187, consistency_loss_ema: 0.02379, total_loss: 1.461
training 1520 (epoch 9): tem_loss: 1.072, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02196, consistency_loss_ema: 0.02366, total_loss: 1.462
training 1530 (epoch 9): tem_loss: 1.072, pem class_loss: 0.262, pem reg_loss: 0.013, consistency_loss: 0.02192, consistency_loss_ema: 0.02366, total_loss: 1.469
training 1540 (epoch 9): tem_loss: 1.073, pem class_loss: 0.262, pem reg_loss: 0.014, consistency_loss: 0.02184, consistency_loss_ema: 0.02359, total_loss: 1.470
training 1550 (epoch 9): tem_loss: 1.074, pem class_loss: 0.265, pem reg_loss: 0.014, consistency_loss: 0.02181, consistency_loss_ema: 0.02356, total_loss: 1.477
training 1560 (epoch 9): tem_loss: 1.075, pem class_loss: 0.266, pem reg_loss: 0.014, consistency_loss: 0.02185, consistency_loss_ema: 0.02349, total_loss: 1.479
training 1570 (epoch 9): tem_loss: 1.074, pem class_loss: 0.266, pem reg_loss: 0.014, consistency_loss: 0.02189, consistency_loss_ema: 0.02364, total_loss: 1.478
training 1580 (epoch 9): tem_loss: 1.072, pem class_loss: 0.266, pem reg_loss: 0.014, consistency_loss: 0.02185, consistency_loss_ema: 0.02365, total_loss: 1.477
training 1590 (epoch 9): tem_loss: 1.072, pem class_loss: 0.266, pem reg_loss: 0.014, consistency_loss: 0.02181, consistency_loss_ema: 0.02363, total_loss: 1.476
training 1600 (epoch 9): tem_loss: 1.070, pem class_loss: 0.265, pem reg_loss: 0.014, consistency_loss: 0.02182, consistency_loss_ema: 0.02364, total_loss: 1.474
training 1610 (epoch 9): tem_loss: 1.069, pem class_loss: 0.264, pem reg_loss: 0.014, consistency_loss: 0.02190, consistency_loss_ema: 0.02369, total_loss: 1.472
[94mBMN training loss(epoch 9): tem_loss: 1.069, pem class_loss: 0.264, pem reg_loss: 0.014, total_loss: 1.472[0m
[94mBMN val loss(epoch 9): tem_loss: 1.158, pem class_loss: 0.342, pem reg_loss: 0.016, total_loss: 1.664[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.158, pem class_loss: 0.340, pem reg_loss: 0.016, total_loss: 1.661[0m
unlabel percent:  0.6
eval student model !!
load : ./checkpoint/Semi-base-0.6/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472687
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.03940079528313%
AR@1 is 	 0.33314136843548614
AR@5 is 	 0.4888660359248595
AR@10 is 	 0.5634992458521871
AR@100 is 	 0.7493898258604139
load : ./checkpoint/Semi-base-0.6/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472693
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.98795420266008%
AR@1 is 	 0.33345673933909226
AR@5 is 	 0.4889483065953654
AR@10 is 	 0.5634306869600987
AR@100 is 	 0.7493761140819964
eval teacher model !!
load : ./checkpoint/Semi-base-0.6/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472702
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.96748251748252%
AR@1 is 	 0.33390922802687506
AR@5 is 	 0.48748114630467587
AR@10 is 	 0.5625531331413685
AR@100 is 	 0.7480734951323187
load : ./checkpoint/Semi-base-0.6/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472695
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.65119292472232%
AR@1 is 	 0.334073769367887
AR@5 is 	 0.48307966543260666
AR@10 is 	 0.5593857123268888
AR@100 is 	 0.7468942821883998
#
train subset video numbers: 4825
unlabel unlabeled subset video numbers: 4824
validation subset video numbers: 4728
use 0.5 label for training!!!
training batchsize : 16
unlabel_training batchsize : 16
use Semi !!!
training 1 (epoch 0): tem_loss: 1.403, pem class_loss: 0.693, pem reg_loss: 0.041, consistency_loss: 0.00055, consistency_loss_ema: 0.00000, total_loss: 2.509
training 11 (epoch 0): tem_loss: 1.369, pem class_loss: 0.624, pem reg_loss: 0.042, consistency_loss: 0.00017, consistency_loss_ema: 0.00014, total_loss: 2.417
training 21 (epoch 0): tem_loss: 1.359, pem class_loss: 0.579, pem reg_loss: 0.038, consistency_loss: 0.00016, consistency_loss_ema: 0.00015, total_loss: 2.314
training 31 (epoch 0): tem_loss: 1.344, pem class_loss: 0.534, pem reg_loss: 0.033, consistency_loss: 0.00015, consistency_loss_ema: 0.00015, total_loss: 2.211
training 41 (epoch 0): tem_loss: 1.324, pem class_loss: 0.498, pem reg_loss: 0.031, consistency_loss: 0.00017, consistency_loss_ema: 0.00017, total_loss: 2.134
training 51 (epoch 0): tem_loss: 1.309, pem class_loss: 0.477, pem reg_loss: 0.030, consistency_loss: 0.00019, consistency_loss_ema: 0.00019, total_loss: 2.082
training 61 (epoch 0): tem_loss: 1.300, pem class_loss: 0.459, pem reg_loss: 0.028, consistency_loss: 0.00023, consistency_loss_ema: 0.00023, total_loss: 2.043
training 71 (epoch 0): tem_loss: 1.296, pem class_loss: 0.452, pem reg_loss: 0.028, consistency_loss: 0.00024, consistency_loss_ema: 0.00024, total_loss: 2.027
training 81 (epoch 0): tem_loss: 1.284, pem class_loss: 0.443, pem reg_loss: 0.027, consistency_loss: 0.00025, consistency_loss_ema: 0.00025, total_loss: 1.995
training 91 (epoch 0): tem_loss: 1.276, pem class_loss: 0.435, pem reg_loss: 0.026, consistency_loss: 0.00026, consistency_loss_ema: 0.00027, total_loss: 1.974
training 101 (epoch 0): tem_loss: 1.271, pem class_loss: 0.427, pem reg_loss: 0.026, consistency_loss: 0.00029, consistency_loss_ema: 0.00029, total_loss: 1.955
training 111 (epoch 0): tem_loss: 1.269, pem class_loss: 0.422, pem reg_loss: 0.025, consistency_loss: 0.00032, consistency_loss_ema: 0.00032, total_loss: 1.944
training 121 (epoch 0): tem_loss: 1.261, pem class_loss: 0.414, pem reg_loss: 0.025, consistency_loss: 0.00033, consistency_loss_ema: 0.00033, total_loss: 1.922
training 131 (epoch 0): tem_loss: 1.253, pem class_loss: 0.412, pem reg_loss: 0.025, consistency_loss: 0.00033, consistency_loss_ema: 0.00033, total_loss: 1.910
training 141 (epoch 0): tem_loss: 1.251, pem class_loss: 0.412, pem reg_loss: 0.025, consistency_loss: 0.00034, consistency_loss_ema: 0.00035, total_loss: 1.908
training 151 (epoch 0): tem_loss: 1.247, pem class_loss: 0.409, pem reg_loss: 0.024, consistency_loss: 0.00034, consistency_loss_ema: 0.00035, total_loss: 1.898
training 161 (epoch 0): tem_loss: 1.241, pem class_loss: 0.406, pem reg_loss: 0.024, consistency_loss: 0.00035, consistency_loss_ema: 0.00035, total_loss: 1.888
training 171 (epoch 0): tem_loss: 1.238, pem class_loss: 0.404, pem reg_loss: 0.024, consistency_loss: 0.00035, consistency_loss_ema: 0.00035, total_loss: 1.880
training 181 (epoch 0): tem_loss: 1.236, pem class_loss: 0.402, pem reg_loss: 0.024, consistency_loss: 0.00035, consistency_loss_ema: 0.00035, total_loss: 1.874
training 191 (epoch 0): tem_loss: 1.232, pem class_loss: 0.401, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00035, total_loss: 1.867
training 201 (epoch 0): tem_loss: 1.229, pem class_loss: 0.398, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00035, total_loss: 1.859
training 211 (epoch 0): tem_loss: 1.228, pem class_loss: 0.397, pem reg_loss: 0.023, consistency_loss: 0.00036, consistency_loss_ema: 0.00036, total_loss: 1.857
training 221 (epoch 0): tem_loss: 1.226, pem class_loss: 0.395, pem reg_loss: 0.023, consistency_loss: 0.00037, consistency_loss_ema: 0.00037, total_loss: 1.852
training 231 (epoch 0): tem_loss: 1.224, pem class_loss: 0.393, pem reg_loss: 0.023, consistency_loss: 0.00037, consistency_loss_ema: 0.00037, total_loss: 1.845
training 241 (epoch 0): tem_loss: 1.222, pem class_loss: 0.392, pem reg_loss: 0.023, consistency_loss: 0.00038, consistency_loss_ema: 0.00038, total_loss: 1.842
training 251 (epoch 0): tem_loss: 1.220, pem class_loss: 0.390, pem reg_loss: 0.023, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.837
training 261 (epoch 0): tem_loss: 1.218, pem class_loss: 0.388, pem reg_loss: 0.023, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.830
training 271 (epoch 0): tem_loss: 1.215, pem class_loss: 0.388, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.827
training 281 (epoch 0): tem_loss: 1.214, pem class_loss: 0.387, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.825
training 291 (epoch 0): tem_loss: 1.213, pem class_loss: 0.385, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00039, total_loss: 1.820
training 301 (epoch 0): tem_loss: 1.211, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00039, total_loss: 1.816
[94mBMN training loss(epoch 0): tem_loss: 1.211, pem class_loss: 0.383, pem reg_loss: 0.022, total_loss: 1.816[0m
[94mBMN val loss(epoch 0): tem_loss: 1.182, pem class_loss: 0.363, pem reg_loss: 0.020, total_loss: 1.749[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.173, pem class_loss: 0.345, pem reg_loss: 0.019, total_loss: 1.711[0m
use Semi !!!
training 302 (epoch 1): tem_loss: 1.158, pem class_loss: 0.347, pem reg_loss: 0.018, consistency_loss: 0.00353, consistency_loss_ema: 0.00250, total_loss: 1.688
training 312 (epoch 1): tem_loss: 1.126, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00276, consistency_loss_ema: 0.00261, total_loss: 1.658
training 322 (epoch 1): tem_loss: 1.121, pem class_loss: 0.332, pem reg_loss: 0.019, consistency_loss: 0.00284, consistency_loss_ema: 0.00275, total_loss: 1.644
training 332 (epoch 1): tem_loss: 1.117, pem class_loss: 0.334, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00261, total_loss: 1.644
training 342 (epoch 1): tem_loss: 1.120, pem class_loss: 0.334, pem reg_loss: 0.020, consistency_loss: 0.00273, consistency_loss_ema: 0.00265, total_loss: 1.650
training 352 (epoch 1): tem_loss: 1.126, pem class_loss: 0.343, pem reg_loss: 0.020, consistency_loss: 0.00270, consistency_loss_ema: 0.00265, total_loss: 1.670
training 362 (epoch 1): tem_loss: 1.125, pem class_loss: 0.340, pem reg_loss: 0.020, consistency_loss: 0.00274, consistency_loss_ema: 0.00270, total_loss: 1.662
training 372 (epoch 1): tem_loss: 1.124, pem class_loss: 0.343, pem reg_loss: 0.020, consistency_loss: 0.00280, consistency_loss_ema: 0.00277, total_loss: 1.665
training 382 (epoch 1): tem_loss: 1.130, pem class_loss: 0.345, pem reg_loss: 0.020, consistency_loss: 0.00289, consistency_loss_ema: 0.00282, total_loss: 1.672
training 392 (epoch 1): tem_loss: 1.135, pem class_loss: 0.344, pem reg_loss: 0.020, consistency_loss: 0.00303, consistency_loss_ema: 0.00297, total_loss: 1.676
training 402 (epoch 1): tem_loss: 1.136, pem class_loss: 0.346, pem reg_loss: 0.020, consistency_loss: 0.00306, consistency_loss_ema: 0.00298, total_loss: 1.679
training 412 (epoch 1): tem_loss: 1.131, pem class_loss: 0.345, pem reg_loss: 0.020, consistency_loss: 0.00300, consistency_loss_ema: 0.00294, total_loss: 1.672
training 422 (epoch 1): tem_loss: 1.133, pem class_loss: 0.343, pem reg_loss: 0.020, consistency_loss: 0.00299, consistency_loss_ema: 0.00295, total_loss: 1.671
training 432 (epoch 1): tem_loss: 1.133, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00299, consistency_loss_ema: 0.00295, total_loss: 1.670
training 442 (epoch 1): tem_loss: 1.134, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00295, consistency_loss_ema: 0.00292, total_loss: 1.670
training 452 (epoch 1): tem_loss: 1.136, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00296, consistency_loss_ema: 0.00295, total_loss: 1.670
training 462 (epoch 1): tem_loss: 1.138, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00298, consistency_loss_ema: 0.00298, total_loss: 1.673
training 472 (epoch 1): tem_loss: 1.138, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00297, consistency_loss_ema: 0.00299, total_loss: 1.675
training 482 (epoch 1): tem_loss: 1.136, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00297, consistency_loss_ema: 0.00301, total_loss: 1.667
training 492 (epoch 1): tem_loss: 1.137, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00296, consistency_loss_ema: 0.00302, total_loss: 1.669
training 502 (epoch 1): tem_loss: 1.136, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00296, consistency_loss_ema: 0.00304, total_loss: 1.667
training 512 (epoch 1): tem_loss: 1.137, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00296, consistency_loss_ema: 0.00304, total_loss: 1.671
training 522 (epoch 1): tem_loss: 1.138, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00295, consistency_loss_ema: 0.00302, total_loss: 1.674
training 532 (epoch 1): tem_loss: 1.138, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00293, consistency_loss_ema: 0.00300, total_loss: 1.675
training 542 (epoch 1): tem_loss: 1.136, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00294, consistency_loss_ema: 0.00302, total_loss: 1.674
training 552 (epoch 1): tem_loss: 1.136, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00295, consistency_loss_ema: 0.00304, total_loss: 1.672
training 562 (epoch 1): tem_loss: 1.135, pem class_loss: 0.342, pem reg_loss: 0.020, consistency_loss: 0.00299, consistency_loss_ema: 0.00306, total_loss: 1.672
training 572 (epoch 1): tem_loss: 1.135, pem class_loss: 0.342, pem reg_loss: 0.020, consistency_loss: 0.00300, consistency_loss_ema: 0.00308, total_loss: 1.672
training 582 (epoch 1): tem_loss: 1.134, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00298, consistency_loss_ema: 0.00306, total_loss: 1.669
training 592 (epoch 1): tem_loss: 1.133, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00297, consistency_loss_ema: 0.00304, total_loss: 1.667
training 602 (epoch 1): tem_loss: 1.133, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00294, consistency_loss_ema: 0.00302, total_loss: 1.669
[94mBMN training loss(epoch 1): tem_loss: 1.133, pem class_loss: 0.342, pem reg_loss: 0.019, total_loss: 1.669[0m
[94mBMN val loss(epoch 1): tem_loss: 1.156, pem class_loss: 0.362, pem reg_loss: 0.019, total_loss: 1.711[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.148, pem class_loss: 0.339, pem reg_loss: 0.019, total_loss: 1.674[0m
use Semi !!!
training 603 (epoch 2): tem_loss: 1.039, pem class_loss: 0.323, pem reg_loss: 0.019, consistency_loss: 0.00911, consistency_loss_ema: 0.01149, total_loss: 1.555
training 613 (epoch 2): tem_loss: 1.054, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.00905, consistency_loss_ema: 0.01001, total_loss: 1.538
training 623 (epoch 2): tem_loss: 1.075, pem class_loss: 0.309, pem reg_loss: 0.017, consistency_loss: 0.00897, consistency_loss_ema: 0.00945, total_loss: 1.559
training 633 (epoch 2): tem_loss: 1.079, pem class_loss: 0.316, pem reg_loss: 0.018, consistency_loss: 0.00884, consistency_loss_ema: 0.00935, total_loss: 1.572
training 643 (epoch 2): tem_loss: 1.094, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.00907, consistency_loss_ema: 0.00937, total_loss: 1.604
training 653 (epoch 2): tem_loss: 1.101, pem class_loss: 0.337, pem reg_loss: 0.019, consistency_loss: 0.00894, consistency_loss_ema: 0.00921, total_loss: 1.625
training 663 (epoch 2): tem_loss: 1.100, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00901, consistency_loss_ema: 0.00929, total_loss: 1.615
training 673 (epoch 2): tem_loss: 1.110, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00889, consistency_loss_ema: 0.00921, total_loss: 1.625
training 683 (epoch 2): tem_loss: 1.110, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00885, consistency_loss_ema: 0.00918, total_loss: 1.625
training 693 (epoch 2): tem_loss: 1.113, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00890, consistency_loss_ema: 0.00916, total_loss: 1.622
training 703 (epoch 2): tem_loss: 1.111, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00890, consistency_loss_ema: 0.00918, total_loss: 1.622
training 713 (epoch 2): tem_loss: 1.111, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00885, consistency_loss_ema: 0.00912, total_loss: 1.622
training 723 (epoch 2): tem_loss: 1.107, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00880, consistency_loss_ema: 0.00908, total_loss: 1.620
training 733 (epoch 2): tem_loss: 1.108, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00878, consistency_loss_ema: 0.00903, total_loss: 1.620
training 743 (epoch 2): tem_loss: 1.107, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00880, consistency_loss_ema: 0.00908, total_loss: 1.620
training 753 (epoch 2): tem_loss: 1.108, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00881, consistency_loss_ema: 0.00909, total_loss: 1.620
training 763 (epoch 2): tem_loss: 1.105, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00889, consistency_loss_ema: 0.00918, total_loss: 1.615
training 773 (epoch 2): tem_loss: 1.109, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00889, consistency_loss_ema: 0.00919, total_loss: 1.618
training 783 (epoch 2): tem_loss: 1.107, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.00891, consistency_loss_ema: 0.00917, total_loss: 1.613
training 793 (epoch 2): tem_loss: 1.107, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00888, consistency_loss_ema: 0.00915, total_loss: 1.614
training 803 (epoch 2): tem_loss: 1.109, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00890, consistency_loss_ema: 0.00920, total_loss: 1.619
training 813 (epoch 2): tem_loss: 1.108, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00892, consistency_loss_ema: 0.00918, total_loss: 1.619
training 823 (epoch 2): tem_loss: 1.109, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00893, consistency_loss_ema: 0.00925, total_loss: 1.620
training 833 (epoch 2): tem_loss: 1.109, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00901, consistency_loss_ema: 0.00934, total_loss: 1.620
training 843 (epoch 2): tem_loss: 1.108, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00901, consistency_loss_ema: 0.00934, total_loss: 1.617
training 853 (epoch 2): tem_loss: 1.108, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00898, consistency_loss_ema: 0.00931, total_loss: 1.617
training 863 (epoch 2): tem_loss: 1.107, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00894, consistency_loss_ema: 0.00927, total_loss: 1.615
training 873 (epoch 2): tem_loss: 1.106, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00891, consistency_loss_ema: 0.00926, total_loss: 1.614
training 883 (epoch 2): tem_loss: 1.105, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00890, consistency_loss_ema: 0.00924, total_loss: 1.612
training 893 (epoch 2): tem_loss: 1.104, pem class_loss: 0.327, pem reg_loss: 0.018, consistency_loss: 0.00892, consistency_loss_ema: 0.00927, total_loss: 1.610
training 903 (epoch 2): tem_loss: 1.104, pem class_loss: 0.326, pem reg_loss: 0.018, consistency_loss: 0.00894, consistency_loss_ema: 0.00932, total_loss: 1.608
[94mBMN training loss(epoch 2): tem_loss: 1.104, pem class_loss: 0.326, pem reg_loss: 0.018, total_loss: 1.608[0m
[94mBMN val loss(epoch 2): tem_loss: 1.150, pem class_loss: 0.362, pem reg_loss: 0.018, total_loss: 1.688[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.140, pem class_loss: 0.330, pem reg_loss: 0.017, total_loss: 1.644[0m
use Semi !!!
training 904 (epoch 3): tem_loss: 1.016, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.03221, consistency_loss_ema: 0.03593, total_loss: 1.422
training 914 (epoch 3): tem_loss: 1.071, pem class_loss: 0.312, pem reg_loss: 0.015, consistency_loss: 0.02474, consistency_loss_ema: 0.02470, total_loss: 1.534
training 924 (epoch 3): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02247, consistency_loss_ema: 0.02196, total_loss: 1.539
training 934 (epoch 3): tem_loss: 1.073, pem class_loss: 0.301, pem reg_loss: 0.016, consistency_loss: 0.02022, consistency_loss_ema: 0.02048, total_loss: 1.531
training 944 (epoch 3): tem_loss: 1.074, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.01979, consistency_loss_ema: 0.01992, total_loss: 1.534
training 954 (epoch 3): tem_loss: 1.082, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.01948, consistency_loss_ema: 0.02011, total_loss: 1.552
training 964 (epoch 3): tem_loss: 1.088, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01964, consistency_loss_ema: 0.02020, total_loss: 1.570
training 974 (epoch 3): tem_loss: 1.085, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01981, consistency_loss_ema: 0.02024, total_loss: 1.568
training 984 (epoch 3): tem_loss: 1.087, pem class_loss: 0.308, pem reg_loss: 0.017, consistency_loss: 0.01963, consistency_loss_ema: 0.02016, total_loss: 1.563
training 994 (epoch 3): tem_loss: 1.083, pem class_loss: 0.308, pem reg_loss: 0.017, consistency_loss: 0.01960, consistency_loss_ema: 0.02010, total_loss: 1.558
training 1004 (epoch 3): tem_loss: 1.085, pem class_loss: 0.308, pem reg_loss: 0.017, consistency_loss: 0.01941, consistency_loss_ema: 0.01991, total_loss: 1.561
training 1014 (epoch 3): tem_loss: 1.084, pem class_loss: 0.309, pem reg_loss: 0.017, consistency_loss: 0.01912, consistency_loss_ema: 0.01969, total_loss: 1.560
training 1024 (epoch 3): tem_loss: 1.083, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.01888, consistency_loss_ema: 0.01939, total_loss: 1.562
training 1034 (epoch 3): tem_loss: 1.087, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.01889, consistency_loss_ema: 0.01939, total_loss: 1.566
training 1044 (epoch 3): tem_loss: 1.090, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.01896, consistency_loss_ema: 0.01941, total_loss: 1.572
training 1054 (epoch 3): tem_loss: 1.092, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.01878, consistency_loss_ema: 0.01927, total_loss: 1.577
training 1064 (epoch 3): tem_loss: 1.091, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01880, consistency_loss_ema: 0.01921, total_loss: 1.575
training 1074 (epoch 3): tem_loss: 1.090, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01877, consistency_loss_ema: 0.01923, total_loss: 1.575
training 1084 (epoch 3): tem_loss: 1.091, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01874, consistency_loss_ema: 0.01916, total_loss: 1.575
training 1094 (epoch 3): tem_loss: 1.090, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01864, consistency_loss_ema: 0.01906, total_loss: 1.574
training 1104 (epoch 3): tem_loss: 1.091, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01867, consistency_loss_ema: 0.01905, total_loss: 1.574
training 1114 (epoch 3): tem_loss: 1.090, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01864, consistency_loss_ema: 0.01902, total_loss: 1.570
training 1124 (epoch 3): tem_loss: 1.089, pem class_loss: 0.313, pem reg_loss: 0.017, consistency_loss: 0.01856, consistency_loss_ema: 0.01900, total_loss: 1.569
training 1134 (epoch 3): tem_loss: 1.089, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.01849, consistency_loss_ema: 0.01901, total_loss: 1.566
training 1144 (epoch 3): tem_loss: 1.090, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01843, consistency_loss_ema: 0.01897, total_loss: 1.568
training 1154 (epoch 3): tem_loss: 1.090, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01840, consistency_loss_ema: 0.01889, total_loss: 1.569
training 1164 (epoch 3): tem_loss: 1.091, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01842, consistency_loss_ema: 0.01884, total_loss: 1.569
training 1174 (epoch 3): tem_loss: 1.089, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01834, consistency_loss_ema: 0.01881, total_loss: 1.567
training 1184 (epoch 3): tem_loss: 1.091, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01823, consistency_loss_ema: 0.01870, total_loss: 1.569
training 1194 (epoch 3): tem_loss: 1.092, pem class_loss: 0.313, pem reg_loss: 0.017, consistency_loss: 0.01818, consistency_loss_ema: 0.01867, total_loss: 1.571
training 1204 (epoch 3): tem_loss: 1.092, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01816, consistency_loss_ema: 0.01865, total_loss: 1.571
[94mBMN training loss(epoch 3): tem_loss: 1.092, pem class_loss: 0.312, pem reg_loss: 0.017, total_loss: 1.571[0m
[94mBMN val loss(epoch 3): tem_loss: 1.147, pem class_loss: 0.326, pem reg_loss: 0.017, total_loss: 1.641[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.144, pem class_loss: 0.326, pem reg_loss: 0.017, total_loss: 1.638[0m
use Semi !!!
training 1205 (epoch 4): tem_loss: 1.100, pem class_loss: 0.247, pem reg_loss: 0.012, consistency_loss: 0.03464, consistency_loss_ema: 0.03305, total_loss: 1.469
training 1215 (epoch 4): tem_loss: 1.077, pem class_loss: 0.326, pem reg_loss: 0.016, consistency_loss: 0.02906, consistency_loss_ema: 0.02859, total_loss: 1.563
training 1225 (epoch 4): tem_loss: 1.077, pem class_loss: 0.311, pem reg_loss: 0.015, consistency_loss: 0.03051, consistency_loss_ema: 0.03019, total_loss: 1.543
training 1235 (epoch 4): tem_loss: 1.077, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02847, consistency_loss_ema: 0.02894, total_loss: 1.525
training 1245 (epoch 4): tem_loss: 1.077, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02817, consistency_loss_ema: 0.02875, total_loss: 1.524
training 1255 (epoch 4): tem_loss: 1.079, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02774, consistency_loss_ema: 0.02851, total_loss: 1.528
training 1265 (epoch 4): tem_loss: 1.078, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02754, consistency_loss_ema: 0.02838, total_loss: 1.536
training 1275 (epoch 4): tem_loss: 1.074, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02770, consistency_loss_ema: 0.02859, total_loss: 1.527
training 1285 (epoch 4): tem_loss: 1.074, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02747, consistency_loss_ema: 0.02811, total_loss: 1.525
training 1295 (epoch 4): tem_loss: 1.073, pem class_loss: 0.296, pem reg_loss: 0.016, consistency_loss: 0.02732, consistency_loss_ema: 0.02824, total_loss: 1.525
training 1305 (epoch 4): tem_loss: 1.081, pem class_loss: 0.298, pem reg_loss: 0.016, consistency_loss: 0.02709, consistency_loss_ema: 0.02837, total_loss: 1.535
training 1315 (epoch 4): tem_loss: 1.082, pem class_loss: 0.299, pem reg_loss: 0.016, consistency_loss: 0.02710, consistency_loss_ema: 0.02831, total_loss: 1.538
training 1325 (epoch 4): tem_loss: 1.081, pem class_loss: 0.298, pem reg_loss: 0.016, consistency_loss: 0.02709, consistency_loss_ema: 0.02801, total_loss: 1.536
training 1335 (epoch 4): tem_loss: 1.083, pem class_loss: 0.299, pem reg_loss: 0.016, consistency_loss: 0.02696, consistency_loss_ema: 0.02810, total_loss: 1.539
training 1345 (epoch 4): tem_loss: 1.087, pem class_loss: 0.298, pem reg_loss: 0.016, consistency_loss: 0.02683, consistency_loss_ema: 0.02804, total_loss: 1.541
training 1355 (epoch 4): tem_loss: 1.089, pem class_loss: 0.299, pem reg_loss: 0.016, consistency_loss: 0.02683, consistency_loss_ema: 0.02799, total_loss: 1.544
training 1365 (epoch 4): tem_loss: 1.089, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02664, consistency_loss_ema: 0.02788, total_loss: 1.546
training 1375 (epoch 4): tem_loss: 1.090, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02663, consistency_loss_ema: 0.02777, total_loss: 1.548
training 1385 (epoch 4): tem_loss: 1.091, pem class_loss: 0.301, pem reg_loss: 0.016, consistency_loss: 0.02666, consistency_loss_ema: 0.02772, total_loss: 1.551
training 1395 (epoch 4): tem_loss: 1.092, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02654, consistency_loss_ema: 0.02766, total_loss: 1.550
training 1405 (epoch 4): tem_loss: 1.091, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02638, consistency_loss_ema: 0.02744, total_loss: 1.549
training 1415 (epoch 4): tem_loss: 1.092, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02622, consistency_loss_ema: 0.02727, total_loss: 1.549
training 1425 (epoch 4): tem_loss: 1.091, pem class_loss: 0.301, pem reg_loss: 0.016, consistency_loss: 0.02606, consistency_loss_ema: 0.02711, total_loss: 1.550
training 1435 (epoch 4): tem_loss: 1.093, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02602, consistency_loss_ema: 0.02703, total_loss: 1.554
training 1445 (epoch 4): tem_loss: 1.092, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02593, consistency_loss_ema: 0.02693, total_loss: 1.553
training 1455 (epoch 4): tem_loss: 1.093, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02588, consistency_loss_ema: 0.02694, total_loss: 1.553
training 1465 (epoch 4): tem_loss: 1.092, pem class_loss: 0.301, pem reg_loss: 0.016, consistency_loss: 0.02588, consistency_loss_ema: 0.02687, total_loss: 1.551
training 1475 (epoch 4): tem_loss: 1.093, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02579, consistency_loss_ema: 0.02679, total_loss: 1.552
training 1485 (epoch 4): tem_loss: 1.094, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02573, consistency_loss_ema: 0.02673, total_loss: 1.554
training 1495 (epoch 4): tem_loss: 1.094, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02574, consistency_loss_ema: 0.02678, total_loss: 1.553
training 1505 (epoch 4): tem_loss: 1.094, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02574, consistency_loss_ema: 0.02672, total_loss: 1.554
[94mBMN training loss(epoch 4): tem_loss: 1.094, pem class_loss: 0.302, pem reg_loss: 0.016, total_loss: 1.554[0m
[94mBMN val loss(epoch 4): tem_loss: 1.153, pem class_loss: 0.326, pem reg_loss: 0.016, total_loss: 1.642[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.152, pem class_loss: 0.323, pem reg_loss: 0.016, total_loss: 1.639[0m
use Semi !!!
training 1506 (epoch 5): tem_loss: 1.098, pem class_loss: 0.233, pem reg_loss: 0.013, consistency_loss: 0.03939, consistency_loss_ema: 0.02982, total_loss: 1.461
training 1516 (epoch 5): tem_loss: 1.124, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.02868, consistency_loss_ema: 0.02996, total_loss: 1.546
training 1526 (epoch 5): tem_loss: 1.088, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.02850, consistency_loss_ema: 0.02927, total_loss: 1.492
training 1536 (epoch 5): tem_loss: 1.107, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02918, consistency_loss_ema: 0.03012, total_loss: 1.526
training 1546 (epoch 5): tem_loss: 1.107, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02964, consistency_loss_ema: 0.02995, total_loss: 1.539
training 1556 (epoch 5): tem_loss: 1.105, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02872, consistency_loss_ema: 0.02965, total_loss: 1.549
training 1566 (epoch 5): tem_loss: 1.101, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02864, consistency_loss_ema: 0.02954, total_loss: 1.541
training 1576 (epoch 5): tem_loss: 1.097, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02867, consistency_loss_ema: 0.02966, total_loss: 1.540
training 1586 (epoch 5): tem_loss: 1.099, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02865, consistency_loss_ema: 0.02967, total_loss: 1.543
training 1596 (epoch 5): tem_loss: 1.094, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02875, consistency_loss_ema: 0.02995, total_loss: 1.541
training 1606 (epoch 5): tem_loss: 1.094, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02878, consistency_loss_ema: 0.02993, total_loss: 1.546
training 1616 (epoch 5): tem_loss: 1.096, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02855, consistency_loss_ema: 0.02980, total_loss: 1.548
training 1626 (epoch 5): tem_loss: 1.093, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02843, consistency_loss_ema: 0.02975, total_loss: 1.543
training 1636 (epoch 5): tem_loss: 1.094, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02857, consistency_loss_ema: 0.02973, total_loss: 1.543
training 1646 (epoch 5): tem_loss: 1.092, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02864, consistency_loss_ema: 0.02985, total_loss: 1.540
training 1656 (epoch 5): tem_loss: 1.091, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02860, consistency_loss_ema: 0.02987, total_loss: 1.536
training 1666 (epoch 5): tem_loss: 1.091, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02847, consistency_loss_ema: 0.02981, total_loss: 1.536
training 1676 (epoch 5): tem_loss: 1.093, pem class_loss: 0.291, pem reg_loss: 0.015, consistency_loss: 0.02843, consistency_loss_ema: 0.02967, total_loss: 1.536
training 1686 (epoch 5): tem_loss: 1.091, pem class_loss: 0.290, pem reg_loss: 0.015, consistency_loss: 0.02848, consistency_loss_ema: 0.02970, total_loss: 1.533
training 1696 (epoch 5): tem_loss: 1.093, pem class_loss: 0.291, pem reg_loss: 0.015, consistency_loss: 0.02844, consistency_loss_ema: 0.02968, total_loss: 1.537
training 1706 (epoch 5): tem_loss: 1.093, pem class_loss: 0.291, pem reg_loss: 0.015, consistency_loss: 0.02839, consistency_loss_ema: 0.02962, total_loss: 1.536
training 1716 (epoch 5): tem_loss: 1.094, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02837, consistency_loss_ema: 0.02949, total_loss: 1.538
training 1726 (epoch 5): tem_loss: 1.096, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02835, consistency_loss_ema: 0.02943, total_loss: 1.541
training 1736 (epoch 5): tem_loss: 1.094, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02830, consistency_loss_ema: 0.02946, total_loss: 1.539
training 1746 (epoch 5): tem_loss: 1.094, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02824, consistency_loss_ema: 0.02944, total_loss: 1.539
training 1756 (epoch 5): tem_loss: 1.094, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02817, consistency_loss_ema: 0.02944, total_loss: 1.539
training 1766 (epoch 5): tem_loss: 1.096, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02810, consistency_loss_ema: 0.02940, total_loss: 1.540
training 1776 (epoch 5): tem_loss: 1.096, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02808, consistency_loss_ema: 0.02931, total_loss: 1.541
training 1786 (epoch 5): tem_loss: 1.097, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02804, consistency_loss_ema: 0.02942, total_loss: 1.541
training 1796 (epoch 5): tem_loss: 1.096, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02804, consistency_loss_ema: 0.02942, total_loss: 1.540
training 1806 (epoch 5): tem_loss: 1.097, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02802, consistency_loss_ema: 0.02942, total_loss: 1.540
[94mBMN training loss(epoch 5): tem_loss: 1.097, pem class_loss: 0.293, pem reg_loss: 0.015, total_loss: 1.540[0m
[94mBMN val loss(epoch 5): tem_loss: 1.161, pem class_loss: 0.325, pem reg_loss: 0.016, total_loss: 1.647[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.156, pem class_loss: 0.321, pem reg_loss: 0.016, total_loss: 1.636[0m
use Semi !!!
training 1807 (epoch 6): tem_loss: 1.139, pem class_loss: 0.269, pem reg_loss: 0.014, consistency_loss: 0.02969, consistency_loss_ema: 0.02282, total_loss: 1.544
training 1817 (epoch 6): tem_loss: 1.094, pem class_loss: 0.265, pem reg_loss: 0.014, consistency_loss: 0.02810, consistency_loss_ema: 0.02985, total_loss: 1.497
training 1827 (epoch 6): tem_loss: 1.088, pem class_loss: 0.274, pem reg_loss: 0.015, consistency_loss: 0.02792, consistency_loss_ema: 0.02948, total_loss: 1.512
training 1837 (epoch 6): tem_loss: 1.077, pem class_loss: 0.276, pem reg_loss: 0.015, consistency_loss: 0.02792, consistency_loss_ema: 0.02984, total_loss: 1.500
training 1847 (epoch 6): tem_loss: 1.066, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.02783, consistency_loss_ema: 0.02909, total_loss: 1.481
training 1857 (epoch 6): tem_loss: 1.064, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.02798, consistency_loss_ema: 0.02937, total_loss: 1.477
training 1867 (epoch 6): tem_loss: 1.075, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.02777, consistency_loss_ema: 0.02938, total_loss: 1.491
training 1877 (epoch 6): tem_loss: 1.076, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02791, consistency_loss_ema: 0.02936, total_loss: 1.491
training 1887 (epoch 6): tem_loss: 1.078, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02764, consistency_loss_ema: 0.02913, total_loss: 1.499
training 1897 (epoch 6): tem_loss: 1.082, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02759, consistency_loss_ema: 0.02914, total_loss: 1.502
training 1907 (epoch 6): tem_loss: 1.081, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02784, consistency_loss_ema: 0.02915, total_loss: 1.502
training 1917 (epoch 6): tem_loss: 1.080, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.02761, consistency_loss_ema: 0.02907, total_loss: 1.498
training 1927 (epoch 6): tem_loss: 1.081, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.02762, consistency_loss_ema: 0.02881, total_loss: 1.499
training 1937 (epoch 6): tem_loss: 1.081, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02759, consistency_loss_ema: 0.02883, total_loss: 1.501
training 1947 (epoch 6): tem_loss: 1.080, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02754, consistency_loss_ema: 0.02879, total_loss: 1.496
training 1957 (epoch 6): tem_loss: 1.080, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02753, consistency_loss_ema: 0.02870, total_loss: 1.494
training 1967 (epoch 6): tem_loss: 1.079, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.02751, consistency_loss_ema: 0.02867, total_loss: 1.496
training 1977 (epoch 6): tem_loss: 1.081, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02761, consistency_loss_ema: 0.02880, total_loss: 1.501
training 1987 (epoch 6): tem_loss: 1.082, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02773, consistency_loss_ema: 0.02895, total_loss: 1.502
training 1997 (epoch 6): tem_loss: 1.081, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02769, consistency_loss_ema: 0.02891, total_loss: 1.501
training 2007 (epoch 6): tem_loss: 1.084, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02798, consistency_loss_ema: 0.02904, total_loss: 1.503
training 2017 (epoch 6): tem_loss: 1.086, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02808, consistency_loss_ema: 0.02923, total_loss: 1.506
training 2027 (epoch 6): tem_loss: 1.085, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02822, consistency_loss_ema: 0.02937, total_loss: 1.508
training 2037 (epoch 6): tem_loss: 1.086, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02822, consistency_loss_ema: 0.02942, total_loss: 1.509
training 2047 (epoch 6): tem_loss: 1.087, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02829, consistency_loss_ema: 0.02946, total_loss: 1.509
training 2057 (epoch 6): tem_loss: 1.089, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.02828, consistency_loss_ema: 0.02948, total_loss: 1.514
training 2067 (epoch 6): tem_loss: 1.089, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.02832, consistency_loss_ema: 0.02956, total_loss: 1.515
training 2077 (epoch 6): tem_loss: 1.090, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.02840, consistency_loss_ema: 0.02963, total_loss: 1.518
training 2087 (epoch 6): tem_loss: 1.091, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.02835, consistency_loss_ema: 0.02964, total_loss: 1.519
training 2097 (epoch 6): tem_loss: 1.091, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.02832, consistency_loss_ema: 0.02967, total_loss: 1.521
training 2107 (epoch 6): tem_loss: 1.093, pem class_loss: 0.286, pem reg_loss: 0.015, consistency_loss: 0.02821, consistency_loss_ema: 0.02960, total_loss: 1.524
[94mBMN training loss(epoch 6): tem_loss: 1.093, pem class_loss: 0.286, pem reg_loss: 0.015, total_loss: 1.524[0m
[94mBMN val loss(epoch 6): tem_loss: 1.159, pem class_loss: 0.324, pem reg_loss: 0.016, total_loss: 1.644[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.157, pem class_loss: 0.322, pem reg_loss: 0.016, total_loss: 1.636[0m
use Semi !!!
training 2108 (epoch 7): tem_loss: 1.054, pem class_loss: 0.331, pem reg_loss: 0.016, consistency_loss: 0.02649, consistency_loss_ema: 0.03253, total_loss: 1.542
training 2118 (epoch 7): tem_loss: 1.111, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02646, consistency_loss_ema: 0.02770, total_loss: 1.560
training 2128 (epoch 7): tem_loss: 1.090, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02445, consistency_loss_ema: 0.02590, total_loss: 1.506
training 2138 (epoch 7): tem_loss: 1.086, pem class_loss: 0.266, pem reg_loss: 0.013, consistency_loss: 0.02326, consistency_loss_ema: 0.02580, total_loss: 1.483
training 2148 (epoch 7): tem_loss: 1.079, pem class_loss: 0.266, pem reg_loss: 0.013, consistency_loss: 0.02243, consistency_loss_ema: 0.02515, total_loss: 1.479
training 2158 (epoch 7): tem_loss: 1.084, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.02191, consistency_loss_ema: 0.02386, total_loss: 1.487
training 2168 (epoch 7): tem_loss: 1.090, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.02133, consistency_loss_ema: 0.02333, total_loss: 1.493
training 2178 (epoch 7): tem_loss: 1.092, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.02097, consistency_loss_ema: 0.02292, total_loss: 1.498
training 2188 (epoch 7): tem_loss: 1.089, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.02064, consistency_loss_ema: 0.02259, total_loss: 1.498
training 2198 (epoch 7): tem_loss: 1.087, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.02050, consistency_loss_ema: 0.02244, total_loss: 1.494
training 2208 (epoch 7): tem_loss: 1.087, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.02031, consistency_loss_ema: 0.02233, total_loss: 1.492
training 2218 (epoch 7): tem_loss: 1.086, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.02013, consistency_loss_ema: 0.02210, total_loss: 1.490
training 2228 (epoch 7): tem_loss: 1.085, pem class_loss: 0.269, pem reg_loss: 0.013, consistency_loss: 0.01999, consistency_loss_ema: 0.02200, total_loss: 1.488
training 2238 (epoch 7): tem_loss: 1.082, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01996, consistency_loss_ema: 0.02188, total_loss: 1.487
training 2248 (epoch 7): tem_loss: 1.080, pem class_loss: 0.269, pem reg_loss: 0.013, consistency_loss: 0.01988, consistency_loss_ema: 0.02174, total_loss: 1.484
training 2258 (epoch 7): tem_loss: 1.082, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01982, consistency_loss_ema: 0.02158, total_loss: 1.487
training 2268 (epoch 7): tem_loss: 1.081, pem class_loss: 0.269, pem reg_loss: 0.013, consistency_loss: 0.01975, consistency_loss_ema: 0.02151, total_loss: 1.485
training 2278 (epoch 7): tem_loss: 1.084, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01971, consistency_loss_ema: 0.02153, total_loss: 1.489
training 2288 (epoch 7): tem_loss: 1.084, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01962, consistency_loss_ema: 0.02138, total_loss: 1.489
training 2298 (epoch 7): tem_loss: 1.084, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01959, consistency_loss_ema: 0.02128, total_loss: 1.490
training 2308 (epoch 7): tem_loss: 1.083, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01960, consistency_loss_ema: 0.02124, total_loss: 1.487
training 2318 (epoch 7): tem_loss: 1.083, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01955, consistency_loss_ema: 0.02124, total_loss: 1.488
training 2328 (epoch 7): tem_loss: 1.083, pem class_loss: 0.269, pem reg_loss: 0.013, consistency_loss: 0.01948, consistency_loss_ema: 0.02121, total_loss: 1.487
training 2338 (epoch 7): tem_loss: 1.082, pem class_loss: 0.269, pem reg_loss: 0.014, consistency_loss: 0.01950, consistency_loss_ema: 0.02118, total_loss: 1.487
training 2348 (epoch 7): tem_loss: 1.081, pem class_loss: 0.269, pem reg_loss: 0.014, consistency_loss: 0.01945, consistency_loss_ema: 0.02115, total_loss: 1.485
training 2358 (epoch 7): tem_loss: 1.081, pem class_loss: 0.269, pem reg_loss: 0.014, consistency_loss: 0.01945, consistency_loss_ema: 0.02110, total_loss: 1.486
training 2368 (epoch 7): tem_loss: 1.081, pem class_loss: 0.268, pem reg_loss: 0.014, consistency_loss: 0.01944, consistency_loss_ema: 0.02113, total_loss: 1.485
training 2378 (epoch 7): tem_loss: 1.081, pem class_loss: 0.268, pem reg_loss: 0.014, consistency_loss: 0.01937, consistency_loss_ema: 0.02116, total_loss: 1.485
training 2388 (epoch 7): tem_loss: 1.081, pem class_loss: 0.267, pem reg_loss: 0.014, consistency_loss: 0.01935, consistency_loss_ema: 0.02113, total_loss: 1.483
training 2398 (epoch 7): tem_loss: 1.080, pem class_loss: 0.268, pem reg_loss: 0.013, consistency_loss: 0.01938, consistency_loss_ema: 0.02112, total_loss: 1.482
training 2408 (epoch 7): tem_loss: 1.081, pem class_loss: 0.267, pem reg_loss: 0.013, consistency_loss: 0.01939, consistency_loss_ema: 0.02112, total_loss: 1.482
[94mBMN training loss(epoch 7): tem_loss: 1.081, pem class_loss: 0.267, pem reg_loss: 0.013, total_loss: 1.482[0m
[94mBMN val loss(epoch 7): tem_loss: 1.156, pem class_loss: 0.330, pem reg_loss: 0.016, total_loss: 1.641[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.157, pem class_loss: 0.327, pem reg_loss: 0.016, total_loss: 1.639[0m
use Semi !!!
training 2409 (epoch 8): tem_loss: 1.031, pem class_loss: 0.263, pem reg_loss: 0.015, consistency_loss: 0.01390, consistency_loss_ema: 0.01884, total_loss: 1.439
training 2419 (epoch 8): tem_loss: 1.102, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.01822, consistency_loss_ema: 0.02196, total_loss: 1.514
training 2429 (epoch 8): tem_loss: 1.087, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01900, consistency_loss_ema: 0.02183, total_loss: 1.490
training 2439 (epoch 8): tem_loss: 1.080, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.01863, consistency_loss_ema: 0.02136, total_loss: 1.487
training 2449 (epoch 8): tem_loss: 1.086, pem class_loss: 0.269, pem reg_loss: 0.013, consistency_loss: 0.01910, consistency_loss_ema: 0.02131, total_loss: 1.488
training 2459 (epoch 8): tem_loss: 1.085, pem class_loss: 0.268, pem reg_loss: 0.013, consistency_loss: 0.01912, consistency_loss_ema: 0.02133, total_loss: 1.486
training 2469 (epoch 8): tem_loss: 1.080, pem class_loss: 0.267, pem reg_loss: 0.013, consistency_loss: 0.01932, consistency_loss_ema: 0.02131, total_loss: 1.479
training 2479 (epoch 8): tem_loss: 1.080, pem class_loss: 0.269, pem reg_loss: 0.013, consistency_loss: 0.01941, consistency_loss_ema: 0.02136, total_loss: 1.483
training 2489 (epoch 8): tem_loss: 1.080, pem class_loss: 0.265, pem reg_loss: 0.013, consistency_loss: 0.01955, consistency_loss_ema: 0.02137, total_loss: 1.478
training 2499 (epoch 8): tem_loss: 1.075, pem class_loss: 0.261, pem reg_loss: 0.013, consistency_loss: 0.01975, consistency_loss_ema: 0.02146, total_loss: 1.467
training 2509 (epoch 8): tem_loss: 1.072, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.01980, consistency_loss_ema: 0.02148, total_loss: 1.462
training 2519 (epoch 8): tem_loss: 1.067, pem class_loss: 0.257, pem reg_loss: 0.013, consistency_loss: 0.01983, consistency_loss_ema: 0.02160, total_loss: 1.453
training 2529 (epoch 8): tem_loss: 1.064, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.01993, consistency_loss_ema: 0.02157, total_loss: 1.445
training 2539 (epoch 8): tem_loss: 1.064, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02006, consistency_loss_ema: 0.02156, total_loss: 1.447
training 2549 (epoch 8): tem_loss: 1.065, pem class_loss: 0.255, pem reg_loss: 0.013, consistency_loss: 0.02013, consistency_loss_ema: 0.02156, total_loss: 1.449
training 2559 (epoch 8): tem_loss: 1.065, pem class_loss: 0.255, pem reg_loss: 0.013, consistency_loss: 0.02008, consistency_loss_ema: 0.02156, total_loss: 1.449
training 2569 (epoch 8): tem_loss: 1.064, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02015, consistency_loss_ema: 0.02156, total_loss: 1.446
training 2579 (epoch 8): tem_loss: 1.066, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02014, consistency_loss_ema: 0.02147, total_loss: 1.449
training 2589 (epoch 8): tem_loss: 1.067, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02015, consistency_loss_ema: 0.02160, total_loss: 1.455
training 2599 (epoch 8): tem_loss: 1.067, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02022, consistency_loss_ema: 0.02167, total_loss: 1.454
training 2609 (epoch 8): tem_loss: 1.067, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02024, consistency_loss_ema: 0.02179, total_loss: 1.455
training 2619 (epoch 8): tem_loss: 1.069, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.02023, consistency_loss_ema: 0.02180, total_loss: 1.460
training 2629 (epoch 8): tem_loss: 1.072, pem class_loss: 0.261, pem reg_loss: 0.013, consistency_loss: 0.02023, consistency_loss_ema: 0.02174, total_loss: 1.465
training 2639 (epoch 8): tem_loss: 1.073, pem class_loss: 0.262, pem reg_loss: 0.013, consistency_loss: 0.02030, consistency_loss_ema: 0.02173, total_loss: 1.466
training 2649 (epoch 8): tem_loss: 1.073, pem class_loss: 0.261, pem reg_loss: 0.013, consistency_loss: 0.02035, consistency_loss_ema: 0.02177, total_loss: 1.464
training 2659 (epoch 8): tem_loss: 1.073, pem class_loss: 0.261, pem reg_loss: 0.013, consistency_loss: 0.02038, consistency_loss_ema: 0.02174, total_loss: 1.465
training 2669 (epoch 8): tem_loss: 1.074, pem class_loss: 0.261, pem reg_loss: 0.013, consistency_loss: 0.02036, consistency_loss_ema: 0.02179, total_loss: 1.466
training 2679 (epoch 8): tem_loss: 1.073, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.02035, consistency_loss_ema: 0.02180, total_loss: 1.464
training 2689 (epoch 8): tem_loss: 1.073, pem class_loss: 0.261, pem reg_loss: 0.013, consistency_loss: 0.02040, consistency_loss_ema: 0.02182, total_loss: 1.464
training 2699 (epoch 8): tem_loss: 1.073, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.02039, consistency_loss_ema: 0.02185, total_loss: 1.464
training 2709 (epoch 8): tem_loss: 1.072, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.02042, consistency_loss_ema: 0.02191, total_loss: 1.464
[94mBMN training loss(epoch 8): tem_loss: 1.072, pem class_loss: 0.260, pem reg_loss: 0.013, total_loss: 1.464[0m
[94mBMN val loss(epoch 8): tem_loss: 1.154, pem class_loss: 0.329, pem reg_loss: 0.016, total_loss: 1.639[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.156, pem class_loss: 0.332, pem reg_loss: 0.016, total_loss: 1.644[0m
use Semi !!!
training 2710 (epoch 9): tem_loss: 0.962, pem class_loss: 0.219, pem reg_loss: 0.010, consistency_loss: 0.01607, consistency_loss_ema: 0.02294, total_loss: 1.282
training 2720 (epoch 9): tem_loss: 1.072, pem class_loss: 0.255, pem reg_loss: 0.012, consistency_loss: 0.02004, consistency_loss_ema: 0.02288, total_loss: 1.445
training 2730 (epoch 9): tem_loss: 1.077, pem class_loss: 0.256, pem reg_loss: 0.012, consistency_loss: 0.02069, consistency_loss_ema: 0.02326, total_loss: 1.457
training 2740 (epoch 9): tem_loss: 1.078, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02116, consistency_loss_ema: 0.02297, total_loss: 1.464
training 2750 (epoch 9): tem_loss: 1.077, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02079, consistency_loss_ema: 0.02294, total_loss: 1.466
training 2760 (epoch 9): tem_loss: 1.076, pem class_loss: 0.255, pem reg_loss: 0.013, consistency_loss: 0.02070, consistency_loss_ema: 0.02303, total_loss: 1.464
training 2770 (epoch 9): tem_loss: 1.076, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02078, consistency_loss_ema: 0.02300, total_loss: 1.466
training 2780 (epoch 9): tem_loss: 1.073, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02104, consistency_loss_ema: 0.02335, total_loss: 1.462
training 2790 (epoch 9): tem_loss: 1.075, pem class_loss: 0.259, pem reg_loss: 0.013, consistency_loss: 0.02085, consistency_loss_ema: 0.02326, total_loss: 1.464
training 2800 (epoch 9): tem_loss: 1.076, pem class_loss: 0.259, pem reg_loss: 0.013, consistency_loss: 0.02084, consistency_loss_ema: 0.02332, total_loss: 1.465
training 2810 (epoch 9): tem_loss: 1.075, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.02096, consistency_loss_ema: 0.02356, total_loss: 1.466
training 2820 (epoch 9): tem_loss: 1.074, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.02092, consistency_loss_ema: 0.02338, total_loss: 1.463
training 2830 (epoch 9): tem_loss: 1.077, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02099, consistency_loss_ema: 0.02337, total_loss: 1.464
training 2840 (epoch 9): tem_loss: 1.078, pem class_loss: 0.260, pem reg_loss: 0.013, consistency_loss: 0.02101, consistency_loss_ema: 0.02346, total_loss: 1.467
training 2850 (epoch 9): tem_loss: 1.077, pem class_loss: 0.259, pem reg_loss: 0.013, consistency_loss: 0.02108, consistency_loss_ema: 0.02351, total_loss: 1.465
training 2860 (epoch 9): tem_loss: 1.077, pem class_loss: 0.257, pem reg_loss: 0.013, consistency_loss: 0.02111, consistency_loss_ema: 0.02348, total_loss: 1.464
training 2870 (epoch 9): tem_loss: 1.078, pem class_loss: 0.258, pem reg_loss: 0.013, consistency_loss: 0.02110, consistency_loss_ema: 0.02353, total_loss: 1.465
training 2880 (epoch 9): tem_loss: 1.074, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02109, consistency_loss_ema: 0.02359, total_loss: 1.457
training 2890 (epoch 9): tem_loss: 1.074, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02114, consistency_loss_ema: 0.02352, total_loss: 1.459
training 2900 (epoch 9): tem_loss: 1.076, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02120, consistency_loss_ema: 0.02350, total_loss: 1.461
training 2910 (epoch 9): tem_loss: 1.074, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02123, consistency_loss_ema: 0.02350, total_loss: 1.458
training 2920 (epoch 9): tem_loss: 1.073, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02122, consistency_loss_ema: 0.02343, total_loss: 1.455
training 2930 (epoch 9): tem_loss: 1.073, pem class_loss: 0.255, pem reg_loss: 0.013, consistency_loss: 0.02125, consistency_loss_ema: 0.02347, total_loss: 1.456
training 2940 (epoch 9): tem_loss: 1.073, pem class_loss: 0.255, pem reg_loss: 0.013, consistency_loss: 0.02126, consistency_loss_ema: 0.02346, total_loss: 1.455
training 2950 (epoch 9): tem_loss: 1.073, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02132, consistency_loss_ema: 0.02349, total_loss: 1.454
training 2960 (epoch 9): tem_loss: 1.072, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02131, consistency_loss_ema: 0.02357, total_loss: 1.453
training 2970 (epoch 9): tem_loss: 1.072, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02136, consistency_loss_ema: 0.02355, total_loss: 1.454
training 2980 (epoch 9): tem_loss: 1.072, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02145, consistency_loss_ema: 0.02354, total_loss: 1.453
training 2990 (epoch 9): tem_loss: 1.072, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02147, consistency_loss_ema: 0.02357, total_loss: 1.453
training 3000 (epoch 9): tem_loss: 1.072, pem class_loss: 0.255, pem reg_loss: 0.013, consistency_loss: 0.02154, consistency_loss_ema: 0.02358, total_loss: 1.455
training 3010 (epoch 9): tem_loss: 1.071, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02162, consistency_loss_ema: 0.02360, total_loss: 1.453
[94mBMN training loss(epoch 9): tem_loss: 1.071, pem class_loss: 0.254, pem reg_loss: 0.013, total_loss: 1.453[0m
[94mBMN val loss(epoch 9): tem_loss: 1.156, pem class_loss: 0.339, pem reg_loss: 0.016, total_loss: 1.651[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.156, pem class_loss: 0.336, pem reg_loss: 0.016, total_loss: 1.648[0m
unlabel percent:  0.5
eval student model !!
load : ./checkpoint/Semi-base-0.5-2/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472619
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.12732757438638%
AR@1 is 	 0.3347730700671877
AR@5 is 	 0.49144385026737963
AR@10 is 	 0.565117235705471
AR@100 is 	 0.751501439736734
load : ./checkpoint/Semi-base-0.5-2/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472619
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.22298779651719%
AR@1 is 	 0.3329631153160565
AR@5 is 	 0.49354175236528175
AR@10 is 	 0.5662553133141368
AR@100 is 	 0.7525572466748937
eval teacher model !!
load : ./checkpoint/Semi-base-0.5-2/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472621
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.15119978061153%
AR@1 is 	 0.3334704511175099
AR@5 is 	 0.49411764705882355
AR@10 is 	 0.5650623885918005
AR@100 is 	 0.7519265048676813
load : ./checkpoint/Semi-base-0.5-2/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472622
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.02938434114905%
AR@1 is 	 0.3341011929247223
AR@5 is 	 0.4909502262443438
AR@10 is 	 0.566570684217743
AR@100 is 	 0.7498148909913616
#
train subset video numbers: 5782
unlabel unlabeled subset video numbers: 3867
validation subset video numbers: 4728
use 0.6 label for training!!!
training batchsize : 16
unlabel_training batchsize : 12
use Semi !!!
training 1 (epoch 0): tem_loss: 1.406, pem class_loss: 0.693, pem reg_loss: 0.041, consistency_loss: 0.00042, consistency_loss_ema: 0.00000, total_loss: 2.510
training 11 (epoch 0): tem_loss: 1.366, pem class_loss: 0.530, pem reg_loss: 0.034, consistency_loss: 0.00014, consistency_loss_ema: 0.00004, total_loss: 2.236
training 21 (epoch 0): tem_loss: 1.343, pem class_loss: 0.477, pem reg_loss: 0.030, consistency_loss: 0.00014, consistency_loss_ema: 0.00009, total_loss: 2.121
training 31 (epoch 0): tem_loss: 1.323, pem class_loss: 0.461, pem reg_loss: 0.028, consistency_loss: 0.00016, consistency_loss_ema: 0.00012, total_loss: 2.066
training 41 (epoch 0): tem_loss: 1.305, pem class_loss: 0.446, pem reg_loss: 0.027, consistency_loss: 0.00018, consistency_loss_ema: 0.00014, total_loss: 2.018
training 51 (epoch 0): tem_loss: 1.304, pem class_loss: 0.431, pem reg_loss: 0.026, consistency_loss: 0.00020, consistency_loss_ema: 0.00018, total_loss: 1.991
training 61 (epoch 0): tem_loss: 1.295, pem class_loss: 0.427, pem reg_loss: 0.025, consistency_loss: 0.00022, consistency_loss_ema: 0.00020, total_loss: 1.975
training 71 (epoch 0): tem_loss: 1.286, pem class_loss: 0.422, pem reg_loss: 0.025, consistency_loss: 0.00022, consistency_loss_ema: 0.00020, total_loss: 1.957
training 81 (epoch 0): tem_loss: 1.281, pem class_loss: 0.417, pem reg_loss: 0.024, consistency_loss: 0.00023, consistency_loss_ema: 0.00022, total_loss: 1.942
training 91 (epoch 0): tem_loss: 1.282, pem class_loss: 0.419, pem reg_loss: 0.024, consistency_loss: 0.00025, consistency_loss_ema: 0.00024, total_loss: 1.946
training 101 (epoch 0): tem_loss: 1.274, pem class_loss: 0.414, pem reg_loss: 0.024, consistency_loss: 0.00027, consistency_loss_ema: 0.00026, total_loss: 1.930
training 111 (epoch 0): tem_loss: 1.269, pem class_loss: 0.407, pem reg_loss: 0.024, consistency_loss: 0.00029, consistency_loss_ema: 0.00028, total_loss: 1.915
training 121 (epoch 0): tem_loss: 1.264, pem class_loss: 0.403, pem reg_loss: 0.024, consistency_loss: 0.00030, consistency_loss_ema: 0.00029, total_loss: 1.905
training 131 (epoch 0): tem_loss: 1.260, pem class_loss: 0.403, pem reg_loss: 0.024, consistency_loss: 0.00030, consistency_loss_ema: 0.00030, total_loss: 1.900
training 141 (epoch 0): tem_loss: 1.255, pem class_loss: 0.399, pem reg_loss: 0.023, consistency_loss: 0.00031, consistency_loss_ema: 0.00030, total_loss: 1.888
training 151 (epoch 0): tem_loss: 1.250, pem class_loss: 0.396, pem reg_loss: 0.023, consistency_loss: 0.00031, consistency_loss_ema: 0.00031, total_loss: 1.876
training 161 (epoch 0): tem_loss: 1.246, pem class_loss: 0.394, pem reg_loss: 0.023, consistency_loss: 0.00033, consistency_loss_ema: 0.00033, total_loss: 1.869
training 171 (epoch 0): tem_loss: 1.241, pem class_loss: 0.391, pem reg_loss: 0.023, consistency_loss: 0.00033, consistency_loss_ema: 0.00034, total_loss: 1.859
training 181 (epoch 0): tem_loss: 1.238, pem class_loss: 0.389, pem reg_loss: 0.023, consistency_loss: 0.00034, consistency_loss_ema: 0.00034, total_loss: 1.852
training 191 (epoch 0): tem_loss: 1.236, pem class_loss: 0.387, pem reg_loss: 0.022, consistency_loss: 0.00035, consistency_loss_ema: 0.00035, total_loss: 1.846
training 201 (epoch 0): tem_loss: 1.232, pem class_loss: 0.386, pem reg_loss: 0.022, consistency_loss: 0.00036, consistency_loss_ema: 0.00035, total_loss: 1.840
training 211 (epoch 0): tem_loss: 1.228, pem class_loss: 0.385, pem reg_loss: 0.022, consistency_loss: 0.00036, consistency_loss_ema: 0.00036, total_loss: 1.835
training 221 (epoch 0): tem_loss: 1.227, pem class_loss: 0.385, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00037, total_loss: 1.834
training 231 (epoch 0): tem_loss: 1.229, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00038, total_loss: 1.834
training 241 (epoch 0): tem_loss: 1.229, pem class_loss: 0.382, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00038, total_loss: 1.831
training 251 (epoch 0): tem_loss: 1.227, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00038, total_loss: 1.831
training 261 (epoch 0): tem_loss: 1.224, pem class_loss: 0.382, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00038, total_loss: 1.826
training 271 (epoch 0): tem_loss: 1.221, pem class_loss: 0.380, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00038, total_loss: 1.819
training 281 (epoch 0): tem_loss: 1.219, pem class_loss: 0.380, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00038, total_loss: 1.817
training 291 (epoch 0): tem_loss: 1.217, pem class_loss: 0.380, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00039, total_loss: 1.814
training 301 (epoch 0): tem_loss: 1.216, pem class_loss: 0.379, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00039, total_loss: 1.812
training 311 (epoch 0): tem_loss: 1.214, pem class_loss: 0.379, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00039, total_loss: 1.809
training 321 (epoch 0): tem_loss: 1.212, pem class_loss: 0.377, pem reg_loss: 0.021, consistency_loss: 0.00039, consistency_loss_ema: 0.00039, total_loss: 1.804
training 331 (epoch 0): tem_loss: 1.212, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00039, consistency_loss_ema: 0.00039, total_loss: 1.802
training 341 (epoch 0): tem_loss: 1.211, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00040, consistency_loss_ema: 0.00039, total_loss: 1.801
training 351 (epoch 0): tem_loss: 1.211, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00040, consistency_loss_ema: 0.00039, total_loss: 1.801
training 361 (epoch 0): tem_loss: 1.210, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00040, consistency_loss_ema: 0.00040, total_loss: 1.799
[94mBMN training loss(epoch 0): tem_loss: 1.210, pem class_loss: 0.376, pem reg_loss: 0.021, total_loss: 1.799[0m
[94mBMN val loss(epoch 0): tem_loss: 1.183, pem class_loss: 0.351, pem reg_loss: 0.019, total_loss: 1.729[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.176, pem class_loss: 0.346, pem reg_loss: 0.019, total_loss: 1.715[0m
use Semi !!!
training 362 (epoch 1): tem_loss: 1.106, pem class_loss: 0.262, pem reg_loss: 0.017, consistency_loss: 0.00283, consistency_loss_ema: 0.00445, total_loss: 1.537
training 372 (epoch 1): tem_loss: 1.139, pem class_loss: 0.334, pem reg_loss: 0.019, consistency_loss: 0.00346, consistency_loss_ema: 0.00332, total_loss: 1.659
training 382 (epoch 1): tem_loss: 1.126, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.00313, consistency_loss_ema: 0.00299, total_loss: 1.627
training 392 (epoch 1): tem_loss: 1.132, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00299, consistency_loss_ema: 0.00286, total_loss: 1.658
training 402 (epoch 1): tem_loss: 1.130, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00290, consistency_loss_ema: 0.00280, total_loss: 1.659
training 412 (epoch 1): tem_loss: 1.132, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.00285, consistency_loss_ema: 0.00278, total_loss: 1.655
training 422 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00279, consistency_loss_ema: 0.00272, total_loss: 1.655
training 432 (epoch 1): tem_loss: 1.134, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00268, total_loss: 1.661
training 442 (epoch 1): tem_loss: 1.132, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00267, consistency_loss_ema: 0.00262, total_loss: 1.658
training 452 (epoch 1): tem_loss: 1.138, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00267, consistency_loss_ema: 0.00261, total_loss: 1.673
training 462 (epoch 1): tem_loss: 1.139, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00269, consistency_loss_ema: 0.00265, total_loss: 1.673
training 472 (epoch 1): tem_loss: 1.140, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00271, consistency_loss_ema: 0.00270, total_loss: 1.672
training 482 (epoch 1): tem_loss: 1.141, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00274, consistency_loss_ema: 0.00275, total_loss: 1.673
training 492 (epoch 1): tem_loss: 1.141, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00273, total_loss: 1.674
training 502 (epoch 1): tem_loss: 1.139, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00269, consistency_loss_ema: 0.00270, total_loss: 1.673
training 512 (epoch 1): tem_loss: 1.140, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00267, consistency_loss_ema: 0.00268, total_loss: 1.672
training 522 (epoch 1): tem_loss: 1.140, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00265, consistency_loss_ema: 0.00266, total_loss: 1.675
training 532 (epoch 1): tem_loss: 1.141, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00264, consistency_loss_ema: 0.00267, total_loss: 1.677
training 542 (epoch 1): tem_loss: 1.142, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00266, consistency_loss_ema: 0.00269, total_loss: 1.679
training 552 (epoch 1): tem_loss: 1.143, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00271, consistency_loss_ema: 0.00275, total_loss: 1.681
training 562 (epoch 1): tem_loss: 1.143, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00273, consistency_loss_ema: 0.00277, total_loss: 1.681
training 572 (epoch 1): tem_loss: 1.143, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00271, consistency_loss_ema: 0.00275, total_loss: 1.680
training 582 (epoch 1): tem_loss: 1.142, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00270, consistency_loss_ema: 0.00274, total_loss: 1.677
training 592 (epoch 1): tem_loss: 1.143, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00269, consistency_loss_ema: 0.00272, total_loss: 1.677
training 602 (epoch 1): tem_loss: 1.142, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00275, total_loss: 1.678
training 612 (epoch 1): tem_loss: 1.141, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00276, total_loss: 1.675
training 622 (epoch 1): tem_loss: 1.141, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00273, consistency_loss_ema: 0.00277, total_loss: 1.674
training 632 (epoch 1): tem_loss: 1.143, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00276, total_loss: 1.676
training 642 (epoch 1): tem_loss: 1.143, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00271, consistency_loss_ema: 0.00275, total_loss: 1.676
training 652 (epoch 1): tem_loss: 1.143, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00270, consistency_loss_ema: 0.00275, total_loss: 1.676
training 662 (epoch 1): tem_loss: 1.143, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00269, consistency_loss_ema: 0.00275, total_loss: 1.677
training 672 (epoch 1): tem_loss: 1.143, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00269, consistency_loss_ema: 0.00275, total_loss: 1.675
training 682 (epoch 1): tem_loss: 1.142, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00270, consistency_loss_ema: 0.00277, total_loss: 1.675
training 692 (epoch 1): tem_loss: 1.142, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00269, consistency_loss_ema: 0.00277, total_loss: 1.675
training 702 (epoch 1): tem_loss: 1.143, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00268, consistency_loss_ema: 0.00275, total_loss: 1.676
training 712 (epoch 1): tem_loss: 1.142, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00267, consistency_loss_ema: 0.00274, total_loss: 1.675
training 722 (epoch 1): tem_loss: 1.141, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00267, consistency_loss_ema: 0.00273, total_loss: 1.672
[94mBMN training loss(epoch 1): tem_loss: 1.141, pem class_loss: 0.343, pem reg_loss: 0.019, total_loss: 1.672[0m
[94mBMN val loss(epoch 1): tem_loss: 1.153, pem class_loss: 0.342, pem reg_loss: 0.019, total_loss: 1.684[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.147, pem class_loss: 0.338, pem reg_loss: 0.018, total_loss: 1.667[0m
use Semi !!!
training 723 (epoch 2): tem_loss: 1.173, pem class_loss: 0.362, pem reg_loss: 0.023, consistency_loss: 0.00957, consistency_loss_ema: 0.00982, total_loss: 1.768
training 733 (epoch 2): tem_loss: 1.144, pem class_loss: 0.326, pem reg_loss: 0.018, consistency_loss: 0.01077, consistency_loss_ema: 0.01057, total_loss: 1.655
training 743 (epoch 2): tem_loss: 1.122, pem class_loss: 0.332, pem reg_loss: 0.019, consistency_loss: 0.00960, consistency_loss_ema: 0.00984, total_loss: 1.641
training 753 (epoch 2): tem_loss: 1.122, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00892, consistency_loss_ema: 0.00935, total_loss: 1.653
training 763 (epoch 2): tem_loss: 1.109, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00887, consistency_loss_ema: 0.00939, total_loss: 1.631
training 773 (epoch 2): tem_loss: 1.106, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00871, consistency_loss_ema: 0.00922, total_loss: 1.623
training 783 (epoch 2): tem_loss: 1.105, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00880, consistency_loss_ema: 0.00924, total_loss: 1.622
training 793 (epoch 2): tem_loss: 1.109, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00877, consistency_loss_ema: 0.00919, total_loss: 1.633
training 803 (epoch 2): tem_loss: 1.102, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00874, consistency_loss_ema: 0.00917, total_loss: 1.621
training 813 (epoch 2): tem_loss: 1.103, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00879, consistency_loss_ema: 0.00918, total_loss: 1.620
training 823 (epoch 2): tem_loss: 1.102, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.00910, consistency_loss_ema: 0.00957, total_loss: 1.622
training 833 (epoch 2): tem_loss: 1.106, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00935, consistency_loss_ema: 0.00979, total_loss: 1.624
training 843 (epoch 2): tem_loss: 1.105, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00921, consistency_loss_ema: 0.00971, total_loss: 1.622
training 853 (epoch 2): tem_loss: 1.106, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00903, consistency_loss_ema: 0.00955, total_loss: 1.622
training 863 (epoch 2): tem_loss: 1.109, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00898, consistency_loss_ema: 0.00944, total_loss: 1.626
training 873 (epoch 2): tem_loss: 1.109, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00887, consistency_loss_ema: 0.00938, total_loss: 1.626
training 883 (epoch 2): tem_loss: 1.109, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00883, consistency_loss_ema: 0.00937, total_loss: 1.626
training 893 (epoch 2): tem_loss: 1.108, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00876, consistency_loss_ema: 0.00930, total_loss: 1.625
training 903 (epoch 2): tem_loss: 1.110, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00874, consistency_loss_ema: 0.00927, total_loss: 1.625
training 913 (epoch 2): tem_loss: 1.110, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00869, consistency_loss_ema: 0.00916, total_loss: 1.624
training 923 (epoch 2): tem_loss: 1.111, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00866, consistency_loss_ema: 0.00916, total_loss: 1.627
training 933 (epoch 2): tem_loss: 1.112, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00865, consistency_loss_ema: 0.00919, total_loss: 1.627
training 943 (epoch 2): tem_loss: 1.113, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00862, consistency_loss_ema: 0.00915, total_loss: 1.627
training 953 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00857, consistency_loss_ema: 0.00915, total_loss: 1.627
training 963 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00854, consistency_loss_ema: 0.00907, total_loss: 1.628
training 973 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00857, consistency_loss_ema: 0.00906, total_loss: 1.629
training 983 (epoch 2): tem_loss: 1.115, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00859, consistency_loss_ema: 0.00902, total_loss: 1.631
training 993 (epoch 2): tem_loss: 1.114, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00864, consistency_loss_ema: 0.00904, total_loss: 1.628
training 1003 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00863, consistency_loss_ema: 0.00904, total_loss: 1.627
training 1013 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00867, consistency_loss_ema: 0.00912, total_loss: 1.627
training 1023 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00873, consistency_loss_ema: 0.00918, total_loss: 1.626
training 1033 (epoch 2): tem_loss: 1.115, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00873, consistency_loss_ema: 0.00916, total_loss: 1.626
training 1043 (epoch 2): tem_loss: 1.115, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00877, consistency_loss_ema: 0.00918, total_loss: 1.626
training 1053 (epoch 2): tem_loss: 1.115, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00876, consistency_loss_ema: 0.00918, total_loss: 1.626
training 1063 (epoch 2): tem_loss: 1.115, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00877, consistency_loss_ema: 0.00923, total_loss: 1.627
training 1073 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00877, consistency_loss_ema: 0.00924, total_loss: 1.627
training 1083 (epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00875, consistency_loss_ema: 0.00923, total_loss: 1.626
[94mBMN training loss(epoch 2): tem_loss: 1.114, pem class_loss: 0.333, pem reg_loss: 0.018, total_loss: 1.626[0m
[94mBMN val loss(epoch 2): tem_loss: 1.149, pem class_loss: 0.335, pem reg_loss: 0.018, total_loss: 1.659[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.142, pem class_loss: 0.333, pem reg_loss: 0.017, total_loss: 1.648[0m
use Semi !!!
training 1084 (epoch 3): tem_loss: 1.276, pem class_loss: 0.370, pem reg_loss: 0.014, consistency_loss: 0.02953, consistency_loss_ema: 0.02173, total_loss: 1.783
training 1094 (epoch 3): tem_loss: 1.085, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.02084, consistency_loss_ema: 0.02054, total_loss: 1.581
training 1104 (epoch 3): tem_loss: 1.097, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.02020, consistency_loss_ema: 0.02014, total_loss: 1.601
training 1114 (epoch 3): tem_loss: 1.098, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.01952, consistency_loss_ema: 0.01972, total_loss: 1.614
training 1124 (epoch 3): tem_loss: 1.098, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.01885, consistency_loss_ema: 0.01937, total_loss: 1.611
training 1134 (epoch 3): tem_loss: 1.095, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.01824, consistency_loss_ema: 0.01909, total_loss: 1.606
training 1144 (epoch 3): tem_loss: 1.089, pem class_loss: 0.333, pem reg_loss: 0.017, consistency_loss: 0.01823, consistency_loss_ema: 0.01907, total_loss: 1.597
training 1154 (epoch 3): tem_loss: 1.094, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.01803, consistency_loss_ema: 0.01907, total_loss: 1.593
training 1164 (epoch 3): tem_loss: 1.097, pem class_loss: 0.327, pem reg_loss: 0.017, consistency_loss: 0.01802, consistency_loss_ema: 0.01913, total_loss: 1.594
training 1174 (epoch 3): tem_loss: 1.098, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01799, consistency_loss_ema: 0.01891, total_loss: 1.594
training 1184 (epoch 3): tem_loss: 1.099, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01781, consistency_loss_ema: 0.01873, total_loss: 1.596
training 1194 (epoch 3): tem_loss: 1.099, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01785, consistency_loss_ema: 0.01879, total_loss: 1.593
training 1204 (epoch 3): tem_loss: 1.101, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01767, consistency_loss_ema: 0.01863, total_loss: 1.596
training 1214 (epoch 3): tem_loss: 1.103, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01773, consistency_loss_ema: 0.01873, total_loss: 1.597
training 1224 (epoch 3): tem_loss: 1.103, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.01766, consistency_loss_ema: 0.01869, total_loss: 1.592
training 1234 (epoch 3): tem_loss: 1.102, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.01759, consistency_loss_ema: 0.01857, total_loss: 1.592
training 1244 (epoch 3): tem_loss: 1.102, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.01757, consistency_loss_ema: 0.01849, total_loss: 1.593
training 1254 (epoch 3): tem_loss: 1.100, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.01752, consistency_loss_ema: 0.01843, total_loss: 1.590
training 1264 (epoch 3): tem_loss: 1.100, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.01754, consistency_loss_ema: 0.01843, total_loss: 1.590
training 1274 (epoch 3): tem_loss: 1.100, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01760, consistency_loss_ema: 0.01841, total_loss: 1.588
training 1284 (epoch 3): tem_loss: 1.100, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01759, consistency_loss_ema: 0.01841, total_loss: 1.587
training 1294 (epoch 3): tem_loss: 1.101, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01748, consistency_loss_ema: 0.01824, total_loss: 1.588
training 1304 (epoch 3): tem_loss: 1.101, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01744, consistency_loss_ema: 0.01819, total_loss: 1.587
training 1314 (epoch 3): tem_loss: 1.102, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01736, consistency_loss_ema: 0.01815, total_loss: 1.590
training 1324 (epoch 3): tem_loss: 1.104, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01734, consistency_loss_ema: 0.01811, total_loss: 1.593
training 1334 (epoch 3): tem_loss: 1.103, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01729, consistency_loss_ema: 0.01804, total_loss: 1.591
training 1344 (epoch 3): tem_loss: 1.103, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01724, consistency_loss_ema: 0.01797, total_loss: 1.590
training 1354 (epoch 3): tem_loss: 1.102, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01715, consistency_loss_ema: 0.01792, total_loss: 1.589
training 1364 (epoch 3): tem_loss: 1.101, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.01711, consistency_loss_ema: 0.01786, total_loss: 1.590
training 1374 (epoch 3): tem_loss: 1.104, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.01709, consistency_loss_ema: 0.01783, total_loss: 1.593
training 1384 (epoch 3): tem_loss: 1.106, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.01707, consistency_loss_ema: 0.01779, total_loss: 1.594
training 1394 (epoch 3): tem_loss: 1.106, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.01707, consistency_loss_ema: 0.01783, total_loss: 1.595
training 1404 (epoch 3): tem_loss: 1.106, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.01702, consistency_loss_ema: 0.01778, total_loss: 1.595
training 1414 (epoch 3): tem_loss: 1.106, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.01699, consistency_loss_ema: 0.01770, total_loss: 1.596
training 1424 (epoch 3): tem_loss: 1.105, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.01696, consistency_loss_ema: 0.01768, total_loss: 1.594
training 1434 (epoch 3): tem_loss: 1.105, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.01691, consistency_loss_ema: 0.01766, total_loss: 1.594
training 1444 (epoch 3): tem_loss: 1.105, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01687, consistency_loss_ema: 0.01764, total_loss: 1.596
[94mBMN training loss(epoch 3): tem_loss: 1.105, pem class_loss: 0.324, pem reg_loss: 0.017, total_loss: 1.596[0m
[94mBMN val loss(epoch 3): tem_loss: 1.148, pem class_loss: 0.334, pem reg_loss: 0.017, total_loss: 1.656[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.147, pem class_loss: 0.328, pem reg_loss: 0.017, total_loss: 1.640[0m
use Semi !!!
training 1445 (epoch 4): tem_loss: 0.933, pem class_loss: 0.264, pem reg_loss: 0.012, consistency_loss: 0.03157, consistency_loss_ema: 0.03288, total_loss: 1.320
training 1455 (epoch 4): tem_loss: 1.117, pem class_loss: 0.327, pem reg_loss: 0.017, consistency_loss: 0.02658, consistency_loss_ema: 0.02833, total_loss: 1.616
training 1465 (epoch 4): tem_loss: 1.109, pem class_loss: 0.321, pem reg_loss: 0.016, consistency_loss: 0.02663, consistency_loss_ema: 0.02809, total_loss: 1.595
training 1475 (epoch 4): tem_loss: 1.109, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.02659, consistency_loss_ema: 0.02801, total_loss: 1.598
training 1485 (epoch 4): tem_loss: 1.098, pem class_loss: 0.325, pem reg_loss: 0.016, consistency_loss: 0.02660, consistency_loss_ema: 0.02741, total_loss: 1.585
training 1495 (epoch 4): tem_loss: 1.095, pem class_loss: 0.321, pem reg_loss: 0.016, consistency_loss: 0.02645, consistency_loss_ema: 0.02776, total_loss: 1.578
training 1505 (epoch 4): tem_loss: 1.105, pem class_loss: 0.323, pem reg_loss: 0.016, consistency_loss: 0.02614, consistency_loss_ema: 0.02761, total_loss: 1.592
training 1515 (epoch 4): tem_loss: 1.111, pem class_loss: 0.326, pem reg_loss: 0.016, consistency_loss: 0.02590, consistency_loss_ema: 0.02695, total_loss: 1.602
training 1525 (epoch 4): tem_loss: 1.109, pem class_loss: 0.324, pem reg_loss: 0.016, consistency_loss: 0.02541, consistency_loss_ema: 0.02658, total_loss: 1.595
training 1535 (epoch 4): tem_loss: 1.108, pem class_loss: 0.321, pem reg_loss: 0.016, consistency_loss: 0.02556, consistency_loss_ema: 0.02646, total_loss: 1.590
training 1545 (epoch 4): tem_loss: 1.108, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02566, consistency_loss_ema: 0.02662, total_loss: 1.588
training 1555 (epoch 4): tem_loss: 1.104, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02547, consistency_loss_ema: 0.02653, total_loss: 1.584
training 1565 (epoch 4): tem_loss: 1.102, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02549, consistency_loss_ema: 0.02656, total_loss: 1.578
training 1575 (epoch 4): tem_loss: 1.103, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02543, consistency_loss_ema: 0.02669, total_loss: 1.578
training 1585 (epoch 4): tem_loss: 1.103, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.02546, consistency_loss_ema: 0.02658, total_loss: 1.578
training 1595 (epoch 4): tem_loss: 1.104, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02537, consistency_loss_ema: 0.02665, total_loss: 1.575
training 1605 (epoch 4): tem_loss: 1.103, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02527, consistency_loss_ema: 0.02656, total_loss: 1.574
training 1615 (epoch 4): tem_loss: 1.102, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02538, consistency_loss_ema: 0.02661, total_loss: 1.573
training 1625 (epoch 4): tem_loss: 1.102, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02541, consistency_loss_ema: 0.02663, total_loss: 1.573
training 1635 (epoch 4): tem_loss: 1.100, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02533, consistency_loss_ema: 0.02656, total_loss: 1.571
training 1645 (epoch 4): tem_loss: 1.101, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02520, consistency_loss_ema: 0.02651, total_loss: 1.571
training 1655 (epoch 4): tem_loss: 1.102, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02522, consistency_loss_ema: 0.02648, total_loss: 1.573
training 1665 (epoch 4): tem_loss: 1.103, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02521, consistency_loss_ema: 0.02654, total_loss: 1.575
training 1675 (epoch 4): tem_loss: 1.103, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02524, consistency_loss_ema: 0.02641, total_loss: 1.576
training 1685 (epoch 4): tem_loss: 1.105, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02519, consistency_loss_ema: 0.02630, total_loss: 1.578
training 1695 (epoch 4): tem_loss: 1.107, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02517, consistency_loss_ema: 0.02624, total_loss: 1.580
training 1705 (epoch 4): tem_loss: 1.106, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02506, consistency_loss_ema: 0.02616, total_loss: 1.579
training 1715 (epoch 4): tem_loss: 1.106, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02502, consistency_loss_ema: 0.02605, total_loss: 1.579
training 1725 (epoch 4): tem_loss: 1.107, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02494, consistency_loss_ema: 0.02598, total_loss: 1.580
training 1735 (epoch 4): tem_loss: 1.108, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.02482, consistency_loss_ema: 0.02587, total_loss: 1.582
training 1745 (epoch 4): tem_loss: 1.107, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02488, consistency_loss_ema: 0.02584, total_loss: 1.581
training 1755 (epoch 4): tem_loss: 1.107, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02479, consistency_loss_ema: 0.02583, total_loss: 1.579
training 1765 (epoch 4): tem_loss: 1.107, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02473, consistency_loss_ema: 0.02575, total_loss: 1.579
training 1775 (epoch 4): tem_loss: 1.107, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02469, consistency_loss_ema: 0.02581, total_loss: 1.578
training 1785 (epoch 4): tem_loss: 1.107, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02464, consistency_loss_ema: 0.02573, total_loss: 1.579
training 1795 (epoch 4): tem_loss: 1.107, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02461, consistency_loss_ema: 0.02568, total_loss: 1.579
training 1805 (epoch 4): tem_loss: 1.108, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02456, consistency_loss_ema: 0.02564, total_loss: 1.580
[94mBMN training loss(epoch 4): tem_loss: 1.108, pem class_loss: 0.313, pem reg_loss: 0.016, total_loss: 1.580[0m
[94mBMN val loss(epoch 4): tem_loss: 1.160, pem class_loss: 0.332, pem reg_loss: 0.017, total_loss: 1.662[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.155, pem class_loss: 0.324, pem reg_loss: 0.016, total_loss: 1.639[0m
use Semi !!!
training 1806 (epoch 5): tem_loss: 1.084, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.03025, consistency_loss_ema: 0.02599, total_loss: 1.516
training 1816 (epoch 5): tem_loss: 1.098, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02693, consistency_loss_ema: 0.03043, total_loss: 1.560
training 1826 (epoch 5): tem_loss: 1.103, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02776, consistency_loss_ema: 0.03151, total_loss: 1.576
training 1836 (epoch 5): tem_loss: 1.104, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02848, consistency_loss_ema: 0.03023, total_loss: 1.566
training 1846 (epoch 5): tem_loss: 1.107, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02876, consistency_loss_ema: 0.03094, total_loss: 1.567
training 1856 (epoch 5): tem_loss: 1.105, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02884, consistency_loss_ema: 0.03093, total_loss: 1.567
training 1866 (epoch 5): tem_loss: 1.107, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02851, consistency_loss_ema: 0.03054, total_loss: 1.571
training 1876 (epoch 5): tem_loss: 1.112, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02826, consistency_loss_ema: 0.03054, total_loss: 1.574
training 1886 (epoch 5): tem_loss: 1.110, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02841, consistency_loss_ema: 0.03016, total_loss: 1.566
training 1896 (epoch 5): tem_loss: 1.108, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02836, consistency_loss_ema: 0.03014, total_loss: 1.564
training 1906 (epoch 5): tem_loss: 1.110, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02817, consistency_loss_ema: 0.02972, total_loss: 1.565
training 1916 (epoch 5): tem_loss: 1.109, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02795, consistency_loss_ema: 0.02968, total_loss: 1.561
training 1926 (epoch 5): tem_loss: 1.111, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02795, consistency_loss_ema: 0.02964, total_loss: 1.563
training 1936 (epoch 5): tem_loss: 1.109, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02779, consistency_loss_ema: 0.02935, total_loss: 1.560
training 1946 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02770, consistency_loss_ema: 0.02902, total_loss: 1.563
training 1956 (epoch 5): tem_loss: 1.108, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02747, consistency_loss_ema: 0.02884, total_loss: 1.562
training 1966 (epoch 5): tem_loss: 1.108, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02738, consistency_loss_ema: 0.02864, total_loss: 1.562
training 1976 (epoch 5): tem_loss: 1.110, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02740, consistency_loss_ema: 0.02853, total_loss: 1.565
training 1986 (epoch 5): tem_loss: 1.108, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02742, consistency_loss_ema: 0.02848, total_loss: 1.564
training 1996 (epoch 5): tem_loss: 1.106, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02754, consistency_loss_ema: 0.02862, total_loss: 1.562
training 2006 (epoch 5): tem_loss: 1.108, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02759, consistency_loss_ema: 0.02895, total_loss: 1.562
training 2016 (epoch 5): tem_loss: 1.108, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02746, consistency_loss_ema: 0.02892, total_loss: 1.562
training 2026 (epoch 5): tem_loss: 1.108, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02740, consistency_loss_ema: 0.02884, total_loss: 1.561
training 2036 (epoch 5): tem_loss: 1.107, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02721, consistency_loss_ema: 0.02867, total_loss: 1.560
training 2046 (epoch 5): tem_loss: 1.108, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02715, consistency_loss_ema: 0.02847, total_loss: 1.560
training 2056 (epoch 5): tem_loss: 1.107, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02706, consistency_loss_ema: 0.02843, total_loss: 1.559
training 2066 (epoch 5): tem_loss: 1.107, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02701, consistency_loss_ema: 0.02855, total_loss: 1.560
training 2076 (epoch 5): tem_loss: 1.108, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02703, consistency_loss_ema: 0.02851, total_loss: 1.562
training 2086 (epoch 5): tem_loss: 1.108, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02698, consistency_loss_ema: 0.02841, total_loss: 1.563
training 2096 (epoch 5): tem_loss: 1.108, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02705, consistency_loss_ema: 0.02855, total_loss: 1.566
training 2106 (epoch 5): tem_loss: 1.109, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02699, consistency_loss_ema: 0.02846, total_loss: 1.567
training 2116 (epoch 5): tem_loss: 1.110, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02699, consistency_loss_ema: 0.02847, total_loss: 1.570
training 2126 (epoch 5): tem_loss: 1.110, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02698, consistency_loss_ema: 0.02842, total_loss: 1.571
training 2136 (epoch 5): tem_loss: 1.110, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02695, consistency_loss_ema: 0.02835, total_loss: 1.571
training 2146 (epoch 5): tem_loss: 1.110, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02696, consistency_loss_ema: 0.02823, total_loss: 1.570
training 2156 (epoch 5): tem_loss: 1.111, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02696, consistency_loss_ema: 0.02820, total_loss: 1.571
training 2166 (epoch 5): tem_loss: 1.111, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02683, consistency_loss_ema: 0.02809, total_loss: 1.573
[94mBMN training loss(epoch 5): tem_loss: 1.111, pem class_loss: 0.308, pem reg_loss: 0.015, total_loss: 1.573[0m
[94mBMN val loss(epoch 5): tem_loss: 1.162, pem class_loss: 0.324, pem reg_loss: 0.016, total_loss: 1.645[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.160, pem class_loss: 0.322, pem reg_loss: 0.016, total_loss: 1.640[0m
use Semi !!!
training 2167 (epoch 6): tem_loss: 1.039, pem class_loss: 0.256, pem reg_loss: 0.013, consistency_loss: 0.02495, consistency_loss_ema: 0.02153, total_loss: 1.426
training 2177 (epoch 6): tem_loss: 1.090, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.02194, consistency_loss_ema: 0.02436, total_loss: 1.518
training 2187 (epoch 6): tem_loss: 1.092, pem class_loss: 0.284, pem reg_loss: 0.015, consistency_loss: 0.02366, consistency_loss_ema: 0.02653, total_loss: 1.522
training 2197 (epoch 6): tem_loss: 1.094, pem class_loss: 0.286, pem reg_loss: 0.015, consistency_loss: 0.02394, consistency_loss_ema: 0.02670, total_loss: 1.529
training 2207 (epoch 6): tem_loss: 1.098, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02478, consistency_loss_ema: 0.02660, total_loss: 1.543
training 2217 (epoch 6): tem_loss: 1.107, pem class_loss: 0.299, pem reg_loss: 0.016, consistency_loss: 0.02466, consistency_loss_ema: 0.02632, total_loss: 1.564
training 2227 (epoch 6): tem_loss: 1.105, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.02489, consistency_loss_ema: 0.02597, total_loss: 1.566
training 2237 (epoch 6): tem_loss: 1.105, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02493, consistency_loss_ema: 0.02587, total_loss: 1.566
training 2247 (epoch 6): tem_loss: 1.108, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02468, consistency_loss_ema: 0.02609, total_loss: 1.570
training 2257 (epoch 6): tem_loss: 1.113, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02465, consistency_loss_ema: 0.02602, total_loss: 1.574
training 2267 (epoch 6): tem_loss: 1.114, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02472, consistency_loss_ema: 0.02594, total_loss: 1.575
training 2277 (epoch 6): tem_loss: 1.115, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02503, consistency_loss_ema: 0.02602, total_loss: 1.573
training 2287 (epoch 6): tem_loss: 1.113, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02633, total_loss: 1.573
training 2297 (epoch 6): tem_loss: 1.112, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02632, total_loss: 1.572
training 2307 (epoch 6): tem_loss: 1.113, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02633, total_loss: 1.572
training 2317 (epoch 6): tem_loss: 1.112, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02639, total_loss: 1.570
training 2327 (epoch 6): tem_loss: 1.111, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02503, consistency_loss_ema: 0.02640, total_loss: 1.571
training 2337 (epoch 6): tem_loss: 1.109, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02634, total_loss: 1.569
training 2347 (epoch 6): tem_loss: 1.110, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02485, consistency_loss_ema: 0.02636, total_loss: 1.572
training 2357 (epoch 6): tem_loss: 1.111, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02490, consistency_loss_ema: 0.02633, total_loss: 1.572
training 2367 (epoch 6): tem_loss: 1.111, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.02491, consistency_loss_ema: 0.02636, total_loss: 1.575
training 2377 (epoch 6): tem_loss: 1.111, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02492, consistency_loss_ema: 0.02635, total_loss: 1.573
training 2387 (epoch 6): tem_loss: 1.111, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.02495, consistency_loss_ema: 0.02627, total_loss: 1.573
training 2397 (epoch 6): tem_loss: 1.112, pem class_loss: 0.310, pem reg_loss: 0.015, consistency_loss: 0.02488, consistency_loss_ema: 0.02614, total_loss: 1.575
training 2407 (epoch 6): tem_loss: 1.111, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02492, consistency_loss_ema: 0.02626, total_loss: 1.572
training 2417 (epoch 6): tem_loss: 1.111, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02491, consistency_loss_ema: 0.02625, total_loss: 1.571
training 2427 (epoch 6): tem_loss: 1.111, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02633, total_loss: 1.571
training 2437 (epoch 6): tem_loss: 1.112, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02641, total_loss: 1.571
training 2447 (epoch 6): tem_loss: 1.112, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02644, total_loss: 1.571
training 2457 (epoch 6): tem_loss: 1.111, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02521, consistency_loss_ema: 0.02667, total_loss: 1.570
training 2467 (epoch 6): tem_loss: 1.111, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02528, consistency_loss_ema: 0.02677, total_loss: 1.569
training 2477 (epoch 6): tem_loss: 1.110, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02523, consistency_loss_ema: 0.02675, total_loss: 1.566
training 2487 (epoch 6): tem_loss: 1.108, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02525, consistency_loss_ema: 0.02675, total_loss: 1.563
training 2497 (epoch 6): tem_loss: 1.107, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02531, consistency_loss_ema: 0.02685, total_loss: 1.563
training 2507 (epoch 6): tem_loss: 1.108, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02535, consistency_loss_ema: 0.02684, total_loss: 1.564
training 2517 (epoch 6): tem_loss: 1.108, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02538, consistency_loss_ema: 0.02678, total_loss: 1.564
training 2527 (epoch 6): tem_loss: 1.108, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02541, consistency_loss_ema: 0.02683, total_loss: 1.564
[94mBMN training loss(epoch 6): tem_loss: 1.108, pem class_loss: 0.305, pem reg_loss: 0.015, total_loss: 1.564[0m
[94mBMN val loss(epoch 6): tem_loss: 1.166, pem class_loss: 0.329, pem reg_loss: 0.016, total_loss: 1.656[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.161, pem class_loss: 0.321, pem reg_loss: 0.016, total_loss: 1.638[0m
use Semi !!!
training 2528 (epoch 7): tem_loss: 1.192, pem class_loss: 0.340, pem reg_loss: 0.013, consistency_loss: 0.02781, consistency_loss_ema: 0.03021, total_loss: 1.662
training 2538 (epoch 7): tem_loss: 1.109, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.02533, consistency_loss_ema: 0.02450, total_loss: 1.516
training 2548 (epoch 7): tem_loss: 1.095, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.02281, consistency_loss_ema: 0.02337, total_loss: 1.509
training 2558 (epoch 7): tem_loss: 1.095, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.02161, consistency_loss_ema: 0.02289, total_loss: 1.499
training 2568 (epoch 7): tem_loss: 1.091, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.02112, consistency_loss_ema: 0.02221, total_loss: 1.497
training 2578 (epoch 7): tem_loss: 1.090, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.02041, consistency_loss_ema: 0.02210, total_loss: 1.501
training 2588 (epoch 7): tem_loss: 1.089, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01996, consistency_loss_ema: 0.02155, total_loss: 1.502
training 2598 (epoch 7): tem_loss: 1.089, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01957, consistency_loss_ema: 0.02127, total_loss: 1.501
training 2608 (epoch 7): tem_loss: 1.091, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01934, consistency_loss_ema: 0.02100, total_loss: 1.507
training 2618 (epoch 7): tem_loss: 1.093, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01926, consistency_loss_ema: 0.02055, total_loss: 1.511
training 2628 (epoch 7): tem_loss: 1.093, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01922, consistency_loss_ema: 0.02029, total_loss: 1.511
training 2638 (epoch 7): tem_loss: 1.094, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01913, consistency_loss_ema: 0.02015, total_loss: 1.517
training 2648 (epoch 7): tem_loss: 1.093, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01892, consistency_loss_ema: 0.02000, total_loss: 1.515
training 2658 (epoch 7): tem_loss: 1.092, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01873, consistency_loss_ema: 0.01978, total_loss: 1.513
training 2668 (epoch 7): tem_loss: 1.092, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01866, consistency_loss_ema: 0.01978, total_loss: 1.517
training 2678 (epoch 7): tem_loss: 1.095, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01855, consistency_loss_ema: 0.01965, total_loss: 1.523
training 2688 (epoch 7): tem_loss: 1.095, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01845, consistency_loss_ema: 0.01966, total_loss: 1.524
training 2698 (epoch 7): tem_loss: 1.092, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01834, consistency_loss_ema: 0.01961, total_loss: 1.521
training 2708 (epoch 7): tem_loss: 1.092, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01824, consistency_loss_ema: 0.01955, total_loss: 1.518
training 2718 (epoch 7): tem_loss: 1.091, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01819, consistency_loss_ema: 0.01949, total_loss: 1.515
training 2728 (epoch 7): tem_loss: 1.092, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01816, consistency_loss_ema: 0.01943, total_loss: 1.515
training 2738 (epoch 7): tem_loss: 1.091, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01819, consistency_loss_ema: 0.01940, total_loss: 1.514
training 2748 (epoch 7): tem_loss: 1.091, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01812, consistency_loss_ema: 0.01934, total_loss: 1.514
training 2758 (epoch 7): tem_loss: 1.091, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01805, consistency_loss_ema: 0.01929, total_loss: 1.513
training 2768 (epoch 7): tem_loss: 1.091, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01800, consistency_loss_ema: 0.01922, total_loss: 1.514
training 2778 (epoch 7): tem_loss: 1.091, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01798, consistency_loss_ema: 0.01916, total_loss: 1.516
training 2788 (epoch 7): tem_loss: 1.092, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01791, consistency_loss_ema: 0.01910, total_loss: 1.517
training 2798 (epoch 7): tem_loss: 1.092, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01784, consistency_loss_ema: 0.01904, total_loss: 1.518
training 2808 (epoch 7): tem_loss: 1.092, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01785, consistency_loss_ema: 0.01902, total_loss: 1.519
training 2818 (epoch 7): tem_loss: 1.093, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01784, consistency_loss_ema: 0.01908, total_loss: 1.519
training 2828 (epoch 7): tem_loss: 1.093, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01787, consistency_loss_ema: 0.01911, total_loss: 1.520
training 2838 (epoch 7): tem_loss: 1.094, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01789, consistency_loss_ema: 0.01912, total_loss: 1.520
training 2848 (epoch 7): tem_loss: 1.094, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01788, consistency_loss_ema: 0.01917, total_loss: 1.520
training 2858 (epoch 7): tem_loss: 1.096, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01788, consistency_loss_ema: 0.01916, total_loss: 1.521
training 2868 (epoch 7): tem_loss: 1.095, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01789, consistency_loss_ema: 0.01918, total_loss: 1.520
training 2878 (epoch 7): tem_loss: 1.095, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01789, consistency_loss_ema: 0.01913, total_loss: 1.520
training 2888 (epoch 7): tem_loss: 1.094, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01785, consistency_loss_ema: 0.01913, total_loss: 1.520
[94mBMN training loss(epoch 7): tem_loss: 1.094, pem class_loss: 0.286, pem reg_loss: 0.014, total_loss: 1.520[0m
[94mBMN val loss(epoch 7): tem_loss: 1.159, pem class_loss: 0.326, pem reg_loss: 0.016, total_loss: 1.641[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.159, pem class_loss: 0.323, pem reg_loss: 0.015, total_loss: 1.637[0m
use Semi !!!
training 2889 (epoch 8): tem_loss: 0.981, pem class_loss: 0.246, pem reg_loss: 0.011, consistency_loss: 0.01846, consistency_loss_ema: 0.01657, total_loss: 1.342
training 2899 (epoch 8): tem_loss: 1.106, pem class_loss: 0.284, pem reg_loss: 0.013, consistency_loss: 0.01739, consistency_loss_ema: 0.02031, total_loss: 1.521
training 2909 (epoch 8): tem_loss: 1.098, pem class_loss: 0.267, pem reg_loss: 0.013, consistency_loss: 0.01811, consistency_loss_ema: 0.01952, total_loss: 1.495
training 2919 (epoch 8): tem_loss: 1.106, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01799, consistency_loss_ema: 0.01924, total_loss: 1.524
training 2929 (epoch 8): tem_loss: 1.107, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01804, consistency_loss_ema: 0.01909, total_loss: 1.527
training 2939 (epoch 8): tem_loss: 1.110, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01820, consistency_loss_ema: 0.01904, total_loss: 1.533
training 2949 (epoch 8): tem_loss: 1.107, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01801, consistency_loss_ema: 0.01896, total_loss: 1.535
training 2959 (epoch 8): tem_loss: 1.107, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01807, consistency_loss_ema: 0.01885, total_loss: 1.534
training 2969 (epoch 8): tem_loss: 1.103, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01804, consistency_loss_ema: 0.01895, total_loss: 1.527
training 2979 (epoch 8): tem_loss: 1.103, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01817, consistency_loss_ema: 0.01893, total_loss: 1.525
training 2989 (epoch 8): tem_loss: 1.101, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01805, consistency_loss_ema: 0.01900, total_loss: 1.519
training 2999 (epoch 8): tem_loss: 1.101, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01813, consistency_loss_ema: 0.01919, total_loss: 1.518
training 3009 (epoch 8): tem_loss: 1.104, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01811, consistency_loss_ema: 0.01914, total_loss: 1.521
training 3019 (epoch 8): tem_loss: 1.101, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01814, consistency_loss_ema: 0.01911, total_loss: 1.515
training 3029 (epoch 8): tem_loss: 1.098, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01818, consistency_loss_ema: 0.01912, total_loss: 1.511
training 3039 (epoch 8): tem_loss: 1.097, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01818, consistency_loss_ema: 0.01925, total_loss: 1.512
training 3049 (epoch 8): tem_loss: 1.097, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01824, consistency_loss_ema: 0.01933, total_loss: 1.512
training 3059 (epoch 8): tem_loss: 1.096, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01825, consistency_loss_ema: 0.01932, total_loss: 1.514
training 3069 (epoch 8): tem_loss: 1.094, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01828, consistency_loss_ema: 0.01943, total_loss: 1.510
training 3079 (epoch 8): tem_loss: 1.093, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01835, consistency_loss_ema: 0.01952, total_loss: 1.506
training 3089 (epoch 8): tem_loss: 1.093, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01838, consistency_loss_ema: 0.01950, total_loss: 1.507
training 3099 (epoch 8): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01837, consistency_loss_ema: 0.01950, total_loss: 1.505
training 3109 (epoch 8): tem_loss: 1.092, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01833, consistency_loss_ema: 0.01953, total_loss: 1.506
training 3119 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01833, consistency_loss_ema: 0.01960, total_loss: 1.503
training 3129 (epoch 8): tem_loss: 1.092, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01835, consistency_loss_ema: 0.01961, total_loss: 1.507
training 3139 (epoch 8): tem_loss: 1.092, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01838, consistency_loss_ema: 0.01963, total_loss: 1.509
training 3149 (epoch 8): tem_loss: 1.092, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01842, consistency_loss_ema: 0.01971, total_loss: 1.511
training 3159 (epoch 8): tem_loss: 1.090, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01844, consistency_loss_ema: 0.01967, total_loss: 1.509
training 3169 (epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01848, consistency_loss_ema: 0.01974, total_loss: 1.507
training 3179 (epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01850, consistency_loss_ema: 0.01979, total_loss: 1.506
training 3189 (epoch 8): tem_loss: 1.090, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01855, consistency_loss_ema: 0.01981, total_loss: 1.508
training 3199 (epoch 8): tem_loss: 1.089, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01854, consistency_loss_ema: 0.01984, total_loss: 1.505
training 3209 (epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01858, consistency_loss_ema: 0.01989, total_loss: 1.505
training 3219 (epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01862, consistency_loss_ema: 0.01995, total_loss: 1.505
training 3229 (epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01864, consistency_loss_ema: 0.01994, total_loss: 1.506
training 3239 (epoch 8): tem_loss: 1.089, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01863, consistency_loss_ema: 0.01995, total_loss: 1.507
training 3249 (epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01866, consistency_loss_ema: 0.01995, total_loss: 1.506
[94mBMN training loss(epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, total_loss: 1.506[0m
[94mBMN val loss(epoch 8): tem_loss: 1.158, pem class_loss: 0.330, pem reg_loss: 0.016, total_loss: 1.646[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.158, pem class_loss: 0.325, pem reg_loss: 0.015, total_loss: 1.638[0m
use Semi !!!
training 3250 (epoch 9): tem_loss: 1.186, pem class_loss: 0.261, pem reg_loss: 0.012, consistency_loss: 0.02012, consistency_loss_ema: 0.01868, total_loss: 1.569
training 3260 (epoch 9): tem_loss: 1.091, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.01984, consistency_loss_ema: 0.02251, total_loss: 1.503
training 3270 (epoch 9): tem_loss: 1.070, pem class_loss: 0.254, pem reg_loss: 0.013, consistency_loss: 0.02030, consistency_loss_ema: 0.02174, total_loss: 1.456
training 3280 (epoch 9): tem_loss: 1.083, pem class_loss: 0.262, pem reg_loss: 0.013, consistency_loss: 0.01998, consistency_loss_ema: 0.02151, total_loss: 1.480
training 3290 (epoch 9): tem_loss: 1.078, pem class_loss: 0.266, pem reg_loss: 0.014, consistency_loss: 0.01995, consistency_loss_ema: 0.02142, total_loss: 1.482
training 3300 (epoch 9): tem_loss: 1.085, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01980, consistency_loss_ema: 0.02148, total_loss: 1.501
training 3310 (epoch 9): tem_loss: 1.081, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.01948, consistency_loss_ema: 0.02127, total_loss: 1.494
training 3320 (epoch 9): tem_loss: 1.083, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.01958, consistency_loss_ema: 0.02125, total_loss: 1.492
training 3330 (epoch 9): tem_loss: 1.086, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.01948, consistency_loss_ema: 0.02130, total_loss: 1.500
training 3340 (epoch 9): tem_loss: 1.087, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.01950, consistency_loss_ema: 0.02128, total_loss: 1.499
training 3350 (epoch 9): tem_loss: 1.088, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01949, consistency_loss_ema: 0.02120, total_loss: 1.502
training 3360 (epoch 9): tem_loss: 1.090, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.01947, consistency_loss_ema: 0.02146, total_loss: 1.500
training 3370 (epoch 9): tem_loss: 1.086, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.01937, consistency_loss_ema: 0.02141, total_loss: 1.496
training 3380 (epoch 9): tem_loss: 1.087, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.01932, consistency_loss_ema: 0.02132, total_loss: 1.495
training 3390 (epoch 9): tem_loss: 1.087, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.01944, consistency_loss_ema: 0.02127, total_loss: 1.498
training 3400 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01945, consistency_loss_ema: 0.02131, total_loss: 1.500
training 3410 (epoch 9): tem_loss: 1.086, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01953, consistency_loss_ema: 0.02137, total_loss: 1.498
training 3420 (epoch 9): tem_loss: 1.086, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01954, consistency_loss_ema: 0.02148, total_loss: 1.498
training 3430 (epoch 9): tem_loss: 1.085, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01957, consistency_loss_ema: 0.02153, total_loss: 1.498
training 3440 (epoch 9): tem_loss: 1.085, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01954, consistency_loss_ema: 0.02151, total_loss: 1.499
training 3450 (epoch 9): tem_loss: 1.085, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01961, consistency_loss_ema: 0.02148, total_loss: 1.497
training 3460 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01959, consistency_loss_ema: 0.02151, total_loss: 1.498
training 3470 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01956, consistency_loss_ema: 0.02155, total_loss: 1.497
training 3480 (epoch 9): tem_loss: 1.086, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01968, consistency_loss_ema: 0.02156, total_loss: 1.496
training 3490 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01967, consistency_loss_ema: 0.02155, total_loss: 1.496
training 3500 (epoch 9): tem_loss: 1.086, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01971, consistency_loss_ema: 0.02151, total_loss: 1.497
training 3510 (epoch 9): tem_loss: 1.088, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01966, consistency_loss_ema: 0.02149, total_loss: 1.498
training 3520 (epoch 9): tem_loss: 1.086, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01966, consistency_loss_ema: 0.02157, total_loss: 1.496
training 3530 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01970, consistency_loss_ema: 0.02161, total_loss: 1.497
training 3540 (epoch 9): tem_loss: 1.087, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01972, consistency_loss_ema: 0.02157, total_loss: 1.496
training 3550 (epoch 9): tem_loss: 1.088, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01977, consistency_loss_ema: 0.02159, total_loss: 1.497
training 3560 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01982, consistency_loss_ema: 0.02160, total_loss: 1.496
training 3570 (epoch 9): tem_loss: 1.087, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01984, consistency_loss_ema: 0.02164, total_loss: 1.495
training 3580 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01982, consistency_loss_ema: 0.02166, total_loss: 1.496
training 3590 (epoch 9): tem_loss: 1.087, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01986, consistency_loss_ema: 0.02166, total_loss: 1.495
training 3600 (epoch 9): tem_loss: 1.087, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01988, consistency_loss_ema: 0.02166, total_loss: 1.497
training 3610 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01994, consistency_loss_ema: 0.02168, total_loss: 1.497
[94mBMN training loss(epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.013, total_loss: 1.497[0m
[94mBMN val loss(epoch 9): tem_loss: 1.159, pem class_loss: 0.329, pem reg_loss: 0.016, total_loss: 1.644[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.158, pem class_loss: 0.328, pem reg_loss: 0.015, total_loss: 1.641[0m
unlabel percent:  0.4
eval student model !!
load : ./checkpoint/Semi-base-0.4-2/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472624
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.17318661730427%
AR@1 is 	 0.3338543809132045
AR@5 is 	 0.49304812834224593
AR@10 is 	 0.5652269299328123
AR@100 is 	 0.7511449334978747
load : ./checkpoint/Semi-base-0.4-2/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472712
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.14902646373234%
AR@1 is 	 0.3348004936240231
AR@5 is 	 0.49385712326888803
AR@10 is 	 0.5662827368709721
AR@100 is 	 0.750363362128068
eval teacher model !!
load : ./checkpoint/Semi-base-0.4-2/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472624
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.1801247771836%
AR@1 is 	 0.3341834635952283
AR@5 is 	 0.49208830385300983
AR@10 is 	 0.5635678047442753
AR@100 is 	 0.7507061565885096
load : ./checkpoint/Semi-base-0.4-2/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472712
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.08220211161388%
AR@1 is 	 0.33618538324420677
AR@5 is 	 0.4922254216371863
AR@10 is 	 0.5631564513917455
AR@100 is 	 0.7495680789798438
#
train subset video numbers: 6737
unlabel unlabeled subset video numbers: 2912
validation subset video numbers: 4728
use 0.7 label for training!!!
training batchsize : 16
unlabel_training batchsize : 8
use Semi !!!
training 1 (epoch 0): tem_loss: 1.402, pem class_loss: 0.693, pem reg_loss: 0.040, consistency_loss: 0.00051, consistency_loss_ema: 0.00000, total_loss: 2.497
training 11 (epoch 0): tem_loss: 1.376, pem class_loss: 0.636, pem reg_loss: 0.037, consistency_loss: 0.00014, consistency_loss_ema: 0.00009, total_loss: 2.383
training 21 (epoch 0): tem_loss: 1.352, pem class_loss: 0.577, pem reg_loss: 0.035, consistency_loss: 0.00013, consistency_loss_ema: 0.00012, total_loss: 2.275
training 31 (epoch 0): tem_loss: 1.334, pem class_loss: 0.526, pem reg_loss: 0.031, consistency_loss: 0.00014, consistency_loss_ema: 0.00013, total_loss: 2.173
training 41 (epoch 0): tem_loss: 1.325, pem class_loss: 0.491, pem reg_loss: 0.029, consistency_loss: 0.00018, consistency_loss_ema: 0.00018, total_loss: 2.106
training 51 (epoch 0): tem_loss: 1.318, pem class_loss: 0.478, pem reg_loss: 0.028, consistency_loss: 0.00019, consistency_loss_ema: 0.00020, total_loss: 2.075
training 61 (epoch 0): tem_loss: 1.300, pem class_loss: 0.458, pem reg_loss: 0.027, consistency_loss: 0.00020, consistency_loss_ema: 0.00021, total_loss: 2.026
training 71 (epoch 0): tem_loss: 1.294, pem class_loss: 0.450, pem reg_loss: 0.026, consistency_loss: 0.00022, consistency_loss_ema: 0.00023, total_loss: 2.006
training 81 (epoch 0): tem_loss: 1.289, pem class_loss: 0.436, pem reg_loss: 0.025, consistency_loss: 0.00024, consistency_loss_ema: 0.00025, total_loss: 1.979
training 91 (epoch 0): tem_loss: 1.282, pem class_loss: 0.429, pem reg_loss: 0.025, consistency_loss: 0.00026, consistency_loss_ema: 0.00028, total_loss: 1.960
training 101 (epoch 0): tem_loss: 1.275, pem class_loss: 0.423, pem reg_loss: 0.024, consistency_loss: 0.00028, consistency_loss_ema: 0.00029, total_loss: 1.943
training 111 (epoch 0): tem_loss: 1.271, pem class_loss: 0.419, pem reg_loss: 0.024, consistency_loss: 0.00028, consistency_loss_ema: 0.00030, total_loss: 1.932
training 121 (epoch 0): tem_loss: 1.269, pem class_loss: 0.417, pem reg_loss: 0.024, consistency_loss: 0.00028, consistency_loss_ema: 0.00030, total_loss: 1.925
training 131 (epoch 0): tem_loss: 1.265, pem class_loss: 0.415, pem reg_loss: 0.024, consistency_loss: 0.00031, consistency_loss_ema: 0.00032, total_loss: 1.916
training 141 (epoch 0): tem_loss: 1.259, pem class_loss: 0.412, pem reg_loss: 0.024, consistency_loss: 0.00032, consistency_loss_ema: 0.00033, total_loss: 1.907
training 151 (epoch 0): tem_loss: 1.253, pem class_loss: 0.410, pem reg_loss: 0.023, consistency_loss: 0.00033, consistency_loss_ema: 0.00034, total_loss: 1.895
training 161 (epoch 0): tem_loss: 1.249, pem class_loss: 0.410, pem reg_loss: 0.023, consistency_loss: 0.00034, consistency_loss_ema: 0.00035, total_loss: 1.891
training 171 (epoch 0): tem_loss: 1.246, pem class_loss: 0.408, pem reg_loss: 0.023, consistency_loss: 0.00034, consistency_loss_ema: 0.00035, total_loss: 1.886
training 181 (epoch 0): tem_loss: 1.243, pem class_loss: 0.405, pem reg_loss: 0.023, consistency_loss: 0.00034, consistency_loss_ema: 0.00036, total_loss: 1.877
training 191 (epoch 0): tem_loss: 1.239, pem class_loss: 0.403, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00036, total_loss: 1.869
training 201 (epoch 0): tem_loss: 1.238, pem class_loss: 0.399, pem reg_loss: 0.022, consistency_loss: 0.00036, consistency_loss_ema: 0.00037, total_loss: 1.862
training 211 (epoch 0): tem_loss: 1.235, pem class_loss: 0.395, pem reg_loss: 0.022, consistency_loss: 0.00036, consistency_loss_ema: 0.00037, total_loss: 1.853
training 221 (epoch 0): tem_loss: 1.232, pem class_loss: 0.392, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00038, total_loss: 1.846
training 231 (epoch 0): tem_loss: 1.229, pem class_loss: 0.390, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00038, total_loss: 1.841
training 241 (epoch 0): tem_loss: 1.226, pem class_loss: 0.389, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00038, total_loss: 1.836
training 251 (epoch 0): tem_loss: 1.224, pem class_loss: 0.388, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00039, total_loss: 1.832
training 261 (epoch 0): tem_loss: 1.223, pem class_loss: 0.388, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00039, total_loss: 1.831
training 271 (epoch 0): tem_loss: 1.221, pem class_loss: 0.386, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.826
training 281 (epoch 0): tem_loss: 1.217, pem class_loss: 0.385, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.821
training 291 (epoch 0): tem_loss: 1.216, pem class_loss: 0.384, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.817
training 301 (epoch 0): tem_loss: 1.216, pem class_loss: 0.384, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.816
training 311 (epoch 0): tem_loss: 1.213, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.812
training 321 (epoch 0): tem_loss: 1.213, pem class_loss: 0.381, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.809
training 331 (epoch 0): tem_loss: 1.211, pem class_loss: 0.380, pem reg_loss: 0.021, consistency_loss: 0.00039, consistency_loss_ema: 0.00040, total_loss: 1.806
training 341 (epoch 0): tem_loss: 1.210, pem class_loss: 0.380, pem reg_loss: 0.021, consistency_loss: 0.00039, consistency_loss_ema: 0.00041, total_loss: 1.804
training 351 (epoch 0): tem_loss: 1.208, pem class_loss: 0.379, pem reg_loss: 0.021, consistency_loss: 0.00040, consistency_loss_ema: 0.00041, total_loss: 1.801
training 361 (epoch 0): tem_loss: 1.207, pem class_loss: 0.378, pem reg_loss: 0.021, consistency_loss: 0.00040, consistency_loss_ema: 0.00042, total_loss: 1.799
training 371 (epoch 0): tem_loss: 1.207, pem class_loss: 0.377, pem reg_loss: 0.021, consistency_loss: 0.00040, consistency_loss_ema: 0.00042, total_loss: 1.797
training 381 (epoch 0): tem_loss: 1.205, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00042, total_loss: 1.795
training 391 (epoch 0): tem_loss: 1.206, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.795
training 401 (epoch 0): tem_loss: 1.205, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.794
training 411 (epoch 0): tem_loss: 1.203, pem class_loss: 0.376, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.792
training 421 (epoch 0): tem_loss: 1.202, pem class_loss: 0.375, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.790
[94mBMN training loss(epoch 0): tem_loss: 1.202, pem class_loss: 0.375, pem reg_loss: 0.021, total_loss: 1.790[0m
[94mBMN val loss(epoch 0): tem_loss: 1.175, pem class_loss: 0.348, pem reg_loss: 0.019, total_loss: 1.717[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.167, pem class_loss: 0.345, pem reg_loss: 0.019, total_loss: 1.704[0m
use Semi !!!
training 422 (epoch 1): tem_loss: 1.228, pem class_loss: 0.309, pem reg_loss: 0.022, consistency_loss: 0.00336, consistency_loss_ema: 0.00255, total_loss: 1.757
training 432 (epoch 1): tem_loss: 1.122, pem class_loss: 0.327, pem reg_loss: 0.019, consistency_loss: 0.00283, consistency_loss_ema: 0.00273, total_loss: 1.635
training 442 (epoch 1): tem_loss: 1.116, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00257, consistency_loss_ema: 0.00259, total_loss: 1.640
training 452 (epoch 1): tem_loss: 1.121, pem class_loss: 0.337, pem reg_loss: 0.019, consistency_loss: 0.00239, consistency_loss_ema: 0.00243, total_loss: 1.651
training 462 (epoch 1): tem_loss: 1.131, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00233, consistency_loss_ema: 0.00235, total_loss: 1.664
training 472 (epoch 1): tem_loss: 1.133, pem class_loss: 0.351, pem reg_loss: 0.020, consistency_loss: 0.00232, consistency_loss_ema: 0.00238, total_loss: 1.680
training 482 (epoch 1): tem_loss: 1.134, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00233, consistency_loss_ema: 0.00239, total_loss: 1.666
training 492 (epoch 1): tem_loss: 1.133, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00241, consistency_loss_ema: 0.00246, total_loss: 1.663
training 502 (epoch 1): tem_loss: 1.135, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00246, consistency_loss_ema: 0.00249, total_loss: 1.669
training 512 (epoch 1): tem_loss: 1.135, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00248, consistency_loss_ema: 0.00248, total_loss: 1.665
training 522 (epoch 1): tem_loss: 1.135, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00247, consistency_loss_ema: 0.00248, total_loss: 1.666
training 532 (epoch 1): tem_loss: 1.133, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00251, consistency_loss_ema: 0.00256, total_loss: 1.662
training 542 (epoch 1): tem_loss: 1.135, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00255, consistency_loss_ema: 0.00266, total_loss: 1.666
training 552 (epoch 1): tem_loss: 1.133, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00256, consistency_loss_ema: 0.00269, total_loss: 1.661
training 562 (epoch 1): tem_loss: 1.129, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00258, consistency_loss_ema: 0.00272, total_loss: 1.656
training 572 (epoch 1): tem_loss: 1.131, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00276, total_loss: 1.655
training 582 (epoch 1): tem_loss: 1.130, pem class_loss: 0.337, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00274, total_loss: 1.654
training 592 (epoch 1): tem_loss: 1.130, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.00258, consistency_loss_ema: 0.00272, total_loss: 1.652
training 602 (epoch 1): tem_loss: 1.129, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00276, total_loss: 1.650
training 612 (epoch 1): tem_loss: 1.128, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00274, total_loss: 1.650
training 622 (epoch 1): tem_loss: 1.128, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00258, consistency_loss_ema: 0.00272, total_loss: 1.649
training 632 (epoch 1): tem_loss: 1.128, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00258, consistency_loss_ema: 0.00271, total_loss: 1.648
training 642 (epoch 1): tem_loss: 1.130, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.00258, consistency_loss_ema: 0.00271, total_loss: 1.651
training 652 (epoch 1): tem_loss: 1.128, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.00259, consistency_loss_ema: 0.00271, total_loss: 1.650
training 662 (epoch 1): tem_loss: 1.129, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00257, consistency_loss_ema: 0.00271, total_loss: 1.653
training 672 (epoch 1): tem_loss: 1.130, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00258, consistency_loss_ema: 0.00272, total_loss: 1.655
training 682 (epoch 1): tem_loss: 1.130, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00274, total_loss: 1.658
training 692 (epoch 1): tem_loss: 1.130, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00274, total_loss: 1.657
training 702 (epoch 1): tem_loss: 1.130, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00264, consistency_loss_ema: 0.00276, total_loss: 1.657
training 712 (epoch 1): tem_loss: 1.129, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00264, consistency_loss_ema: 0.00276, total_loss: 1.657
training 722 (epoch 1): tem_loss: 1.130, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00274, total_loss: 1.658
training 732 (epoch 1): tem_loss: 1.129, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00274, total_loss: 1.658
training 742 (epoch 1): tem_loss: 1.129, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00275, total_loss: 1.657
training 752 (epoch 1): tem_loss: 1.130, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00275, total_loss: 1.658
training 762 (epoch 1): tem_loss: 1.130, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00275, total_loss: 1.657
training 772 (epoch 1): tem_loss: 1.130, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00275, total_loss: 1.656
training 782 (epoch 1): tem_loss: 1.131, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00274, total_loss: 1.657
training 792 (epoch 1): tem_loss: 1.131, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00273, total_loss: 1.657
training 802 (epoch 1): tem_loss: 1.131, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00272, total_loss: 1.657
training 812 (epoch 1): tem_loss: 1.131, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00272, total_loss: 1.658
training 822 (epoch 1): tem_loss: 1.133, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00271, total_loss: 1.659
training 832 (epoch 1): tem_loss: 1.134, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00272, total_loss: 1.659
training 842 (epoch 1): tem_loss: 1.133, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00259, consistency_loss_ema: 0.00271, total_loss: 1.658
[94mBMN training loss(epoch 1): tem_loss: 1.133, pem class_loss: 0.339, pem reg_loss: 0.019, total_loss: 1.658[0m
[94mBMN val loss(epoch 1): tem_loss: 1.152, pem class_loss: 0.336, pem reg_loss: 0.018, total_loss: 1.666[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.145, pem class_loss: 0.333, pem reg_loss: 0.018, total_loss: 1.655[0m
use Semi !!!
training 843 (epoch 2): tem_loss: 1.106, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.01106, consistency_loss_ema: 0.01254, total_loss: 1.600
training 853 (epoch 2): tem_loss: 1.112, pem class_loss: 0.321, pem reg_loss: 0.016, consistency_loss: 0.01029, consistency_loss_ema: 0.01059, total_loss: 1.594
training 863 (epoch 2): tem_loss: 1.086, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01008, consistency_loss_ema: 0.01012, total_loss: 1.566
training 873 (epoch 2): tem_loss: 1.092, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01000, consistency_loss_ema: 0.00996, total_loss: 1.588
training 883 (epoch 2): tem_loss: 1.103, pem class_loss: 0.331, pem reg_loss: 0.017, consistency_loss: 0.00970, consistency_loss_ema: 0.00955, total_loss: 1.607
training 893 (epoch 2): tem_loss: 1.104, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.00928, consistency_loss_ema: 0.00908, total_loss: 1.600
training 903 (epoch 2): tem_loss: 1.098, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.00914, consistency_loss_ema: 0.00901, total_loss: 1.597
training 913 (epoch 2): tem_loss: 1.098, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00908, consistency_loss_ema: 0.00893, total_loss: 1.594
training 923 (epoch 2): tem_loss: 1.095, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00905, consistency_loss_ema: 0.00896, total_loss: 1.592
training 933 (epoch 2): tem_loss: 1.095, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.00893, consistency_loss_ema: 0.00885, total_loss: 1.594
training 943 (epoch 2): tem_loss: 1.101, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.00896, consistency_loss_ema: 0.00883, total_loss: 1.602
training 953 (epoch 2): tem_loss: 1.103, pem class_loss: 0.327, pem reg_loss: 0.017, consistency_loss: 0.00892, consistency_loss_ema: 0.00878, total_loss: 1.603
training 963 (epoch 2): tem_loss: 1.105, pem class_loss: 0.329, pem reg_loss: 0.017, consistency_loss: 0.00896, consistency_loss_ema: 0.00885, total_loss: 1.610
training 973 (epoch 2): tem_loss: 1.110, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00896, consistency_loss_ema: 0.00893, total_loss: 1.617
training 983 (epoch 2): tem_loss: 1.110, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00895, consistency_loss_ema: 0.00897, total_loss: 1.615
training 993 (epoch 2): tem_loss: 1.113, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00886, consistency_loss_ema: 0.00891, total_loss: 1.622
training 1003 (epoch 2): tem_loss: 1.112, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.00880, consistency_loss_ema: 0.00888, total_loss: 1.617
training 1013 (epoch 2): tem_loss: 1.116, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00890, consistency_loss_ema: 0.00900, total_loss: 1.625
training 1023 (epoch 2): tem_loss: 1.115, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00888, consistency_loss_ema: 0.00896, total_loss: 1.625
training 1033 (epoch 2): tem_loss: 1.114, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00882, consistency_loss_ema: 0.00894, total_loss: 1.622
training 1043 (epoch 2): tem_loss: 1.114, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00881, consistency_loss_ema: 0.00891, total_loss: 1.622
training 1053 (epoch 2): tem_loss: 1.114, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00877, consistency_loss_ema: 0.00894, total_loss: 1.620
training 1063 (epoch 2): tem_loss: 1.114, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00874, consistency_loss_ema: 0.00890, total_loss: 1.620
training 1073 (epoch 2): tem_loss: 1.113, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00877, consistency_loss_ema: 0.00894, total_loss: 1.617
training 1083 (epoch 2): tem_loss: 1.112, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00877, consistency_loss_ema: 0.00899, total_loss: 1.616
training 1093 (epoch 2): tem_loss: 1.114, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00876, consistency_loss_ema: 0.00898, total_loss: 1.620
training 1103 (epoch 2): tem_loss: 1.112, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00876, consistency_loss_ema: 0.00895, total_loss: 1.617
training 1113 (epoch 2): tem_loss: 1.112, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00878, consistency_loss_ema: 0.00897, total_loss: 1.617
training 1123 (epoch 2): tem_loss: 1.113, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00879, consistency_loss_ema: 0.00902, total_loss: 1.618
training 1133 (epoch 2): tem_loss: 1.112, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00874, consistency_loss_ema: 0.00897, total_loss: 1.618
training 1143 (epoch 2): tem_loss: 1.113, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00870, consistency_loss_ema: 0.00895, total_loss: 1.616
training 1153 (epoch 2): tem_loss: 1.111, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00868, consistency_loss_ema: 0.00893, total_loss: 1.614
training 1163 (epoch 2): tem_loss: 1.111, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.00866, consistency_loss_ema: 0.00893, total_loss: 1.614
training 1173 (epoch 2): tem_loss: 1.112, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00865, consistency_loss_ema: 0.00889, total_loss: 1.615
training 1183 (epoch 2): tem_loss: 1.114, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00865, consistency_loss_ema: 0.00889, total_loss: 1.618
training 1193 (epoch 2): tem_loss: 1.113, pem class_loss: 0.328, pem reg_loss: 0.018, consistency_loss: 0.00862, consistency_loss_ema: 0.00888, total_loss: 1.617
training 1203 (epoch 2): tem_loss: 1.113, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.00861, consistency_loss_ema: 0.00886, total_loss: 1.616
training 1213 (epoch 2): tem_loss: 1.113, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00861, consistency_loss_ema: 0.00887, total_loss: 1.617
training 1223 (epoch 2): tem_loss: 1.112, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.00861, consistency_loss_ema: 0.00887, total_loss: 1.615
training 1233 (epoch 2): tem_loss: 1.112, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00861, consistency_loss_ema: 0.00888, total_loss: 1.617
training 1243 (epoch 2): tem_loss: 1.111, pem class_loss: 0.329, pem reg_loss: 0.017, consistency_loss: 0.00859, consistency_loss_ema: 0.00886, total_loss: 1.614
training 1253 (epoch 2): tem_loss: 1.112, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.00860, consistency_loss_ema: 0.00889, total_loss: 1.615
training 1263 (epoch 2): tem_loss: 1.110, pem class_loss: 0.329, pem reg_loss: 0.017, consistency_loss: 0.00862, consistency_loss_ema: 0.00892, total_loss: 1.613
[94mBMN training loss(epoch 2): tem_loss: 1.110, pem class_loss: 0.329, pem reg_loss: 0.017, total_loss: 1.613[0m
[94mBMN val loss(epoch 2): tem_loss: 1.142, pem class_loss: 0.331, pem reg_loss: 0.017, total_loss: 1.648[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.138, pem class_loss: 0.328, pem reg_loss: 0.017, total_loss: 1.635[0m
use Semi !!!
training 1264 (epoch 3): tem_loss: 1.104, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02806, consistency_loss_ema: 0.02659, total_loss: 1.550
training 1274 (epoch 3): tem_loss: 1.124, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02260, consistency_loss_ema: 0.02369, total_loss: 1.596
training 1284 (epoch 3): tem_loss: 1.122, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.02095, consistency_loss_ema: 0.02206, total_loss: 1.613
training 1294 (epoch 3): tem_loss: 1.110, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01999, consistency_loss_ema: 0.02085, total_loss: 1.597
training 1304 (epoch 3): tem_loss: 1.111, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01918, consistency_loss_ema: 0.02001, total_loss: 1.596
training 1314 (epoch 3): tem_loss: 1.114, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01920, consistency_loss_ema: 0.01987, total_loss: 1.592
training 1324 (epoch 3): tem_loss: 1.114, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.01969, consistency_loss_ema: 0.02014, total_loss: 1.589
training 1334 (epoch 3): tem_loss: 1.104, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.01934, consistency_loss_ema: 0.01988, total_loss: 1.579
training 1344 (epoch 3): tem_loss: 1.101, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.01958, consistency_loss_ema: 0.02021, total_loss: 1.571
training 1354 (epoch 3): tem_loss: 1.100, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.01943, consistency_loss_ema: 0.02005, total_loss: 1.573
training 1364 (epoch 3): tem_loss: 1.098, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.01907, consistency_loss_ema: 0.01988, total_loss: 1.573
training 1374 (epoch 3): tem_loss: 1.094, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.01902, consistency_loss_ema: 0.01971, total_loss: 1.566
training 1384 (epoch 3): tem_loss: 1.094, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.01894, consistency_loss_ema: 0.01961, total_loss: 1.567
training 1394 (epoch 3): tem_loss: 1.096, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01896, consistency_loss_ema: 0.01973, total_loss: 1.575
training 1404 (epoch 3): tem_loss: 1.096, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01884, consistency_loss_ema: 0.01949, total_loss: 1.575
training 1414 (epoch 3): tem_loss: 1.099, pem class_loss: 0.316, pem reg_loss: 0.017, consistency_loss: 0.01881, consistency_loss_ema: 0.01941, total_loss: 1.582
training 1424 (epoch 3): tem_loss: 1.097, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.01858, consistency_loss_ema: 0.01925, total_loss: 1.578
training 1434 (epoch 3): tem_loss: 1.097, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01853, consistency_loss_ema: 0.01923, total_loss: 1.575
training 1444 (epoch 3): tem_loss: 1.099, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01856, consistency_loss_ema: 0.01924, total_loss: 1.578
training 1454 (epoch 3): tem_loss: 1.102, pem class_loss: 0.316, pem reg_loss: 0.017, consistency_loss: 0.01858, consistency_loss_ema: 0.01932, total_loss: 1.583
training 1464 (epoch 3): tem_loss: 1.102, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.01842, consistency_loss_ema: 0.01920, total_loss: 1.583
training 1474 (epoch 3): tem_loss: 1.103, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.01835, consistency_loss_ema: 0.01915, total_loss: 1.584
training 1484 (epoch 3): tem_loss: 1.101, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.01828, consistency_loss_ema: 0.01909, total_loss: 1.583
training 1494 (epoch 3): tem_loss: 1.103, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01823, consistency_loss_ema: 0.01906, total_loss: 1.587
training 1504 (epoch 3): tem_loss: 1.103, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01818, consistency_loss_ema: 0.01894, total_loss: 1.588
training 1514 (epoch 3): tem_loss: 1.104, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01810, consistency_loss_ema: 0.01886, total_loss: 1.590
training 1524 (epoch 3): tem_loss: 1.104, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01803, consistency_loss_ema: 0.01882, total_loss: 1.591
training 1534 (epoch 3): tem_loss: 1.105, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01793, consistency_loss_ema: 0.01870, total_loss: 1.590
training 1544 (epoch 3): tem_loss: 1.104, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01789, consistency_loss_ema: 0.01865, total_loss: 1.587
training 1554 (epoch 3): tem_loss: 1.103, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01795, consistency_loss_ema: 0.01868, total_loss: 1.585
training 1564 (epoch 3): tem_loss: 1.103, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.01790, consistency_loss_ema: 0.01861, total_loss: 1.584
training 1574 (epoch 3): tem_loss: 1.104, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01777, consistency_loss_ema: 0.01851, total_loss: 1.586
training 1584 (epoch 3): tem_loss: 1.104, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01773, consistency_loss_ema: 0.01840, total_loss: 1.585
training 1594 (epoch 3): tem_loss: 1.103, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.01774, consistency_loss_ema: 0.01842, total_loss: 1.584
training 1604 (epoch 3): tem_loss: 1.103, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01771, consistency_loss_ema: 0.01839, total_loss: 1.585
training 1614 (epoch 3): tem_loss: 1.103, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.01765, consistency_loss_ema: 0.01828, total_loss: 1.586
training 1624 (epoch 3): tem_loss: 1.103, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.01757, consistency_loss_ema: 0.01821, total_loss: 1.587
training 1634 (epoch 3): tem_loss: 1.104, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.01752, consistency_loss_ema: 0.01816, total_loss: 1.588
training 1644 (epoch 3): tem_loss: 1.104, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.01755, consistency_loss_ema: 0.01814, total_loss: 1.588
training 1654 (epoch 3): tem_loss: 1.104, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.01747, consistency_loss_ema: 0.01810, total_loss: 1.587
training 1664 (epoch 3): tem_loss: 1.104, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.01742, consistency_loss_ema: 0.01805, total_loss: 1.587
training 1674 (epoch 3): tem_loss: 1.104, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01737, consistency_loss_ema: 0.01799, total_loss: 1.586
training 1684 (epoch 3): tem_loss: 1.104, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.01734, consistency_loss_ema: 0.01792, total_loss: 1.586
[94mBMN training loss(epoch 3): tem_loss: 1.104, pem class_loss: 0.318, pem reg_loss: 0.016, total_loss: 1.586[0m
[94mBMN val loss(epoch 3): tem_loss: 1.144, pem class_loss: 0.326, pem reg_loss: 0.017, total_loss: 1.637[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.142, pem class_loss: 0.322, pem reg_loss: 0.016, total_loss: 1.625[0m
use Semi !!!
training 1685 (epoch 4): tem_loss: 1.001, pem class_loss: 0.231, pem reg_loss: 0.016, consistency_loss: 0.02273, consistency_loss_ema: 0.03515, total_loss: 1.389
training 1695 (epoch 4): tem_loss: 1.084, pem class_loss: 0.296, pem reg_loss: 0.016, consistency_loss: 0.02553, consistency_loss_ema: 0.02797, total_loss: 1.538
training 1705 (epoch 4): tem_loss: 1.095, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02491, consistency_loss_ema: 0.02788, total_loss: 1.543
training 1715 (epoch 4): tem_loss: 1.090, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02465, consistency_loss_ema: 0.02676, total_loss: 1.536
training 1725 (epoch 4): tem_loss: 1.090, pem class_loss: 0.295, pem reg_loss: 0.016, consistency_loss: 0.02445, consistency_loss_ema: 0.02706, total_loss: 1.540
training 1735 (epoch 4): tem_loss: 1.091, pem class_loss: 0.298, pem reg_loss: 0.016, consistency_loss: 0.02418, consistency_loss_ema: 0.02644, total_loss: 1.545
training 1745 (epoch 4): tem_loss: 1.094, pem class_loss: 0.298, pem reg_loss: 0.016, consistency_loss: 0.02412, consistency_loss_ema: 0.02610, total_loss: 1.549
training 1755 (epoch 4): tem_loss: 1.100, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.02399, consistency_loss_ema: 0.02575, total_loss: 1.561
training 1765 (epoch 4): tem_loss: 1.101, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02419, consistency_loss_ema: 0.02575, total_loss: 1.566
training 1775 (epoch 4): tem_loss: 1.099, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02441, consistency_loss_ema: 0.02577, total_loss: 1.563
training 1785 (epoch 4): tem_loss: 1.099, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02438, consistency_loss_ema: 0.02589, total_loss: 1.563
training 1795 (epoch 4): tem_loss: 1.098, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02428, consistency_loss_ema: 0.02598, total_loss: 1.561
training 1805 (epoch 4): tem_loss: 1.099, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02425, consistency_loss_ema: 0.02600, total_loss: 1.563
training 1815 (epoch 4): tem_loss: 1.100, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02418, consistency_loss_ema: 0.02602, total_loss: 1.568
training 1825 (epoch 4): tem_loss: 1.099, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02414, consistency_loss_ema: 0.02603, total_loss: 1.568
training 1835 (epoch 4): tem_loss: 1.098, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02404, consistency_loss_ema: 0.02592, total_loss: 1.565
training 1845 (epoch 4): tem_loss: 1.099, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02407, consistency_loss_ema: 0.02591, total_loss: 1.565
training 1855 (epoch 4): tem_loss: 1.097, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02407, consistency_loss_ema: 0.02592, total_loss: 1.561
training 1865 (epoch 4): tem_loss: 1.095, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02407, consistency_loss_ema: 0.02595, total_loss: 1.560
training 1875 (epoch 4): tem_loss: 1.094, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02394, consistency_loss_ema: 0.02587, total_loss: 1.558
training 1885 (epoch 4): tem_loss: 1.097, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02403, consistency_loss_ema: 0.02588, total_loss: 1.564
training 1895 (epoch 4): tem_loss: 1.098, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02406, consistency_loss_ema: 0.02578, total_loss: 1.565
training 1905 (epoch 4): tem_loss: 1.101, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02405, consistency_loss_ema: 0.02565, total_loss: 1.569
training 1915 (epoch 4): tem_loss: 1.100, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02403, consistency_loss_ema: 0.02563, total_loss: 1.566
training 1925 (epoch 4): tem_loss: 1.100, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02400, consistency_loss_ema: 0.02548, total_loss: 1.564
training 1935 (epoch 4): tem_loss: 1.101, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02396, consistency_loss_ema: 0.02548, total_loss: 1.564
training 1945 (epoch 4): tem_loss: 1.101, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02395, consistency_loss_ema: 0.02556, total_loss: 1.564
training 1955 (epoch 4): tem_loss: 1.101, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02396, consistency_loss_ema: 0.02557, total_loss: 1.564
training 1965 (epoch 4): tem_loss: 1.101, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02400, consistency_loss_ema: 0.02553, total_loss: 1.565
training 1975 (epoch 4): tem_loss: 1.101, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02403, consistency_loss_ema: 0.02550, total_loss: 1.565
training 1985 (epoch 4): tem_loss: 1.101, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02390, consistency_loss_ema: 0.02540, total_loss: 1.566
training 1995 (epoch 4): tem_loss: 1.101, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02384, consistency_loss_ema: 0.02537, total_loss: 1.567
training 2005 (epoch 4): tem_loss: 1.102, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02388, consistency_loss_ema: 0.02539, total_loss: 1.567
training 2015 (epoch 4): tem_loss: 1.102, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02383, consistency_loss_ema: 0.02530, total_loss: 1.567
training 2025 (epoch 4): tem_loss: 1.103, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02384, consistency_loss_ema: 0.02527, total_loss: 1.568
training 2035 (epoch 4): tem_loss: 1.103, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02381, consistency_loss_ema: 0.02522, total_loss: 1.568
training 2045 (epoch 4): tem_loss: 1.103, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02374, consistency_loss_ema: 0.02511, total_loss: 1.570
training 2055 (epoch 4): tem_loss: 1.105, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02367, consistency_loss_ema: 0.02505, total_loss: 1.571
training 2065 (epoch 4): tem_loss: 1.104, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02367, consistency_loss_ema: 0.02501, total_loss: 1.570
training 2075 (epoch 4): tem_loss: 1.104, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02372, consistency_loss_ema: 0.02494, total_loss: 1.570
training 2085 (epoch 4): tem_loss: 1.104, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02371, consistency_loss_ema: 0.02491, total_loss: 1.569
training 2095 (epoch 4): tem_loss: 1.103, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02372, consistency_loss_ema: 0.02492, total_loss: 1.569
training 2105 (epoch 4): tem_loss: 1.104, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.02372, consistency_loss_ema: 0.02483, total_loss: 1.570
[94mBMN training loss(epoch 4): tem_loss: 1.104, pem class_loss: 0.310, pem reg_loss: 0.016, total_loss: 1.570[0m
[94mBMN val loss(epoch 4): tem_loss: 1.156, pem class_loss: 0.324, pem reg_loss: 0.016, total_loss: 1.643[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.149, pem class_loss: 0.320, pem reg_loss: 0.016, total_loss: 1.627[0m
use Semi !!!
training 2106 (epoch 5): tem_loss: 1.210, pem class_loss: 0.265, pem reg_loss: 0.016, consistency_loss: 0.03000, consistency_loss_ema: 0.02354, total_loss: 1.634
training 2116 (epoch 5): tem_loss: 1.112, pem class_loss: 0.268, pem reg_loss: 0.014, consistency_loss: 0.02928, consistency_loss_ema: 0.03150, total_loss: 1.517
training 2126 (epoch 5): tem_loss: 1.112, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02923, consistency_loss_ema: 0.03135, total_loss: 1.533
training 2136 (epoch 5): tem_loss: 1.110, pem class_loss: 0.289, pem reg_loss: 0.015, consistency_loss: 0.02867, consistency_loss_ema: 0.03234, total_loss: 1.545
training 2146 (epoch 5): tem_loss: 1.110, pem class_loss: 0.291, pem reg_loss: 0.015, consistency_loss: 0.02827, consistency_loss_ema: 0.03122, total_loss: 1.549
training 2156 (epoch 5): tem_loss: 1.115, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02781, consistency_loss_ema: 0.03083, total_loss: 1.553
training 2166 (epoch 5): tem_loss: 1.117, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02791, consistency_loss_ema: 0.03062, total_loss: 1.564
training 2176 (epoch 5): tem_loss: 1.113, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02781, consistency_loss_ema: 0.03056, total_loss: 1.559
training 2186 (epoch 5): tem_loss: 1.115, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02763, consistency_loss_ema: 0.03057, total_loss: 1.573
training 2196 (epoch 5): tem_loss: 1.116, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02737, consistency_loss_ema: 0.03002, total_loss: 1.578
training 2206 (epoch 5): tem_loss: 1.120, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02728, consistency_loss_ema: 0.02974, total_loss: 1.582
training 2216 (epoch 5): tem_loss: 1.117, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02690, consistency_loss_ema: 0.02946, total_loss: 1.577
training 2226 (epoch 5): tem_loss: 1.119, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02683, consistency_loss_ema: 0.02924, total_loss: 1.580
training 2236 (epoch 5): tem_loss: 1.120, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02672, consistency_loss_ema: 0.02937, total_loss: 1.579
training 2246 (epoch 5): tem_loss: 1.116, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02680, consistency_loss_ema: 0.02945, total_loss: 1.574
training 2256 (epoch 5): tem_loss: 1.113, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02692, consistency_loss_ema: 0.02934, total_loss: 1.571
training 2266 (epoch 5): tem_loss: 1.112, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02680, consistency_loss_ema: 0.02923, total_loss: 1.569
training 2276 (epoch 5): tem_loss: 1.115, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02673, consistency_loss_ema: 0.02901, total_loss: 1.573
training 2286 (epoch 5): tem_loss: 1.111, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02663, consistency_loss_ema: 0.02879, total_loss: 1.568
training 2296 (epoch 5): tem_loss: 1.113, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02646, consistency_loss_ema: 0.02860, total_loss: 1.572
training 2306 (epoch 5): tem_loss: 1.113, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02630, consistency_loss_ema: 0.02840, total_loss: 1.570
training 2316 (epoch 5): tem_loss: 1.112, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02623, consistency_loss_ema: 0.02822, total_loss: 1.569
training 2326 (epoch 5): tem_loss: 1.112, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02619, consistency_loss_ema: 0.02825, total_loss: 1.569
training 2336 (epoch 5): tem_loss: 1.110, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02622, consistency_loss_ema: 0.02834, total_loss: 1.565
training 2346 (epoch 5): tem_loss: 1.111, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02616, consistency_loss_ema: 0.02824, total_loss: 1.566
training 2356 (epoch 5): tem_loss: 1.111, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02596, consistency_loss_ema: 0.02812, total_loss: 1.564
training 2366 (epoch 5): tem_loss: 1.109, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02593, consistency_loss_ema: 0.02815, total_loss: 1.562
training 2376 (epoch 5): tem_loss: 1.108, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02584, consistency_loss_ema: 0.02808, total_loss: 1.561
training 2386 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02584, consistency_loss_ema: 0.02810, total_loss: 1.563
training 2396 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02581, consistency_loss_ema: 0.02800, total_loss: 1.563
training 2406 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02587, consistency_loss_ema: 0.02798, total_loss: 1.562
training 2416 (epoch 5): tem_loss: 1.110, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02582, consistency_loss_ema: 0.02802, total_loss: 1.563
training 2426 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02577, consistency_loss_ema: 0.02798, total_loss: 1.562
training 2436 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02573, consistency_loss_ema: 0.02797, total_loss: 1.563
training 2446 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02581, consistency_loss_ema: 0.02799, total_loss: 1.562
training 2456 (epoch 5): tem_loss: 1.110, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02579, consistency_loss_ema: 0.02801, total_loss: 1.563
training 2466 (epoch 5): tem_loss: 1.109, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02586, consistency_loss_ema: 0.02799, total_loss: 1.562
training 2476 (epoch 5): tem_loss: 1.110, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02588, consistency_loss_ema: 0.02800, total_loss: 1.563
training 2486 (epoch 5): tem_loss: 1.111, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02584, consistency_loss_ema: 0.02793, total_loss: 1.563
training 2496 (epoch 5): tem_loss: 1.111, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02581, consistency_loss_ema: 0.02784, total_loss: 1.563
training 2506 (epoch 5): tem_loss: 1.110, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02579, consistency_loss_ema: 0.02780, total_loss: 1.562
training 2516 (epoch 5): tem_loss: 1.109, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02584, consistency_loss_ema: 0.02782, total_loss: 1.560
training 2526 (epoch 5): tem_loss: 1.110, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02582, consistency_loss_ema: 0.02783, total_loss: 1.561
[94mBMN training loss(epoch 5): tem_loss: 1.110, pem class_loss: 0.302, pem reg_loss: 0.015, total_loss: 1.561[0m
[94mBMN val loss(epoch 5): tem_loss: 1.162, pem class_loss: 0.326, pem reg_loss: 0.016, total_loss: 1.646[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.154, pem class_loss: 0.320, pem reg_loss: 0.015, total_loss: 1.630[0m
use Semi !!!
training 2527 (epoch 6): tem_loss: 1.096, pem class_loss: 0.280, pem reg_loss: 0.015, consistency_loss: 0.02661, consistency_loss_ema: 0.02883, total_loss: 1.522
training 2537 (epoch 6): tem_loss: 1.089, pem class_loss: 0.295, pem reg_loss: 0.016, consistency_loss: 0.02522, consistency_loss_ema: 0.02495, total_loss: 1.539
training 2547 (epoch 6): tem_loss: 1.106, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02583, consistency_loss_ema: 0.02628, total_loss: 1.556
training 2557 (epoch 6): tem_loss: 1.105, pem class_loss: 0.288, pem reg_loss: 0.015, consistency_loss: 0.02542, consistency_loss_ema: 0.02615, total_loss: 1.542
training 2567 (epoch 6): tem_loss: 1.117, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02595, total_loss: 1.557
training 2577 (epoch 6): tem_loss: 1.111, pem class_loss: 0.289, pem reg_loss: 0.015, consistency_loss: 0.02471, consistency_loss_ema: 0.02599, total_loss: 1.546
training 2587 (epoch 6): tem_loss: 1.117, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02477, consistency_loss_ema: 0.02585, total_loss: 1.564
training 2597 (epoch 6): tem_loss: 1.116, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02490, consistency_loss_ema: 0.02609, total_loss: 1.562
training 2607 (epoch 6): tem_loss: 1.114, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02481, consistency_loss_ema: 0.02655, total_loss: 1.557
training 2617 (epoch 6): tem_loss: 1.109, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02463, consistency_loss_ema: 0.02641, total_loss: 1.551
training 2627 (epoch 6): tem_loss: 1.108, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02452, consistency_loss_ema: 0.02635, total_loss: 1.548
training 2637 (epoch 6): tem_loss: 1.108, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02451, consistency_loss_ema: 0.02613, total_loss: 1.550
training 2647 (epoch 6): tem_loss: 1.110, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02472, consistency_loss_ema: 0.02618, total_loss: 1.550
training 2657 (epoch 6): tem_loss: 1.109, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02463, consistency_loss_ema: 0.02623, total_loss: 1.549
training 2667 (epoch 6): tem_loss: 1.110, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02461, consistency_loss_ema: 0.02635, total_loss: 1.550
training 2677 (epoch 6): tem_loss: 1.111, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02470, consistency_loss_ema: 0.02663, total_loss: 1.555
training 2687 (epoch 6): tem_loss: 1.111, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02471, consistency_loss_ema: 0.02651, total_loss: 1.556
training 2697 (epoch 6): tem_loss: 1.112, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02477, consistency_loss_ema: 0.02664, total_loss: 1.555
training 2707 (epoch 6): tem_loss: 1.111, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02486, consistency_loss_ema: 0.02683, total_loss: 1.556
training 2717 (epoch 6): tem_loss: 1.113, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02493, consistency_loss_ema: 0.02672, total_loss: 1.558
training 2727 (epoch 6): tem_loss: 1.112, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02499, consistency_loss_ema: 0.02673, total_loss: 1.558
training 2737 (epoch 6): tem_loss: 1.112, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02666, total_loss: 1.556
training 2747 (epoch 6): tem_loss: 1.111, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02507, consistency_loss_ema: 0.02665, total_loss: 1.558
training 2757 (epoch 6): tem_loss: 1.111, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02514, consistency_loss_ema: 0.02669, total_loss: 1.558
training 2767 (epoch 6): tem_loss: 1.111, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02540, consistency_loss_ema: 0.02684, total_loss: 1.558
training 2777 (epoch 6): tem_loss: 1.112, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02547, consistency_loss_ema: 0.02701, total_loss: 1.558
training 2787 (epoch 6): tem_loss: 1.112, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02554, consistency_loss_ema: 0.02707, total_loss: 1.559
training 2797 (epoch 6): tem_loss: 1.112, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02554, consistency_loss_ema: 0.02709, total_loss: 1.557
training 2807 (epoch 6): tem_loss: 1.110, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02558, consistency_loss_ema: 0.02717, total_loss: 1.553
training 2817 (epoch 6): tem_loss: 1.110, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02556, consistency_loss_ema: 0.02717, total_loss: 1.553
training 2827 (epoch 6): tem_loss: 1.110, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02558, consistency_loss_ema: 0.02717, total_loss: 1.552
training 2837 (epoch 6): tem_loss: 1.110, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02560, consistency_loss_ema: 0.02710, total_loss: 1.553
training 2847 (epoch 6): tem_loss: 1.110, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02557, consistency_loss_ema: 0.02710, total_loss: 1.553
training 2857 (epoch 6): tem_loss: 1.110, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02560, consistency_loss_ema: 0.02714, total_loss: 1.553
training 2867 (epoch 6): tem_loss: 1.109, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02557, consistency_loss_ema: 0.02713, total_loss: 1.551
training 2877 (epoch 6): tem_loss: 1.108, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02554, consistency_loss_ema: 0.02717, total_loss: 1.549
training 2887 (epoch 6): tem_loss: 1.107, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02555, consistency_loss_ema: 0.02722, total_loss: 1.550
training 2897 (epoch 6): tem_loss: 1.108, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02553, consistency_loss_ema: 0.02730, total_loss: 1.551
training 2907 (epoch 6): tem_loss: 1.108, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02552, consistency_loss_ema: 0.02730, total_loss: 1.552
training 2917 (epoch 6): tem_loss: 1.107, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02551, consistency_loss_ema: 0.02737, total_loss: 1.550
training 2927 (epoch 6): tem_loss: 1.108, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02551, consistency_loss_ema: 0.02739, total_loss: 1.552
training 2937 (epoch 6): tem_loss: 1.109, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02545, consistency_loss_ema: 0.02725, total_loss: 1.553
training 2947 (epoch 6): tem_loss: 1.108, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02541, consistency_loss_ema: 0.02723, total_loss: 1.552
[94mBMN training loss(epoch 6): tem_loss: 1.108, pem class_loss: 0.298, pem reg_loss: 0.015, total_loss: 1.552[0m
[94mBMN val loss(epoch 6): tem_loss: 1.156, pem class_loss: 0.325, pem reg_loss: 0.016, total_loss: 1.639[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.155, pem class_loss: 0.319, pem reg_loss: 0.015, total_loss: 1.628[0m
use Semi !!!
training 2948 (epoch 7): tem_loss: 1.183, pem class_loss: 0.237, pem reg_loss: 0.011, consistency_loss: 0.02445, consistency_loss_ema: 0.02564, total_loss: 1.534
training 2958 (epoch 7): tem_loss: 1.113, pem class_loss: 0.270, pem reg_loss: 0.014, consistency_loss: 0.02420, consistency_loss_ema: 0.02538, total_loss: 1.520
training 2968 (epoch 7): tem_loss: 1.104, pem class_loss: 0.283, pem reg_loss: 0.013, consistency_loss: 0.02181, consistency_loss_ema: 0.02383, total_loss: 1.522
training 2978 (epoch 7): tem_loss: 1.099, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.02091, consistency_loss_ema: 0.02249, total_loss: 1.521
training 2988 (epoch 7): tem_loss: 1.087, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02062, consistency_loss_ema: 0.02152, total_loss: 1.508
training 2998 (epoch 7): tem_loss: 1.086, pem class_loss: 0.274, pem reg_loss: 0.014, consistency_loss: 0.02020, consistency_loss_ema: 0.02090, total_loss: 1.498
training 3008 (epoch 7): tem_loss: 1.083, pem class_loss: 0.273, pem reg_loss: 0.014, consistency_loss: 0.01987, consistency_loss_ema: 0.02090, total_loss: 1.493
training 3018 (epoch 7): tem_loss: 1.086, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01951, consistency_loss_ema: 0.02080, total_loss: 1.491
training 3028 (epoch 7): tem_loss: 1.082, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.01925, consistency_loss_ema: 0.02078, total_loss: 1.489
training 3038 (epoch 7): tem_loss: 1.082, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01889, consistency_loss_ema: 0.02052, total_loss: 1.490
training 3048 (epoch 7): tem_loss: 1.083, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01881, consistency_loss_ema: 0.02027, total_loss: 1.492
training 3058 (epoch 7): tem_loss: 1.084, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01862, consistency_loss_ema: 0.01999, total_loss: 1.493
training 3068 (epoch 7): tem_loss: 1.085, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01852, consistency_loss_ema: 0.01983, total_loss: 1.497
training 3078 (epoch 7): tem_loss: 1.087, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01837, consistency_loss_ema: 0.01976, total_loss: 1.501
training 3088 (epoch 7): tem_loss: 1.087, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01832, consistency_loss_ema: 0.01961, total_loss: 1.504
training 3098 (epoch 7): tem_loss: 1.088, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01819, consistency_loss_ema: 0.01946, total_loss: 1.504
training 3108 (epoch 7): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01811, consistency_loss_ema: 0.01938, total_loss: 1.506
training 3118 (epoch 7): tem_loss: 1.091, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01801, consistency_loss_ema: 0.01923, total_loss: 1.509
training 3128 (epoch 7): tem_loss: 1.093, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01800, consistency_loss_ema: 0.01910, total_loss: 1.513
training 3138 (epoch 7): tem_loss: 1.092, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01793, consistency_loss_ema: 0.01901, total_loss: 1.511
training 3148 (epoch 7): tem_loss: 1.091, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01784, consistency_loss_ema: 0.01901, total_loss: 1.509
training 3158 (epoch 7): tem_loss: 1.091, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01784, consistency_loss_ema: 0.01898, total_loss: 1.507
training 3168 (epoch 7): tem_loss: 1.091, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01775, consistency_loss_ema: 0.01890, total_loss: 1.508
training 3178 (epoch 7): tem_loss: 1.092, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01766, consistency_loss_ema: 0.01883, total_loss: 1.510
training 3188 (epoch 7): tem_loss: 1.093, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01766, consistency_loss_ema: 0.01882, total_loss: 1.511
training 3198 (epoch 7): tem_loss: 1.094, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01767, consistency_loss_ema: 0.01878, total_loss: 1.514
training 3208 (epoch 7): tem_loss: 1.093, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01767, consistency_loss_ema: 0.01877, total_loss: 1.514
training 3218 (epoch 7): tem_loss: 1.093, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01762, consistency_loss_ema: 0.01875, total_loss: 1.513
training 3228 (epoch 7): tem_loss: 1.094, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01759, consistency_loss_ema: 0.01872, total_loss: 1.514
training 3238 (epoch 7): tem_loss: 1.093, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01762, consistency_loss_ema: 0.01869, total_loss: 1.511
training 3248 (epoch 7): tem_loss: 1.094, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01763, consistency_loss_ema: 0.01875, total_loss: 1.511
training 3258 (epoch 7): tem_loss: 1.095, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01760, consistency_loss_ema: 0.01872, total_loss: 1.513
training 3268 (epoch 7): tem_loss: 1.095, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01757, consistency_loss_ema: 0.01867, total_loss: 1.513
training 3278 (epoch 7): tem_loss: 1.095, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01755, consistency_loss_ema: 0.01863, total_loss: 1.515
training 3288 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01751, consistency_loss_ema: 0.01863, total_loss: 1.517
training 3298 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01752, consistency_loss_ema: 0.01859, total_loss: 1.517
training 3308 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01748, consistency_loss_ema: 0.01860, total_loss: 1.517
training 3318 (epoch 7): tem_loss: 1.098, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01744, consistency_loss_ema: 0.01861, total_loss: 1.518
training 3328 (epoch 7): tem_loss: 1.096, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01742, consistency_loss_ema: 0.01861, total_loss: 1.515
training 3338 (epoch 7): tem_loss: 1.096, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01740, consistency_loss_ema: 0.01869, total_loss: 1.514
training 3348 (epoch 7): tem_loss: 1.096, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01739, consistency_loss_ema: 0.01870, total_loss: 1.513
training 3358 (epoch 7): tem_loss: 1.096, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01738, consistency_loss_ema: 0.01869, total_loss: 1.514
training 3368 (epoch 7): tem_loss: 1.095, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01736, consistency_loss_ema: 0.01867, total_loss: 1.513
[94mBMN training loss(epoch 7): tem_loss: 1.095, pem class_loss: 0.281, pem reg_loss: 0.014, total_loss: 1.513[0m
[94mBMN val loss(epoch 7): tem_loss: 1.152, pem class_loss: 0.323, pem reg_loss: 0.015, total_loss: 1.628[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.153, pem class_loss: 0.322, pem reg_loss: 0.015, total_loss: 1.628[0m
use Semi !!!
training 3369 (epoch 8): tem_loss: 1.031, pem class_loss: 0.283, pem reg_loss: 0.012, consistency_loss: 0.01655, consistency_loss_ema: 0.02625, total_loss: 1.431
training 3379 (epoch 8): tem_loss: 1.079, pem class_loss: 0.268, pem reg_loss: 0.013, consistency_loss: 0.01717, consistency_loss_ema: 0.01747, total_loss: 1.476
training 3389 (epoch 8): tem_loss: 1.093, pem class_loss: 0.283, pem reg_loss: 0.013, consistency_loss: 0.01746, consistency_loss_ema: 0.01730, total_loss: 1.512
training 3399 (epoch 8): tem_loss: 1.073, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01736, consistency_loss_ema: 0.01834, total_loss: 1.472
training 3409 (epoch 8): tem_loss: 1.077, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01759, consistency_loss_ema: 0.01899, total_loss: 1.484
training 3419 (epoch 8): tem_loss: 1.076, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01755, consistency_loss_ema: 0.01897, total_loss: 1.487
training 3429 (epoch 8): tem_loss: 1.083, pem class_loss: 0.282, pem reg_loss: 0.013, consistency_loss: 0.01765, consistency_loss_ema: 0.01926, total_loss: 1.499
training 3439 (epoch 8): tem_loss: 1.084, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01767, consistency_loss_ema: 0.01934, total_loss: 1.499
training 3449 (epoch 8): tem_loss: 1.089, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01754, consistency_loss_ema: 0.01926, total_loss: 1.503
training 3459 (epoch 8): tem_loss: 1.091, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01750, consistency_loss_ema: 0.01899, total_loss: 1.507
training 3469 (epoch 8): tem_loss: 1.092, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01756, consistency_loss_ema: 0.01921, total_loss: 1.505
training 3479 (epoch 8): tem_loss: 1.090, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01752, consistency_loss_ema: 0.01923, total_loss: 1.504
training 3489 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01753, consistency_loss_ema: 0.01915, total_loss: 1.502
training 3499 (epoch 8): tem_loss: 1.088, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01757, consistency_loss_ema: 0.01923, total_loss: 1.500
training 3509 (epoch 8): tem_loss: 1.089, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01761, consistency_loss_ema: 0.01921, total_loss: 1.500
training 3519 (epoch 8): tem_loss: 1.088, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01765, consistency_loss_ema: 0.01921, total_loss: 1.501
training 3529 (epoch 8): tem_loss: 1.087, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01762, consistency_loss_ema: 0.01928, total_loss: 1.499
training 3539 (epoch 8): tem_loss: 1.088, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01761, consistency_loss_ema: 0.01935, total_loss: 1.499
training 3549 (epoch 8): tem_loss: 1.089, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01758, consistency_loss_ema: 0.01927, total_loss: 1.499
training 3559 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01765, consistency_loss_ema: 0.01936, total_loss: 1.501
training 3569 (epoch 8): tem_loss: 1.092, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01768, consistency_loss_ema: 0.01941, total_loss: 1.505
training 3579 (epoch 8): tem_loss: 1.091, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01768, consistency_loss_ema: 0.01933, total_loss: 1.502
training 3589 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01769, consistency_loss_ema: 0.01940, total_loss: 1.501
training 3599 (epoch 8): tem_loss: 1.091, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01767, consistency_loss_ema: 0.01943, total_loss: 1.502
training 3609 (epoch 8): tem_loss: 1.089, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01773, consistency_loss_ema: 0.01948, total_loss: 1.500
training 3619 (epoch 8): tem_loss: 1.089, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01774, consistency_loss_ema: 0.01955, total_loss: 1.500
training 3629 (epoch 8): tem_loss: 1.088, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01776, consistency_loss_ema: 0.01952, total_loss: 1.500
training 3639 (epoch 8): tem_loss: 1.087, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01785, consistency_loss_ema: 0.01956, total_loss: 1.497
training 3649 (epoch 8): tem_loss: 1.088, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01793, consistency_loss_ema: 0.01964, total_loss: 1.497
training 3659 (epoch 8): tem_loss: 1.088, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01798, consistency_loss_ema: 0.01960, total_loss: 1.496
training 3669 (epoch 8): tem_loss: 1.088, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01802, consistency_loss_ema: 0.01960, total_loss: 1.498
training 3679 (epoch 8): tem_loss: 1.089, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01801, consistency_loss_ema: 0.01959, total_loss: 1.500
training 3689 (epoch 8): tem_loss: 1.089, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01800, consistency_loss_ema: 0.01960, total_loss: 1.501
training 3699 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01800, consistency_loss_ema: 0.01965, total_loss: 1.502
training 3709 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01803, consistency_loss_ema: 0.01963, total_loss: 1.502
training 3719 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01806, consistency_loss_ema: 0.01964, total_loss: 1.502
training 3729 (epoch 8): tem_loss: 1.089, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01807, consistency_loss_ema: 0.01974, total_loss: 1.500
training 3739 (epoch 8): tem_loss: 1.089, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01804, consistency_loss_ema: 0.01979, total_loss: 1.499
training 3749 (epoch 8): tem_loss: 1.089, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01806, consistency_loss_ema: 0.01987, total_loss: 1.500
training 3759 (epoch 8): tem_loss: 1.089, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01809, consistency_loss_ema: 0.01994, total_loss: 1.499
training 3769 (epoch 8): tem_loss: 1.088, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01814, consistency_loss_ema: 0.01998, total_loss: 1.498
training 3779 (epoch 8): tem_loss: 1.090, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01815, consistency_loss_ema: 0.01998, total_loss: 1.500
training 3789 (epoch 8): tem_loss: 1.090, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01816, consistency_loss_ema: 0.02001, total_loss: 1.500
[94mBMN training loss(epoch 8): tem_loss: 1.090, pem class_loss: 0.276, pem reg_loss: 0.013, total_loss: 1.500[0m
[94mBMN val loss(epoch 8): tem_loss: 1.151, pem class_loss: 0.325, pem reg_loss: 0.015, total_loss: 1.628[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.152, pem class_loss: 0.325, pem reg_loss: 0.015, total_loss: 1.629[0m
use Semi !!!
training 3790 (epoch 9): tem_loss: 1.113, pem class_loss: 0.249, pem reg_loss: 0.015, consistency_loss: 0.01891, consistency_loss_ema: 0.01827, total_loss: 1.507
training 3800 (epoch 9): tem_loss: 1.080, pem class_loss: 0.266, pem reg_loss: 0.014, consistency_loss: 0.02096, consistency_loss_ema: 0.02141, total_loss: 1.489
training 3810 (epoch 9): tem_loss: 1.083, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02001, consistency_loss_ema: 0.02194, total_loss: 1.503
training 3820 (epoch 9): tem_loss: 1.087, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01958, consistency_loss_ema: 0.02181, total_loss: 1.499
training 3830 (epoch 9): tem_loss: 1.080, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01948, consistency_loss_ema: 0.02136, total_loss: 1.485
training 3840 (epoch 9): tem_loss: 1.083, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01968, consistency_loss_ema: 0.02108, total_loss: 1.488
training 3850 (epoch 9): tem_loss: 1.083, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01939, consistency_loss_ema: 0.02164, total_loss: 1.487
training 3860 (epoch 9): tem_loss: 1.083, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01942, consistency_loss_ema: 0.02165, total_loss: 1.483
training 3870 (epoch 9): tem_loss: 1.088, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01958, consistency_loss_ema: 0.02174, total_loss: 1.490
training 3880 (epoch 9): tem_loss: 1.086, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01953, consistency_loss_ema: 0.02169, total_loss: 1.487
training 3890 (epoch 9): tem_loss: 1.088, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01947, consistency_loss_ema: 0.02170, total_loss: 1.489
training 3900 (epoch 9): tem_loss: 1.087, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01938, consistency_loss_ema: 0.02158, total_loss: 1.488
training 3910 (epoch 9): tem_loss: 1.088, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01940, consistency_loss_ema: 0.02144, total_loss: 1.491
training 3920 (epoch 9): tem_loss: 1.088, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01938, consistency_loss_ema: 0.02128, total_loss: 1.490
training 3930 (epoch 9): tem_loss: 1.088, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01939, consistency_loss_ema: 0.02120, total_loss: 1.492
training 3940 (epoch 9): tem_loss: 1.088, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01938, consistency_loss_ema: 0.02137, total_loss: 1.491
training 3950 (epoch 9): tem_loss: 1.087, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01946, consistency_loss_ema: 0.02142, total_loss: 1.490
training 3960 (epoch 9): tem_loss: 1.087, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01954, consistency_loss_ema: 0.02149, total_loss: 1.490
training 3970 (epoch 9): tem_loss: 1.087, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01945, consistency_loss_ema: 0.02150, total_loss: 1.488
training 3980 (epoch 9): tem_loss: 1.087, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01948, consistency_loss_ema: 0.02161, total_loss: 1.488
training 3990 (epoch 9): tem_loss: 1.087, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01947, consistency_loss_ema: 0.02146, total_loss: 1.487
training 4000 (epoch 9): tem_loss: 1.087, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01947, consistency_loss_ema: 0.02142, total_loss: 1.488
training 4010 (epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01948, consistency_loss_ema: 0.02140, total_loss: 1.492
training 4020 (epoch 9): tem_loss: 1.089, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01947, consistency_loss_ema: 0.02133, total_loss: 1.492
training 4030 (epoch 9): tem_loss: 1.091, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01948, consistency_loss_ema: 0.02134, total_loss: 1.496
training 4040 (epoch 9): tem_loss: 1.089, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01946, consistency_loss_ema: 0.02134, total_loss: 1.497
training 4050 (epoch 9): tem_loss: 1.090, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01947, consistency_loss_ema: 0.02134, total_loss: 1.497
training 4060 (epoch 9): tem_loss: 1.090, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01949, consistency_loss_ema: 0.02134, total_loss: 1.498
training 4070 (epoch 9): tem_loss: 1.089, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01944, consistency_loss_ema: 0.02132, total_loss: 1.496
training 4080 (epoch 9): tem_loss: 1.089, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01943, consistency_loss_ema: 0.02131, total_loss: 1.496
training 4090 (epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01942, consistency_loss_ema: 0.02133, total_loss: 1.493
training 4100 (epoch 9): tem_loss: 1.086, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01946, consistency_loss_ema: 0.02130, total_loss: 1.490
training 4110 (epoch 9): tem_loss: 1.086, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01949, consistency_loss_ema: 0.02132, total_loss: 1.491
training 4120 (epoch 9): tem_loss: 1.087, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01947, consistency_loss_ema: 0.02128, total_loss: 1.491
training 4130 (epoch 9): tem_loss: 1.086, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01963, consistency_loss_ema: 0.02140, total_loss: 1.492
training 4140 (epoch 9): tem_loss: 1.086, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01965, consistency_loss_ema: 0.02142, total_loss: 1.490
training 4150 (epoch 9): tem_loss: 1.086, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01972, consistency_loss_ema: 0.02138, total_loss: 1.490
training 4160 (epoch 9): tem_loss: 1.086, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01975, consistency_loss_ema: 0.02143, total_loss: 1.489
training 4170 (epoch 9): tem_loss: 1.086, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01976, consistency_loss_ema: 0.02148, total_loss: 1.489
training 4180 (epoch 9): tem_loss: 1.085, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01978, consistency_loss_ema: 0.02150, total_loss: 1.488
training 4190 (epoch 9): tem_loss: 1.085, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01973, consistency_loss_ema: 0.02152, total_loss: 1.488
training 4200 (epoch 9): tem_loss: 1.086, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01972, consistency_loss_ema: 0.02165, total_loss: 1.490
training 4210 (epoch 9): tem_loss: 1.086, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01977, consistency_loss_ema: 0.02173, total_loss: 1.490
[94mBMN training loss(epoch 9): tem_loss: 1.086, pem class_loss: 0.272, pem reg_loss: 0.013, total_loss: 1.490[0m
[94mBMN val loss(epoch 9): tem_loss: 1.152, pem class_loss: 0.326, pem reg_loss: 0.015, total_loss: 1.631[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.152, pem class_loss: 0.327, pem reg_loss: 0.015, total_loss: 1.632[0m
unlabel percent:  0.3
eval student model !!
load : ./checkpoint/Semi-base-0.3-2/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472618
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.30403126285479%
AR@1 is 	 0.3320032908268203
AR@5 is 	 0.49184149184149184
AR@10 is 	 0.566447278211984
AR@100 is 	 0.7524338406691348
load : ./checkpoint/Semi-base-0.3-2/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472599
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.20153571918277%
AR@1 is 	 0.3339777869189634
AR@5 is 	 0.4901138077608665
AR@10 is 	 0.5652269299328123
AR@100 is 	 0.7524886877828055
eval teacher model !!
load : ./checkpoint/Semi-base-0.3-2/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472607
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.32847250788426%
AR@1 is 	 0.33463595228301113
AR@5 is 	 0.49260935143288076
AR@10 is 	 0.5674071027012204
AR@100 is 	 0.7548334018922254
load : ./checkpoint/Semi-base-0.3-2/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472618
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 66.47808857808856%
AR@1 is 	 0.33407376936788696
AR@5 is 	 0.4845468257232963
AR@10 is 	 0.5571781160016454
AR@100 is 	 0.745920745920746
#
train subset video numbers: 7724
unlabel unlabeled subset video numbers: 1925
validation subset video numbers: 4728
use 0.8 label for training!!!
training batchsize : 16
unlabel_training batchsize : 4
use Semi !!!
training 1 (epoch 0): tem_loss: 1.416, pem class_loss: 0.693, pem reg_loss: 0.042, consistency_loss: 0.00041, consistency_loss_ema: 0.00000, total_loss: 2.527
training 11 (epoch 0): tem_loss: 1.363, pem class_loss: 0.604, pem reg_loss: 0.040, consistency_loss: 0.00012, consistency_loss_ema: 0.00002, total_loss: 2.370
training 21 (epoch 0): tem_loss: 1.343, pem class_loss: 0.525, pem reg_loss: 0.033, consistency_loss: 0.00013, consistency_loss_ema: 0.00008, total_loss: 2.203
training 31 (epoch 0): tem_loss: 1.327, pem class_loss: 0.490, pem reg_loss: 0.030, consistency_loss: 0.00015, consistency_loss_ema: 0.00010, total_loss: 2.118
training 41 (epoch 0): tem_loss: 1.317, pem class_loss: 0.464, pem reg_loss: 0.028, consistency_loss: 0.00017, consistency_loss_ema: 0.00014, total_loss: 2.061
training 51 (epoch 0): tem_loss: 1.312, pem class_loss: 0.449, pem reg_loss: 0.027, consistency_loss: 0.00018, consistency_loss_ema: 0.00016, total_loss: 2.029
training 61 (epoch 0): tem_loss: 1.305, pem class_loss: 0.436, pem reg_loss: 0.026, consistency_loss: 0.00019, consistency_loss_ema: 0.00017, total_loss: 2.000
training 71 (epoch 0): tem_loss: 1.295, pem class_loss: 0.428, pem reg_loss: 0.025, consistency_loss: 0.00021, consistency_loss_ema: 0.00019, total_loss: 1.976
training 81 (epoch 0): tem_loss: 1.286, pem class_loss: 0.422, pem reg_loss: 0.025, consistency_loss: 0.00022, consistency_loss_ema: 0.00021, total_loss: 1.955
training 91 (epoch 0): tem_loss: 1.283, pem class_loss: 0.421, pem reg_loss: 0.025, consistency_loss: 0.00024, consistency_loss_ema: 0.00023, total_loss: 1.950
training 101 (epoch 0): tem_loss: 1.282, pem class_loss: 0.417, pem reg_loss: 0.024, consistency_loss: 0.00026, consistency_loss_ema: 0.00024, total_loss: 1.942
training 111 (epoch 0): tem_loss: 1.274, pem class_loss: 0.414, pem reg_loss: 0.024, consistency_loss: 0.00027, consistency_loss_ema: 0.00026, total_loss: 1.928
training 121 (epoch 0): tem_loss: 1.266, pem class_loss: 0.412, pem reg_loss: 0.024, consistency_loss: 0.00028, consistency_loss_ema: 0.00027, total_loss: 1.917
training 131 (epoch 0): tem_loss: 1.263, pem class_loss: 0.411, pem reg_loss: 0.024, consistency_loss: 0.00031, consistency_loss_ema: 0.00030, total_loss: 1.912
training 141 (epoch 0): tem_loss: 1.257, pem class_loss: 0.409, pem reg_loss: 0.024, consistency_loss: 0.00032, consistency_loss_ema: 0.00033, total_loss: 1.904
training 151 (epoch 0): tem_loss: 1.252, pem class_loss: 0.405, pem reg_loss: 0.024, consistency_loss: 0.00033, consistency_loss_ema: 0.00033, total_loss: 1.894
training 161 (epoch 0): tem_loss: 1.247, pem class_loss: 0.404, pem reg_loss: 0.023, consistency_loss: 0.00033, consistency_loss_ema: 0.00034, total_loss: 1.886
training 171 (epoch 0): tem_loss: 1.245, pem class_loss: 0.404, pem reg_loss: 0.023, consistency_loss: 0.00034, consistency_loss_ema: 0.00035, total_loss: 1.882
training 181 (epoch 0): tem_loss: 1.243, pem class_loss: 0.401, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00036, total_loss: 1.876
training 191 (epoch 0): tem_loss: 1.240, pem class_loss: 0.399, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00036, total_loss: 1.870
training 201 (epoch 0): tem_loss: 1.238, pem class_loss: 0.397, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00036, total_loss: 1.866
training 211 (epoch 0): tem_loss: 1.234, pem class_loss: 0.394, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00036, total_loss: 1.856
training 221 (epoch 0): tem_loss: 1.233, pem class_loss: 0.394, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00036, total_loss: 1.855
training 231 (epoch 0): tem_loss: 1.230, pem class_loss: 0.392, pem reg_loss: 0.023, consistency_loss: 0.00036, consistency_loss_ema: 0.00037, total_loss: 1.849
training 241 (epoch 0): tem_loss: 1.228, pem class_loss: 0.391, pem reg_loss: 0.023, consistency_loss: 0.00036, consistency_loss_ema: 0.00037, total_loss: 1.845
training 251 (epoch 0): tem_loss: 1.225, pem class_loss: 0.389, pem reg_loss: 0.022, consistency_loss: 0.00036, consistency_loss_ema: 0.00038, total_loss: 1.839
training 261 (epoch 0): tem_loss: 1.223, pem class_loss: 0.390, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00038, total_loss: 1.838
training 271 (epoch 0): tem_loss: 1.222, pem class_loss: 0.389, pem reg_loss: 0.022, consistency_loss: 0.00037, consistency_loss_ema: 0.00039, total_loss: 1.835
training 281 (epoch 0): tem_loss: 1.218, pem class_loss: 0.387, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00039, total_loss: 1.830
training 291 (epoch 0): tem_loss: 1.218, pem class_loss: 0.387, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.829
training 301 (epoch 0): tem_loss: 1.218, pem class_loss: 0.386, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.828
training 311 (epoch 0): tem_loss: 1.216, pem class_loss: 0.386, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.825
training 321 (epoch 0): tem_loss: 1.215, pem class_loss: 0.384, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.821
training 331 (epoch 0): tem_loss: 1.214, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.818
training 341 (epoch 0): tem_loss: 1.211, pem class_loss: 0.381, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.813
training 351 (epoch 0): tem_loss: 1.211, pem class_loss: 0.379, pem reg_loss: 0.022, consistency_loss: 0.00038, consistency_loss_ema: 0.00040, total_loss: 1.809
training 361 (epoch 0): tem_loss: 1.211, pem class_loss: 0.379, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00040, total_loss: 1.808
training 371 (epoch 0): tem_loss: 1.211, pem class_loss: 0.378, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00040, total_loss: 1.806
training 381 (epoch 0): tem_loss: 1.210, pem class_loss: 0.378, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00041, total_loss: 1.806
training 391 (epoch 0): tem_loss: 1.209, pem class_loss: 0.377, pem reg_loss: 0.022, consistency_loss: 0.00040, consistency_loss_ema: 0.00041, total_loss: 1.803
training 401 (epoch 0): tem_loss: 1.208, pem class_loss: 0.377, pem reg_loss: 0.022, consistency_loss: 0.00040, consistency_loss_ema: 0.00041, total_loss: 1.801
training 411 (epoch 0): tem_loss: 1.207, pem class_loss: 0.377, pem reg_loss: 0.022, consistency_loss: 0.00040, consistency_loss_ema: 0.00042, total_loss: 1.801
training 421 (epoch 0): tem_loss: 1.206, pem class_loss: 0.376, pem reg_loss: 0.022, consistency_loss: 0.00040, consistency_loss_ema: 0.00042, total_loss: 1.798
training 431 (epoch 0): tem_loss: 1.205, pem class_loss: 0.375, pem reg_loss: 0.022, consistency_loss: 0.00040, consistency_loss_ema: 0.00042, total_loss: 1.796
training 441 (epoch 0): tem_loss: 1.205, pem class_loss: 0.375, pem reg_loss: 0.022, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.795
training 451 (epoch 0): tem_loss: 1.204, pem class_loss: 0.374, pem reg_loss: 0.022, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.793
training 461 (epoch 0): tem_loss: 1.203, pem class_loss: 0.374, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.792
training 471 (epoch 0): tem_loss: 1.202, pem class_loss: 0.373, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.790
training 481 (epoch 0): tem_loss: 1.201, pem class_loss: 0.373, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00043, total_loss: 1.788
[94mBMN training loss(epoch 0): tem_loss: 1.201, pem class_loss: 0.373, pem reg_loss: 0.021, total_loss: 1.788[0m
[94mBMN val loss(epoch 0): tem_loss: 1.165, pem class_loss: 0.360, pem reg_loss: 0.021, total_loss: 1.734[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.160, pem class_loss: 0.346, pem reg_loss: 0.019, total_loss: 1.697[0m
use Semi !!!
training 483 (epoch 1): tem_loss: 1.150, pem class_loss: 0.371, pem reg_loss: 0.019, consistency_loss: 0.00238, consistency_loss_ema: 0.00283, total_loss: 1.708
training 493 (epoch 1): tem_loss: 1.113, pem class_loss: 0.354, pem reg_loss: 0.019, consistency_loss: 0.00308, consistency_loss_ema: 0.00331, total_loss: 1.660
training 503 (epoch 1): tem_loss: 1.117, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00303, consistency_loss_ema: 0.00339, total_loss: 1.654
training 513 (epoch 1): tem_loss: 1.127, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00298, consistency_loss_ema: 0.00341, total_loss: 1.662
training 523 (epoch 1): tem_loss: 1.140, pem class_loss: 0.353, pem reg_loss: 0.020, consistency_loss: 0.00292, consistency_loss_ema: 0.00323, total_loss: 1.691
training 533 (epoch 1): tem_loss: 1.139, pem class_loss: 0.350, pem reg_loss: 0.019, consistency_loss: 0.00283, consistency_loss_ema: 0.00308, total_loss: 1.682
training 543 (epoch 1): tem_loss: 1.137, pem class_loss: 0.351, pem reg_loss: 0.019, consistency_loss: 0.00278, consistency_loss_ema: 0.00306, total_loss: 1.682
training 553 (epoch 1): tem_loss: 1.134, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00286, consistency_loss_ema: 0.00306, total_loss: 1.671
training 563 (epoch 1): tem_loss: 1.138, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00294, consistency_loss_ema: 0.00300, total_loss: 1.674
training 573 (epoch 1): tem_loss: 1.141, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00291, consistency_loss_ema: 0.00295, total_loss: 1.682
training 583 (epoch 1): tem_loss: 1.143, pem class_loss: 0.351, pem reg_loss: 0.020, consistency_loss: 0.00287, consistency_loss_ema: 0.00292, total_loss: 1.690
training 593 (epoch 1): tem_loss: 1.141, pem class_loss: 0.352, pem reg_loss: 0.020, consistency_loss: 0.00284, consistency_loss_ema: 0.00291, total_loss: 1.691
training 603 (epoch 1): tem_loss: 1.140, pem class_loss: 0.350, pem reg_loss: 0.020, consistency_loss: 0.00283, consistency_loss_ema: 0.00290, total_loss: 1.687
training 613 (epoch 1): tem_loss: 1.138, pem class_loss: 0.349, pem reg_loss: 0.019, consistency_loss: 0.00291, consistency_loss_ema: 0.00295, total_loss: 1.681
training 623 (epoch 1): tem_loss: 1.138, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00296, consistency_loss_ema: 0.00301, total_loss: 1.679
training 633 (epoch 1): tem_loss: 1.139, pem class_loss: 0.349, pem reg_loss: 0.019, consistency_loss: 0.00293, consistency_loss_ema: 0.00299, total_loss: 1.682
training 643 (epoch 1): tem_loss: 1.139, pem class_loss: 0.349, pem reg_loss: 0.019, consistency_loss: 0.00289, consistency_loss_ema: 0.00295, total_loss: 1.683
training 653 (epoch 1): tem_loss: 1.138, pem class_loss: 0.348, pem reg_loss: 0.019, consistency_loss: 0.00286, consistency_loss_ema: 0.00292, total_loss: 1.680
training 663 (epoch 1): tem_loss: 1.138, pem class_loss: 0.348, pem reg_loss: 0.019, consistency_loss: 0.00286, consistency_loss_ema: 0.00290, total_loss: 1.679
training 673 (epoch 1): tem_loss: 1.138, pem class_loss: 0.349, pem reg_loss: 0.019, consistency_loss: 0.00285, consistency_loss_ema: 0.00289, total_loss: 1.681
training 683 (epoch 1): tem_loss: 1.138, pem class_loss: 0.348, pem reg_loss: 0.019, consistency_loss: 0.00284, consistency_loss_ema: 0.00288, total_loss: 1.679
training 693 (epoch 1): tem_loss: 1.140, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00282, consistency_loss_ema: 0.00284, total_loss: 1.680
training 703 (epoch 1): tem_loss: 1.139, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00283, consistency_loss_ema: 0.00287, total_loss: 1.679
training 713 (epoch 1): tem_loss: 1.140, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00283, consistency_loss_ema: 0.00287, total_loss: 1.679
training 723 (epoch 1): tem_loss: 1.139, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00281, consistency_loss_ema: 0.00285, total_loss: 1.677
training 733 (epoch 1): tem_loss: 1.138, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00279, consistency_loss_ema: 0.00282, total_loss: 1.676
training 743 (epoch 1): tem_loss: 1.137, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00282, consistency_loss_ema: 0.00284, total_loss: 1.673
training 753 (epoch 1): tem_loss: 1.137, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00284, consistency_loss_ema: 0.00285, total_loss: 1.673
training 763 (epoch 1): tem_loss: 1.138, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00285, consistency_loss_ema: 0.00288, total_loss: 1.675
training 773 (epoch 1): tem_loss: 1.138, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00284, consistency_loss_ema: 0.00287, total_loss: 1.674
training 783 (epoch 1): tem_loss: 1.139, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00284, consistency_loss_ema: 0.00285, total_loss: 1.677
training 793 (epoch 1): tem_loss: 1.140, pem class_loss: 0.347, pem reg_loss: 0.019, consistency_loss: 0.00283, consistency_loss_ema: 0.00287, total_loss: 1.679
training 803 (epoch 1): tem_loss: 1.140, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00283, consistency_loss_ema: 0.00288, total_loss: 1.678
training 813 (epoch 1): tem_loss: 1.139, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00282, consistency_loss_ema: 0.00287, total_loss: 1.676
training 823 (epoch 1): tem_loss: 1.138, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00282, consistency_loss_ema: 0.00287, total_loss: 1.675
training 833 (epoch 1): tem_loss: 1.139, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00281, consistency_loss_ema: 0.00285, total_loss: 1.674
training 843 (epoch 1): tem_loss: 1.139, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00280, consistency_loss_ema: 0.00284, total_loss: 1.674
training 853 (epoch 1): tem_loss: 1.140, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00280, consistency_loss_ema: 0.00284, total_loss: 1.675
training 863 (epoch 1): tem_loss: 1.138, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00279, consistency_loss_ema: 0.00283, total_loss: 1.671
training 873 (epoch 1): tem_loss: 1.139, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00279, consistency_loss_ema: 0.00283, total_loss: 1.673
training 883 (epoch 1): tem_loss: 1.139, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00278, consistency_loss_ema: 0.00283, total_loss: 1.674
training 893 (epoch 1): tem_loss: 1.138, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00277, consistency_loss_ema: 0.00282, total_loss: 1.673
training 903 (epoch 1): tem_loss: 1.137, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00278, consistency_loss_ema: 0.00282, total_loss: 1.672
training 913 (epoch 1): tem_loss: 1.138, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00278, consistency_loss_ema: 0.00282, total_loss: 1.674
training 923 (epoch 1): tem_loss: 1.137, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00277, consistency_loss_ema: 0.00281, total_loss: 1.673
training 933 (epoch 1): tem_loss: 1.137, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00276, consistency_loss_ema: 0.00280, total_loss: 1.670
training 943 (epoch 1): tem_loss: 1.137, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00275, consistency_loss_ema: 0.00279, total_loss: 1.671
training 953 (epoch 1): tem_loss: 1.137, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00274, consistency_loss_ema: 0.00278, total_loss: 1.670
training 963 (epoch 1): tem_loss: 1.138, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00273, consistency_loss_ema: 0.00278, total_loss: 1.670
[94mBMN training loss(epoch 1): tem_loss: 1.138, pem class_loss: 0.343, pem reg_loss: 0.019, total_loss: 1.669[0m
[94mBMN val loss(epoch 1): tem_loss: 1.153, pem class_loss: 0.340, pem reg_loss: 0.018, total_loss: 1.678[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.143, pem class_loss: 0.333, pem reg_loss: 0.018, total_loss: 1.653[0m
use Semi !!!
training 965 (epoch 2): tem_loss: 1.175, pem class_loss: 0.253, pem reg_loss: 0.013, consistency_loss: 0.01027, consistency_loss_ema: 0.00898, total_loss: 1.560
training 975 (epoch 2): tem_loss: 1.073, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.01016, consistency_loss_ema: 0.00976, total_loss: 1.559
training 985 (epoch 2): tem_loss: 1.094, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.00935, consistency_loss_ema: 0.00892, total_loss: 1.582
training 995 (epoch 2): tem_loss: 1.105, pem class_loss: 0.333, pem reg_loss: 0.017, consistency_loss: 0.00913, consistency_loss_ema: 0.00899, total_loss: 1.611
training 1005 (epoch 2): tem_loss: 1.111, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00900, consistency_loss_ema: 0.00937, total_loss: 1.625
training 1015 (epoch 2): tem_loss: 1.116, pem class_loss: 0.343, pem reg_loss: 0.018, consistency_loss: 0.00871, consistency_loss_ema: 0.00918, total_loss: 1.636
training 1025 (epoch 2): tem_loss: 1.124, pem class_loss: 0.345, pem reg_loss: 0.018, consistency_loss: 0.00854, consistency_loss_ema: 0.00902, total_loss: 1.647
training 1035 (epoch 2): tem_loss: 1.118, pem class_loss: 0.344, pem reg_loss: 0.018, consistency_loss: 0.00860, consistency_loss_ema: 0.00922, total_loss: 1.639
training 1045 (epoch 2): tem_loss: 1.110, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00876, consistency_loss_ema: 0.00949, total_loss: 1.625
training 1055 (epoch 2): tem_loss: 1.109, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00882, consistency_loss_ema: 0.00935, total_loss: 1.622
training 1065 (epoch 2): tem_loss: 1.111, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00884, consistency_loss_ema: 0.00929, total_loss: 1.623
training 1075 (epoch 2): tem_loss: 1.108, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00880, consistency_loss_ema: 0.00924, total_loss: 1.623
training 1085 (epoch 2): tem_loss: 1.106, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00878, consistency_loss_ema: 0.00920, total_loss: 1.622
training 1095 (epoch 2): tem_loss: 1.102, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.00886, consistency_loss_ema: 0.00929, total_loss: 1.615
training 1105 (epoch 2): tem_loss: 1.105, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00881, consistency_loss_ema: 0.00920, total_loss: 1.620
training 1115 (epoch 2): tem_loss: 1.105, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.00875, consistency_loss_ema: 0.00913, total_loss: 1.619
training 1125 (epoch 2): tem_loss: 1.110, pem class_loss: 0.335, pem reg_loss: 0.018, consistency_loss: 0.00881, consistency_loss_ema: 0.00919, total_loss: 1.622
training 1135 (epoch 2): tem_loss: 1.108, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00898, consistency_loss_ema: 0.00933, total_loss: 1.617
training 1145 (epoch 2): tem_loss: 1.109, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00918, consistency_loss_ema: 0.00943, total_loss: 1.620
training 1155 (epoch 2): tem_loss: 1.109, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00913, consistency_loss_ema: 0.00947, total_loss: 1.620
training 1165 (epoch 2): tem_loss: 1.109, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00912, consistency_loss_ema: 0.00949, total_loss: 1.622
training 1175 (epoch 2): tem_loss: 1.109, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00905, consistency_loss_ema: 0.00944, total_loss: 1.622
training 1185 (epoch 2): tem_loss: 1.110, pem class_loss: 0.334, pem reg_loss: 0.018, consistency_loss: 0.00907, consistency_loss_ema: 0.00940, total_loss: 1.624
training 1195 (epoch 2): tem_loss: 1.109, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00905, consistency_loss_ema: 0.00940, total_loss: 1.620
training 1205 (epoch 2): tem_loss: 1.107, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00904, consistency_loss_ema: 0.00937, total_loss: 1.618
training 1215 (epoch 2): tem_loss: 1.106, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00903, consistency_loss_ema: 0.00934, total_loss: 1.615
training 1225 (epoch 2): tem_loss: 1.106, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00901, consistency_loss_ema: 0.00930, total_loss: 1.614
training 1235 (epoch 2): tem_loss: 1.106, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00898, consistency_loss_ema: 0.00926, total_loss: 1.615
training 1245 (epoch 2): tem_loss: 1.108, pem class_loss: 0.333, pem reg_loss: 0.018, consistency_loss: 0.00898, consistency_loss_ema: 0.00928, total_loss: 1.618
training 1255 (epoch 2): tem_loss: 1.107, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00897, consistency_loss_ema: 0.00929, total_loss: 1.616
training 1265 (epoch 2): tem_loss: 1.109, pem class_loss: 0.332, pem reg_loss: 0.018, consistency_loss: 0.00894, consistency_loss_ema: 0.00926, total_loss: 1.618
training 1275 (epoch 2): tem_loss: 1.108, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00891, consistency_loss_ema: 0.00923, total_loss: 1.615
training 1285 (epoch 2): tem_loss: 1.109, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00889, consistency_loss_ema: 0.00919, total_loss: 1.616
training 1295 (epoch 2): tem_loss: 1.109, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00886, consistency_loss_ema: 0.00913, total_loss: 1.616
training 1305 (epoch 2): tem_loss: 1.110, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00880, consistency_loss_ema: 0.00908, total_loss: 1.616
training 1315 (epoch 2): tem_loss: 1.109, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00880, consistency_loss_ema: 0.00906, total_loss: 1.615
training 1325 (epoch 2): tem_loss: 1.111, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00876, consistency_loss_ema: 0.00904, total_loss: 1.618
training 1335 (epoch 2): tem_loss: 1.112, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00872, consistency_loss_ema: 0.00900, total_loss: 1.619
training 1345 (epoch 2): tem_loss: 1.113, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00872, consistency_loss_ema: 0.00901, total_loss: 1.621
training 1355 (epoch 2): tem_loss: 1.113, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00870, consistency_loss_ema: 0.00897, total_loss: 1.621
training 1365 (epoch 2): tem_loss: 1.113, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00871, consistency_loss_ema: 0.00896, total_loss: 1.620
training 1375 (epoch 2): tem_loss: 1.113, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00872, consistency_loss_ema: 0.00895, total_loss: 1.619
training 1385 (epoch 2): tem_loss: 1.113, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00871, consistency_loss_ema: 0.00891, total_loss: 1.620
training 1395 (epoch 2): tem_loss: 1.113, pem class_loss: 0.331, pem reg_loss: 0.018, consistency_loss: 0.00870, consistency_loss_ema: 0.00891, total_loss: 1.620
training 1405 (epoch 2): tem_loss: 1.112, pem class_loss: 0.330, pem reg_loss: 0.018, consistency_loss: 0.00868, consistency_loss_ema: 0.00888, total_loss: 1.618
training 1415 (epoch 2): tem_loss: 1.112, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00866, consistency_loss_ema: 0.00885, total_loss: 1.617
training 1425 (epoch 2): tem_loss: 1.114, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00864, consistency_loss_ema: 0.00883, total_loss: 1.618
training 1435 (epoch 2): tem_loss: 1.114, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00863, consistency_loss_ema: 0.00887, total_loss: 1.618
training 1445 (epoch 2): tem_loss: 1.114, pem class_loss: 0.329, pem reg_loss: 0.018, consistency_loss: 0.00863, consistency_loss_ema: 0.00887, total_loss: 1.618
[94mBMN training loss(epoch 2): tem_loss: 1.114, pem class_loss: 0.329, pem reg_loss: 0.018, total_loss: 1.618[0m
[94mBMN val loss(epoch 2): tem_loss: 1.141, pem class_loss: 0.332, pem reg_loss: 0.018, total_loss: 1.649[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.135, pem class_loss: 0.327, pem reg_loss: 0.017, total_loss: 1.630[0m
use Semi !!!
training 1447 (epoch 3): tem_loss: 1.111, pem class_loss: 0.244, pem reg_loss: 0.012, consistency_loss: 0.02412, consistency_loss_ema: 0.02678, total_loss: 1.478
training 1457 (epoch 3): tem_loss: 1.094, pem class_loss: 0.305, pem reg_loss: 0.017, consistency_loss: 0.02004, consistency_loss_ema: 0.02089, total_loss: 1.567
training 1467 (epoch 3): tem_loss: 1.107, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.01820, consistency_loss_ema: 0.01981, total_loss: 1.598
training 1477 (epoch 3): tem_loss: 1.081, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.01874, consistency_loss_ema: 0.02009, total_loss: 1.549
training 1487 (epoch 3): tem_loss: 1.077, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.01862, consistency_loss_ema: 0.01963, total_loss: 1.554
training 1497 (epoch 3): tem_loss: 1.076, pem class_loss: 0.313, pem reg_loss: 0.017, consistency_loss: 0.01896, consistency_loss_ema: 0.01926, total_loss: 1.557
training 1507 (epoch 3): tem_loss: 1.078, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.01899, consistency_loss_ema: 0.01895, total_loss: 1.552
training 1517 (epoch 3): tem_loss: 1.079, pem class_loss: 0.312, pem reg_loss: 0.017, consistency_loss: 0.01864, consistency_loss_ema: 0.01891, total_loss: 1.557
training 1527 (epoch 3): tem_loss: 1.091, pem class_loss: 0.313, pem reg_loss: 0.017, consistency_loss: 0.01859, consistency_loss_ema: 0.01866, total_loss: 1.571
training 1537 (epoch 3): tem_loss: 1.095, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01833, consistency_loss_ema: 0.01882, total_loss: 1.575
training 1547 (epoch 3): tem_loss: 1.097, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.01814, consistency_loss_ema: 0.01872, total_loss: 1.577
training 1557 (epoch 3): tem_loss: 1.097, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01811, consistency_loss_ema: 0.01858, total_loss: 1.577
training 1567 (epoch 3): tem_loss: 1.099, pem class_loss: 0.316, pem reg_loss: 0.017, consistency_loss: 0.01813, consistency_loss_ema: 0.01861, total_loss: 1.581
training 1577 (epoch 3): tem_loss: 1.101, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01799, consistency_loss_ema: 0.01849, total_loss: 1.586
training 1587 (epoch 3): tem_loss: 1.106, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01786, consistency_loss_ema: 0.01828, total_loss: 1.590
training 1597 (epoch 3): tem_loss: 1.104, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.01784, consistency_loss_ema: 0.01823, total_loss: 1.586
training 1607 (epoch 3): tem_loss: 1.103, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01791, consistency_loss_ema: 0.01809, total_loss: 1.588
training 1617 (epoch 3): tem_loss: 1.105, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01773, consistency_loss_ema: 0.01792, total_loss: 1.591
training 1627 (epoch 3): tem_loss: 1.105, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01769, consistency_loss_ema: 0.01797, total_loss: 1.594
training 1637 (epoch 3): tem_loss: 1.107, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01761, consistency_loss_ema: 0.01790, total_loss: 1.595
training 1647 (epoch 3): tem_loss: 1.107, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01745, consistency_loss_ema: 0.01772, total_loss: 1.595
training 1657 (epoch 3): tem_loss: 1.107, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01741, consistency_loss_ema: 0.01769, total_loss: 1.593
training 1667 (epoch 3): tem_loss: 1.108, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01739, consistency_loss_ema: 0.01761, total_loss: 1.594
training 1677 (epoch 3): tem_loss: 1.109, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01730, consistency_loss_ema: 0.01755, total_loss: 1.595
training 1687 (epoch 3): tem_loss: 1.111, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01728, consistency_loss_ema: 0.01759, total_loss: 1.598
training 1697 (epoch 3): tem_loss: 1.112, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01727, consistency_loss_ema: 0.01756, total_loss: 1.598
training 1707 (epoch 3): tem_loss: 1.111, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01727, consistency_loss_ema: 0.01763, total_loss: 1.596
training 1717 (epoch 3): tem_loss: 1.110, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01722, consistency_loss_ema: 0.01754, total_loss: 1.595
training 1727 (epoch 3): tem_loss: 1.110, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01715, consistency_loss_ema: 0.01751, total_loss: 1.593
training 1737 (epoch 3): tem_loss: 1.109, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.01718, consistency_loss_ema: 0.01751, total_loss: 1.591
training 1747 (epoch 3): tem_loss: 1.110, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.01716, consistency_loss_ema: 0.01746, total_loss: 1.593
training 1757 (epoch 3): tem_loss: 1.110, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.01710, consistency_loss_ema: 0.01746, total_loss: 1.592
training 1767 (epoch 3): tem_loss: 1.110, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01703, consistency_loss_ema: 0.01737, total_loss: 1.594
training 1777 (epoch 3): tem_loss: 1.112, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01694, consistency_loss_ema: 0.01730, total_loss: 1.596
training 1787 (epoch 3): tem_loss: 1.112, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01687, consistency_loss_ema: 0.01719, total_loss: 1.596
training 1797 (epoch 3): tem_loss: 1.111, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01680, consistency_loss_ema: 0.01715, total_loss: 1.595
training 1807 (epoch 3): tem_loss: 1.111, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01680, consistency_loss_ema: 0.01712, total_loss: 1.594
training 1817 (epoch 3): tem_loss: 1.112, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.01678, consistency_loss_ema: 0.01718, total_loss: 1.596
training 1827 (epoch 3): tem_loss: 1.112, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01680, consistency_loss_ema: 0.01721, total_loss: 1.597
training 1837 (epoch 3): tem_loss: 1.112, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01680, consistency_loss_ema: 0.01721, total_loss: 1.597
training 1847 (epoch 3): tem_loss: 1.112, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01674, consistency_loss_ema: 0.01718, total_loss: 1.598
training 1857 (epoch 3): tem_loss: 1.112, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.01678, consistency_loss_ema: 0.01723, total_loss: 1.598
training 1867 (epoch 3): tem_loss: 1.112, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01674, consistency_loss_ema: 0.01719, total_loss: 1.598
training 1877 (epoch 3): tem_loss: 1.112, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01669, consistency_loss_ema: 0.01715, total_loss: 1.597
training 1887 (epoch 3): tem_loss: 1.111, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01668, consistency_loss_ema: 0.01719, total_loss: 1.595
training 1897 (epoch 3): tem_loss: 1.111, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01663, consistency_loss_ema: 0.01711, total_loss: 1.595
training 1907 (epoch 3): tem_loss: 1.110, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01667, consistency_loss_ema: 0.01715, total_loss: 1.595
training 1917 (epoch 3): tem_loss: 1.110, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01664, consistency_loss_ema: 0.01715, total_loss: 1.595
training 1927 (epoch 3): tem_loss: 1.110, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.01660, consistency_loss_ema: 0.01710, total_loss: 1.595
[94mBMN training loss(epoch 3): tem_loss: 1.110, pem class_loss: 0.319, pem reg_loss: 0.017, total_loss: 1.595[0m
[94mBMN val loss(epoch 3): tem_loss: 1.144, pem class_loss: 0.325, pem reg_loss: 0.017, total_loss: 1.638[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.141, pem class_loss: 0.323, pem reg_loss: 0.016, total_loss: 1.626[0m
use Semi !!!
training 1929 (epoch 4): tem_loss: 1.032, pem class_loss: 0.259, pem reg_loss: 0.012, consistency_loss: 0.02680, consistency_loss_ema: 0.05443, total_loss: 1.413
training 1939 (epoch 4): tem_loss: 1.093, pem class_loss: 0.308, pem reg_loss: 0.017, consistency_loss: 0.02592, consistency_loss_ema: 0.03163, total_loss: 1.567
training 1949 (epoch 4): tem_loss: 1.096, pem class_loss: 0.287, pem reg_loss: 0.016, consistency_loss: 0.02652, consistency_loss_ema: 0.03138, total_loss: 1.539
training 1959 (epoch 4): tem_loss: 1.086, pem class_loss: 0.282, pem reg_loss: 0.015, consistency_loss: 0.02630, consistency_loss_ema: 0.03057, total_loss: 1.520
training 1969 (epoch 4): tem_loss: 1.087, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02619, consistency_loss_ema: 0.02955, total_loss: 1.534
training 1979 (epoch 4): tem_loss: 1.087, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02562, consistency_loss_ema: 0.02870, total_loss: 1.531
training 1989 (epoch 4): tem_loss: 1.101, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02571, consistency_loss_ema: 0.02890, total_loss: 1.547
training 1999 (epoch 4): tem_loss: 1.102, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02555, consistency_loss_ema: 0.02858, total_loss: 1.547
training 2009 (epoch 4): tem_loss: 1.100, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02521, consistency_loss_ema: 0.02771, total_loss: 1.542
training 2019 (epoch 4): tem_loss: 1.099, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02493, consistency_loss_ema: 0.02742, total_loss: 1.542
training 2029 (epoch 4): tem_loss: 1.098, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02466, consistency_loss_ema: 0.02737, total_loss: 1.542
training 2039 (epoch 4): tem_loss: 1.100, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02458, consistency_loss_ema: 0.02710, total_loss: 1.543
training 2049 (epoch 4): tem_loss: 1.101, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02469, consistency_loss_ema: 0.02708, total_loss: 1.550
training 2059 (epoch 4): tem_loss: 1.103, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02475, consistency_loss_ema: 0.02698, total_loss: 1.556
training 2069 (epoch 4): tem_loss: 1.105, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02443, consistency_loss_ema: 0.02657, total_loss: 1.560
training 2079 (epoch 4): tem_loss: 1.106, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02427, consistency_loss_ema: 0.02632, total_loss: 1.560
training 2089 (epoch 4): tem_loss: 1.106, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02410, consistency_loss_ema: 0.02626, total_loss: 1.559
training 2099 (epoch 4): tem_loss: 1.105, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02402, consistency_loss_ema: 0.02622, total_loss: 1.560
training 2109 (epoch 4): tem_loss: 1.104, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02402, consistency_loss_ema: 0.02613, total_loss: 1.561
training 2119 (epoch 4): tem_loss: 1.108, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02400, consistency_loss_ema: 0.02607, total_loss: 1.565
training 2129 (epoch 4): tem_loss: 1.107, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02389, consistency_loss_ema: 0.02607, total_loss: 1.566
training 2139 (epoch 4): tem_loss: 1.107, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02395, consistency_loss_ema: 0.02603, total_loss: 1.567
training 2149 (epoch 4): tem_loss: 1.108, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02383, consistency_loss_ema: 0.02584, total_loss: 1.569
training 2159 (epoch 4): tem_loss: 1.108, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02376, consistency_loss_ema: 0.02575, total_loss: 1.570
training 2169 (epoch 4): tem_loss: 1.110, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02368, consistency_loss_ema: 0.02573, total_loss: 1.571
training 2179 (epoch 4): tem_loss: 1.112, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02355, consistency_loss_ema: 0.02555, total_loss: 1.575
training 2189 (epoch 4): tem_loss: 1.113, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02358, consistency_loss_ema: 0.02548, total_loss: 1.576
training 2199 (epoch 4): tem_loss: 1.114, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02357, consistency_loss_ema: 0.02549, total_loss: 1.578
training 2209 (epoch 4): tem_loss: 1.114, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02360, consistency_loss_ema: 0.02548, total_loss: 1.577
training 2219 (epoch 4): tem_loss: 1.113, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02350, consistency_loss_ema: 0.02539, total_loss: 1.578
training 2229 (epoch 4): tem_loss: 1.114, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02348, consistency_loss_ema: 0.02534, total_loss: 1.582
training 2239 (epoch 4): tem_loss: 1.113, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02347, consistency_loss_ema: 0.02534, total_loss: 1.581
training 2249 (epoch 4): tem_loss: 1.113, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02343, consistency_loss_ema: 0.02524, total_loss: 1.582
training 2259 (epoch 4): tem_loss: 1.113, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02340, consistency_loss_ema: 0.02522, total_loss: 1.582
training 2269 (epoch 4): tem_loss: 1.113, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02332, consistency_loss_ema: 0.02509, total_loss: 1.582
training 2279 (epoch 4): tem_loss: 1.113, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02333, consistency_loss_ema: 0.02507, total_loss: 1.584
training 2289 (epoch 4): tem_loss: 1.113, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02333, consistency_loss_ema: 0.02513, total_loss: 1.582
training 2299 (epoch 4): tem_loss: 1.112, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02331, consistency_loss_ema: 0.02502, total_loss: 1.583
training 2309 (epoch 4): tem_loss: 1.113, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02326, consistency_loss_ema: 0.02494, total_loss: 1.583
training 2319 (epoch 4): tem_loss: 1.114, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02317, consistency_loss_ema: 0.02494, total_loss: 1.584
training 2329 (epoch 4): tem_loss: 1.114, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02309, consistency_loss_ema: 0.02487, total_loss: 1.586
training 2339 (epoch 4): tem_loss: 1.114, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02309, consistency_loss_ema: 0.02480, total_loss: 1.585
training 2349 (epoch 4): tem_loss: 1.113, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02304, consistency_loss_ema: 0.02467, total_loss: 1.584
training 2359 (epoch 4): tem_loss: 1.114, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.02299, consistency_loss_ema: 0.02462, total_loss: 1.584
training 2369 (epoch 4): tem_loss: 1.114, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02297, consistency_loss_ema: 0.02459, total_loss: 1.583
training 2379 (epoch 4): tem_loss: 1.114, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02302, consistency_loss_ema: 0.02459, total_loss: 1.583
training 2389 (epoch 4): tem_loss: 1.115, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02297, consistency_loss_ema: 0.02456, total_loss: 1.585
training 2399 (epoch 4): tem_loss: 1.115, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02294, consistency_loss_ema: 0.02451, total_loss: 1.583
training 2409 (epoch 4): tem_loss: 1.113, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.02286, consistency_loss_ema: 0.02451, total_loss: 1.582
[94mBMN training loss(epoch 4): tem_loss: 1.114, pem class_loss: 0.311, pem reg_loss: 0.016, total_loss: 1.581[0m
[94mBMN val loss(epoch 4): tem_loss: 1.150, pem class_loss: 0.329, pem reg_loss: 0.017, total_loss: 1.646[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.150, pem class_loss: 0.321, pem reg_loss: 0.016, total_loss: 1.628[0m
use Semi !!!
training 2411 (epoch 5): tem_loss: 1.159, pem class_loss: 0.327, pem reg_loss: 0.017, consistency_loss: 0.03165, consistency_loss_ema: 0.01951, total_loss: 1.652
training 2421 (epoch 5): tem_loss: 1.104, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02687, consistency_loss_ema: 0.02431, total_loss: 1.551
training 2431 (epoch 5): tem_loss: 1.093, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.02603, consistency_loss_ema: 0.02504, total_loss: 1.519
training 2441 (epoch 5): tem_loss: 1.091, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02559, consistency_loss_ema: 0.02641, total_loss: 1.523
training 2451 (epoch 5): tem_loss: 1.090, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02508, consistency_loss_ema: 0.02609, total_loss: 1.524
training 2461 (epoch 5): tem_loss: 1.090, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02501, consistency_loss_ema: 0.02584, total_loss: 1.527
training 2471 (epoch 5): tem_loss: 1.092, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02470, consistency_loss_ema: 0.02616, total_loss: 1.542
training 2481 (epoch 5): tem_loss: 1.095, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02546, consistency_loss_ema: 0.02632, total_loss: 1.548
training 2491 (epoch 5): tem_loss: 1.094, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02556, consistency_loss_ema: 0.02657, total_loss: 1.549
training 2501 (epoch 5): tem_loss: 1.098, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02547, consistency_loss_ema: 0.02629, total_loss: 1.551
training 2511 (epoch 5): tem_loss: 1.102, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02535, consistency_loss_ema: 0.02601, total_loss: 1.554
training 2521 (epoch 5): tem_loss: 1.104, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02519, consistency_loss_ema: 0.02599, total_loss: 1.556
training 2531 (epoch 5): tem_loss: 1.106, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02508, consistency_loss_ema: 0.02569, total_loss: 1.559
training 2541 (epoch 5): tem_loss: 1.105, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02510, consistency_loss_ema: 0.02593, total_loss: 1.558
training 2551 (epoch 5): tem_loss: 1.103, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02521, consistency_loss_ema: 0.02601, total_loss: 1.557
training 2561 (epoch 5): tem_loss: 1.105, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02518, consistency_loss_ema: 0.02603, total_loss: 1.559
training 2571 (epoch 5): tem_loss: 1.104, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02515, consistency_loss_ema: 0.02617, total_loss: 1.562
training 2581 (epoch 5): tem_loss: 1.105, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02511, consistency_loss_ema: 0.02626, total_loss: 1.562
training 2591 (epoch 5): tem_loss: 1.107, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02508, consistency_loss_ema: 0.02626, total_loss: 1.566
training 2601 (epoch 5): tem_loss: 1.109, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02618, total_loss: 1.569
training 2611 (epoch 5): tem_loss: 1.110, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02499, consistency_loss_ema: 0.02629, total_loss: 1.570
training 2621 (epoch 5): tem_loss: 1.110, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02654, total_loss: 1.570
training 2631 (epoch 5): tem_loss: 1.112, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02655, total_loss: 1.572
training 2641 (epoch 5): tem_loss: 1.110, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02646, total_loss: 1.569
training 2651 (epoch 5): tem_loss: 1.110, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02656, total_loss: 1.571
training 2661 (epoch 5): tem_loss: 1.112, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02494, consistency_loss_ema: 0.02642, total_loss: 1.573
training 2671 (epoch 5): tem_loss: 1.112, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02494, consistency_loss_ema: 0.02639, total_loss: 1.572
training 2681 (epoch 5): tem_loss: 1.112, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02497, consistency_loss_ema: 0.02660, total_loss: 1.570
training 2691 (epoch 5): tem_loss: 1.112, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02499, consistency_loss_ema: 0.02667, total_loss: 1.571
training 2701 (epoch 5): tem_loss: 1.111, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02509, consistency_loss_ema: 0.02672, total_loss: 1.571
training 2711 (epoch 5): tem_loss: 1.112, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02515, consistency_loss_ema: 0.02718, total_loss: 1.572
training 2721 (epoch 5): tem_loss: 1.113, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02518, consistency_loss_ema: 0.02723, total_loss: 1.574
training 2731 (epoch 5): tem_loss: 1.114, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02514, consistency_loss_ema: 0.02722, total_loss: 1.575
training 2741 (epoch 5): tem_loss: 1.114, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02508, consistency_loss_ema: 0.02715, total_loss: 1.575
training 2751 (epoch 5): tem_loss: 1.115, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02505, consistency_loss_ema: 0.02715, total_loss: 1.575
training 2761 (epoch 5): tem_loss: 1.114, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.02507, consistency_loss_ema: 0.02710, total_loss: 1.574
training 2771 (epoch 5): tem_loss: 1.114, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02704, total_loss: 1.573
training 2781 (epoch 5): tem_loss: 1.115, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02504, consistency_loss_ema: 0.02700, total_loss: 1.574
training 2791 (epoch 5): tem_loss: 1.114, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02503, consistency_loss_ema: 0.02699, total_loss: 1.572
training 2801 (epoch 5): tem_loss: 1.113, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02701, total_loss: 1.572
training 2811 (epoch 5): tem_loss: 1.114, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02694, total_loss: 1.572
training 2821 (epoch 5): tem_loss: 1.113, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02696, total_loss: 1.572
training 2831 (epoch 5): tem_loss: 1.112, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02690, total_loss: 1.570
training 2841 (epoch 5): tem_loss: 1.112, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02504, consistency_loss_ema: 0.02694, total_loss: 1.570
training 2851 (epoch 5): tem_loss: 1.113, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02683, total_loss: 1.571
training 2861 (epoch 5): tem_loss: 1.113, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02679, total_loss: 1.569
training 2871 (epoch 5): tem_loss: 1.114, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02496, consistency_loss_ema: 0.02678, total_loss: 1.571
training 2881 (epoch 5): tem_loss: 1.114, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02497, consistency_loss_ema: 0.02665, total_loss: 1.572
training 2891 (epoch 5): tem_loss: 1.115, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02498, consistency_loss_ema: 0.02669, total_loss: 1.573
[94mBMN training loss(epoch 5): tem_loss: 1.115, pem class_loss: 0.306, pem reg_loss: 0.015, total_loss: 1.574[0m
[94mBMN val loss(epoch 5): tem_loss: 1.156, pem class_loss: 0.322, pem reg_loss: 0.016, total_loss: 1.634[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.154, pem class_loss: 0.320, pem reg_loss: 0.015, total_loss: 1.628[0m
use Semi !!!
training 2893 (epoch 6): tem_loss: 0.942, pem class_loss: 0.282, pem reg_loss: 0.016, consistency_loss: 0.02269, consistency_loss_ema: 0.02148, total_loss: 1.384
training 2903 (epoch 6): tem_loss: 1.105, pem class_loss: 0.287, pem reg_loss: 0.013, consistency_loss: 0.02470, consistency_loss_ema: 0.02543, total_loss: 1.522
training 2913 (epoch 6): tem_loss: 1.098, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02465, consistency_loss_ema: 0.02486, total_loss: 1.524
training 2923 (epoch 6): tem_loss: 1.090, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.02474, consistency_loss_ema: 0.02519, total_loss: 1.512
training 2933 (epoch 6): tem_loss: 1.096, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.02476, consistency_loss_ema: 0.02567, total_loss: 1.529
training 2943 (epoch 6): tem_loss: 1.108, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02600, consistency_loss_ema: 0.02802, total_loss: 1.537
training 2953 (epoch 6): tem_loss: 1.105, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.02611, consistency_loss_ema: 0.02765, total_loss: 1.532
training 2963 (epoch 6): tem_loss: 1.104, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02588, consistency_loss_ema: 0.02733, total_loss: 1.533
training 2973 (epoch 6): tem_loss: 1.106, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02574, consistency_loss_ema: 0.02719, total_loss: 1.535
training 2983 (epoch 6): tem_loss: 1.106, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02557, consistency_loss_ema: 0.02723, total_loss: 1.535
training 2993 (epoch 6): tem_loss: 1.108, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02538, consistency_loss_ema: 0.02735, total_loss: 1.538
training 3003 (epoch 6): tem_loss: 1.107, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02521, consistency_loss_ema: 0.02688, total_loss: 1.537
training 3013 (epoch 6): tem_loss: 1.108, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02535, consistency_loss_ema: 0.02737, total_loss: 1.543
training 3023 (epoch 6): tem_loss: 1.107, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02507, consistency_loss_ema: 0.02737, total_loss: 1.544
training 3033 (epoch 6): tem_loss: 1.107, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02505, consistency_loss_ema: 0.02704, total_loss: 1.542
training 3043 (epoch 6): tem_loss: 1.108, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02497, consistency_loss_ema: 0.02660, total_loss: 1.546
training 3053 (epoch 6): tem_loss: 1.108, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02487, consistency_loss_ema: 0.02693, total_loss: 1.544
training 3063 (epoch 6): tem_loss: 1.111, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02493, consistency_loss_ema: 0.02676, total_loss: 1.549
training 3073 (epoch 6): tem_loss: 1.111, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02504, consistency_loss_ema: 0.02692, total_loss: 1.550
training 3083 (epoch 6): tem_loss: 1.113, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02502, consistency_loss_ema: 0.02691, total_loss: 1.553
training 3093 (epoch 6): tem_loss: 1.112, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02498, consistency_loss_ema: 0.02681, total_loss: 1.551
training 3103 (epoch 6): tem_loss: 1.112, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02512, consistency_loss_ema: 0.02683, total_loss: 1.555
training 3113 (epoch 6): tem_loss: 1.110, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02523, consistency_loss_ema: 0.02678, total_loss: 1.551
training 3123 (epoch 6): tem_loss: 1.110, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02532, consistency_loss_ema: 0.02691, total_loss: 1.550
training 3133 (epoch 6): tem_loss: 1.110, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02520, consistency_loss_ema: 0.02684, total_loss: 1.552
training 3143 (epoch 6): tem_loss: 1.109, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02522, consistency_loss_ema: 0.02682, total_loss: 1.551
training 3153 (epoch 6): tem_loss: 1.109, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02534, consistency_loss_ema: 0.02686, total_loss: 1.551
training 3163 (epoch 6): tem_loss: 1.109, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02533, consistency_loss_ema: 0.02685, total_loss: 1.551
training 3173 (epoch 6): tem_loss: 1.109, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02526, consistency_loss_ema: 0.02683, total_loss: 1.553
training 3183 (epoch 6): tem_loss: 1.109, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02515, consistency_loss_ema: 0.02684, total_loss: 1.553
training 3193 (epoch 6): tem_loss: 1.109, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02514, consistency_loss_ema: 0.02679, total_loss: 1.553
training 3203 (epoch 6): tem_loss: 1.110, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02512, consistency_loss_ema: 0.02660, total_loss: 1.554
training 3213 (epoch 6): tem_loss: 1.109, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02511, consistency_loss_ema: 0.02656, total_loss: 1.553
training 3223 (epoch 6): tem_loss: 1.110, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02507, consistency_loss_ema: 0.02647, total_loss: 1.553
training 3233 (epoch 6): tem_loss: 1.110, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02650, total_loss: 1.554
training 3243 (epoch 6): tem_loss: 1.111, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02496, consistency_loss_ema: 0.02649, total_loss: 1.555
training 3253 (epoch 6): tem_loss: 1.111, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02496, consistency_loss_ema: 0.02652, total_loss: 1.555
training 3263 (epoch 6): tem_loss: 1.111, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02499, consistency_loss_ema: 0.02652, total_loss: 1.556
training 3273 (epoch 6): tem_loss: 1.113, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02503, consistency_loss_ema: 0.02658, total_loss: 1.559
training 3283 (epoch 6): tem_loss: 1.113, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02509, consistency_loss_ema: 0.02663, total_loss: 1.561
training 3293 (epoch 6): tem_loss: 1.113, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02505, consistency_loss_ema: 0.02657, total_loss: 1.562
training 3303 (epoch 6): tem_loss: 1.113, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02504, consistency_loss_ema: 0.02661, total_loss: 1.562
training 3313 (epoch 6): tem_loss: 1.113, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02505, consistency_loss_ema: 0.02651, total_loss: 1.562
training 3323 (epoch 6): tem_loss: 1.114, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02513, consistency_loss_ema: 0.02669, total_loss: 1.565
training 3333 (epoch 6): tem_loss: 1.115, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02513, consistency_loss_ema: 0.02669, total_loss: 1.565
training 3343 (epoch 6): tem_loss: 1.115, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02509, consistency_loss_ema: 0.02663, total_loss: 1.565
training 3353 (epoch 6): tem_loss: 1.114, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02507, consistency_loss_ema: 0.02660, total_loss: 1.563
training 3363 (epoch 6): tem_loss: 1.114, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02504, consistency_loss_ema: 0.02656, total_loss: 1.564
training 3373 (epoch 6): tem_loss: 1.114, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02500, consistency_loss_ema: 0.02651, total_loss: 1.565
[94mBMN training loss(epoch 6): tem_loss: 1.114, pem class_loss: 0.301, pem reg_loss: 0.015, total_loss: 1.565[0m
[94mBMN val loss(epoch 6): tem_loss: 1.160, pem class_loss: 0.319, pem reg_loss: 0.015, total_loss: 1.633[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.155, pem class_loss: 0.319, pem reg_loss: 0.015, total_loss: 1.628[0m
use Semi !!!
training 3375 (epoch 7): tem_loss: 1.034, pem class_loss: 0.259, pem reg_loss: 0.015, consistency_loss: 0.01918, consistency_loss_ema: 0.02688, total_loss: 1.442
training 3385 (epoch 7): tem_loss: 1.112, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02313, consistency_loss_ema: 0.02177, total_loss: 1.530
training 3395 (epoch 7): tem_loss: 1.117, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02206, consistency_loss_ema: 0.02074, total_loss: 1.536
training 3405 (epoch 7): tem_loss: 1.116, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02161, consistency_loss_ema: 0.02029, total_loss: 1.531
training 3415 (epoch 7): tem_loss: 1.109, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.02118, consistency_loss_ema: 0.01993, total_loss: 1.529
training 3425 (epoch 7): tem_loss: 1.105, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02028, consistency_loss_ema: 0.01979, total_loss: 1.520
training 3435 (epoch 7): tem_loss: 1.105, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01973, consistency_loss_ema: 0.01953, total_loss: 1.524
training 3445 (epoch 7): tem_loss: 1.101, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01935, consistency_loss_ema: 0.01932, total_loss: 1.518
training 3455 (epoch 7): tem_loss: 1.105, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01905, consistency_loss_ema: 0.01914, total_loss: 1.520
training 3465 (epoch 7): tem_loss: 1.101, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01882, consistency_loss_ema: 0.01906, total_loss: 1.519
training 3475 (epoch 7): tem_loss: 1.103, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01853, consistency_loss_ema: 0.01906, total_loss: 1.518
training 3485 (epoch 7): tem_loss: 1.105, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01833, consistency_loss_ema: 0.01885, total_loss: 1.523
training 3495 (epoch 7): tem_loss: 1.107, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01807, consistency_loss_ema: 0.01877, total_loss: 1.527
training 3505 (epoch 7): tem_loss: 1.108, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01786, consistency_loss_ema: 0.01867, total_loss: 1.529
training 3515 (epoch 7): tem_loss: 1.106, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01782, consistency_loss_ema: 0.01857, total_loss: 1.524
training 3525 (epoch 7): tem_loss: 1.105, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01773, consistency_loss_ema: 0.01838, total_loss: 1.526
training 3535 (epoch 7): tem_loss: 1.104, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01778, consistency_loss_ema: 0.01843, total_loss: 1.528
training 3545 (epoch 7): tem_loss: 1.105, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01776, consistency_loss_ema: 0.01835, total_loss: 1.529
training 3555 (epoch 7): tem_loss: 1.104, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01765, consistency_loss_ema: 0.01828, total_loss: 1.530
training 3565 (epoch 7): tem_loss: 1.105, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01753, consistency_loss_ema: 0.01819, total_loss: 1.530
training 3575 (epoch 7): tem_loss: 1.105, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01743, consistency_loss_ema: 0.01803, total_loss: 1.530
training 3585 (epoch 7): tem_loss: 1.106, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01743, consistency_loss_ema: 0.01800, total_loss: 1.531
training 3595 (epoch 7): tem_loss: 1.107, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01730, consistency_loss_ema: 0.01794, total_loss: 1.532
training 3605 (epoch 7): tem_loss: 1.107, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01726, consistency_loss_ema: 0.01794, total_loss: 1.533
training 3615 (epoch 7): tem_loss: 1.106, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01714, consistency_loss_ema: 0.01789, total_loss: 1.531
training 3625 (epoch 7): tem_loss: 1.105, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01710, consistency_loss_ema: 0.01789, total_loss: 1.528
training 3635 (epoch 7): tem_loss: 1.104, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01705, consistency_loss_ema: 0.01790, total_loss: 1.528
training 3645 (epoch 7): tem_loss: 1.105, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01704, consistency_loss_ema: 0.01788, total_loss: 1.529
training 3655 (epoch 7): tem_loss: 1.105, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01705, consistency_loss_ema: 0.01784, total_loss: 1.528
training 3665 (epoch 7): tem_loss: 1.105, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01701, consistency_loss_ema: 0.01779, total_loss: 1.529
training 3675 (epoch 7): tem_loss: 1.105, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01697, consistency_loss_ema: 0.01778, total_loss: 1.529
training 3685 (epoch 7): tem_loss: 1.106, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01693, consistency_loss_ema: 0.01773, total_loss: 1.530
training 3695 (epoch 7): tem_loss: 1.107, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01692, consistency_loss_ema: 0.01768, total_loss: 1.532
training 3705 (epoch 7): tem_loss: 1.105, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01687, consistency_loss_ema: 0.01771, total_loss: 1.531
training 3715 (epoch 7): tem_loss: 1.105, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01682, consistency_loss_ema: 0.01772, total_loss: 1.530
training 3725 (epoch 7): tem_loss: 1.105, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01683, consistency_loss_ema: 0.01770, total_loss: 1.529
training 3735 (epoch 7): tem_loss: 1.105, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01682, consistency_loss_ema: 0.01771, total_loss: 1.529
training 3745 (epoch 7): tem_loss: 1.106, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01682, consistency_loss_ema: 0.01775, total_loss: 1.529
training 3755 (epoch 7): tem_loss: 1.106, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01681, consistency_loss_ema: 0.01773, total_loss: 1.529
training 3765 (epoch 7): tem_loss: 1.104, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01681, consistency_loss_ema: 0.01766, total_loss: 1.528
training 3775 (epoch 7): tem_loss: 1.104, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01678, consistency_loss_ema: 0.01762, total_loss: 1.527
training 3785 (epoch 7): tem_loss: 1.104, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01677, consistency_loss_ema: 0.01761, total_loss: 1.528
training 3795 (epoch 7): tem_loss: 1.104, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01678, consistency_loss_ema: 0.01765, total_loss: 1.529
training 3805 (epoch 7): tem_loss: 1.105, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01676, consistency_loss_ema: 0.01766, total_loss: 1.531
training 3815 (epoch 7): tem_loss: 1.104, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01678, consistency_loss_ema: 0.01772, total_loss: 1.531
training 3825 (epoch 7): tem_loss: 1.104, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01679, consistency_loss_ema: 0.01776, total_loss: 1.530
training 3835 (epoch 7): tem_loss: 1.104, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01675, consistency_loss_ema: 0.01777, total_loss: 1.530
training 3845 (epoch 7): tem_loss: 1.104, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.01675, consistency_loss_ema: 0.01778, total_loss: 1.530
training 3855 (epoch 7): tem_loss: 1.104, pem class_loss: 0.286, pem reg_loss: 0.014, consistency_loss: 0.01676, consistency_loss_ema: 0.01779, total_loss: 1.529
[94mBMN training loss(epoch 7): tem_loss: 1.104, pem class_loss: 0.286, pem reg_loss: 0.014, total_loss: 1.529[0m
[94mBMN val loss(epoch 7): tem_loss: 1.153, pem class_loss: 0.321, pem reg_loss: 0.015, total_loss: 1.626[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.154, pem class_loss: 0.319, pem reg_loss: 0.015, total_loss: 1.625[0m
use Semi !!!
training 3857 (epoch 8): tem_loss: 1.038, pem class_loss: 0.245, pem reg_loss: 0.014, consistency_loss: 0.01982, consistency_loss_ema: 0.01813, total_loss: 1.423
training 3867 (epoch 8): tem_loss: 1.076, pem class_loss: 0.270, pem reg_loss: 0.012, consistency_loss: 0.01637, consistency_loss_ema: 0.01706, total_loss: 1.469
training 3877 (epoch 8): tem_loss: 1.089, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01702, consistency_loss_ema: 0.01861, total_loss: 1.488
training 3887 (epoch 8): tem_loss: 1.093, pem class_loss: 0.267, pem reg_loss: 0.013, consistency_loss: 0.01716, consistency_loss_ema: 0.01838, total_loss: 1.494
training 3897 (epoch 8): tem_loss: 1.087, pem class_loss: 0.268, pem reg_loss: 0.013, consistency_loss: 0.01701, consistency_loss_ema: 0.01810, total_loss: 1.489
training 3907 (epoch 8): tem_loss: 1.083, pem class_loss: 0.272, pem reg_loss: 0.014, consistency_loss: 0.01736, consistency_loss_ema: 0.01811, total_loss: 1.490
training 3917 (epoch 8): tem_loss: 1.087, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.01725, consistency_loss_ema: 0.01839, total_loss: 1.499
training 3927 (epoch 8): tem_loss: 1.092, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01718, consistency_loss_ema: 0.01838, total_loss: 1.508
training 3937 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01729, consistency_loss_ema: 0.01827, total_loss: 1.508
training 3947 (epoch 8): tem_loss: 1.089, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01722, consistency_loss_ema: 0.01884, total_loss: 1.507
training 3957 (epoch 8): tem_loss: 1.089, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01722, consistency_loss_ema: 0.01916, total_loss: 1.504
training 3967 (epoch 8): tem_loss: 1.092, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.01731, consistency_loss_ema: 0.01916, total_loss: 1.504
training 3977 (epoch 8): tem_loss: 1.097, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01720, consistency_loss_ema: 0.01901, total_loss: 1.515
training 3987 (epoch 8): tem_loss: 1.099, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01720, consistency_loss_ema: 0.01899, total_loss: 1.515
training 3997 (epoch 8): tem_loss: 1.100, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01727, consistency_loss_ema: 0.01905, total_loss: 1.513
training 4007 (epoch 8): tem_loss: 1.098, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01722, consistency_loss_ema: 0.01908, total_loss: 1.511
training 4017 (epoch 8): tem_loss: 1.096, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01722, consistency_loss_ema: 0.01906, total_loss: 1.510
training 4027 (epoch 8): tem_loss: 1.096, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01724, consistency_loss_ema: 0.01918, total_loss: 1.512
training 4037 (epoch 8): tem_loss: 1.097, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01722, consistency_loss_ema: 0.01903, total_loss: 1.514
training 4047 (epoch 8): tem_loss: 1.097, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01726, consistency_loss_ema: 0.01900, total_loss: 1.514
training 4057 (epoch 8): tem_loss: 1.094, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01717, consistency_loss_ema: 0.01911, total_loss: 1.507
training 4067 (epoch 8): tem_loss: 1.095, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01717, consistency_loss_ema: 0.01919, total_loss: 1.507
training 4077 (epoch 8): tem_loss: 1.093, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01721, consistency_loss_ema: 0.01922, total_loss: 1.505
training 4087 (epoch 8): tem_loss: 1.094, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01725, consistency_loss_ema: 0.01922, total_loss: 1.507
training 4097 (epoch 8): tem_loss: 1.095, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.01732, consistency_loss_ema: 0.01921, total_loss: 1.507
training 4107 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01734, consistency_loss_ema: 0.01924, total_loss: 1.507
training 4117 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01737, consistency_loss_ema: 0.01923, total_loss: 1.507
training 4127 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01742, consistency_loss_ema: 0.01935, total_loss: 1.509
training 4137 (epoch 8): tem_loss: 1.093, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01739, consistency_loss_ema: 0.01935, total_loss: 1.508
training 4147 (epoch 8): tem_loss: 1.095, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01741, consistency_loss_ema: 0.01931, total_loss: 1.510
training 4157 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01740, consistency_loss_ema: 0.01942, total_loss: 1.508
training 4167 (epoch 8): tem_loss: 1.095, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01742, consistency_loss_ema: 0.01934, total_loss: 1.508
training 4177 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01740, consistency_loss_ema: 0.01929, total_loss: 1.506
training 4187 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01741, consistency_loss_ema: 0.01926, total_loss: 1.508
training 4197 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01742, consistency_loss_ema: 0.01929, total_loss: 1.508
training 4207 (epoch 8): tem_loss: 1.095, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01744, consistency_loss_ema: 0.01923, total_loss: 1.509
training 4217 (epoch 8): tem_loss: 1.094, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.01746, consistency_loss_ema: 0.01922, total_loss: 1.508
training 4227 (epoch 8): tem_loss: 1.096, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01750, consistency_loss_ema: 0.01925, total_loss: 1.510
training 4237 (epoch 8): tem_loss: 1.097, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01750, consistency_loss_ema: 0.01918, total_loss: 1.512
training 4247 (epoch 8): tem_loss: 1.096, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01752, consistency_loss_ema: 0.01913, total_loss: 1.512
training 4257 (epoch 8): tem_loss: 1.097, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01752, consistency_loss_ema: 0.01908, total_loss: 1.512
training 4267 (epoch 8): tem_loss: 1.097, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01755, consistency_loss_ema: 0.01911, total_loss: 1.513
training 4277 (epoch 8): tem_loss: 1.097, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01754, consistency_loss_ema: 0.01914, total_loss: 1.514
training 4287 (epoch 8): tem_loss: 1.097, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01754, consistency_loss_ema: 0.01919, total_loss: 1.513
training 4297 (epoch 8): tem_loss: 1.097, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01755, consistency_loss_ema: 0.01917, total_loss: 1.513
training 4307 (epoch 8): tem_loss: 1.098, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01753, consistency_loss_ema: 0.01920, total_loss: 1.514
training 4317 (epoch 8): tem_loss: 1.098, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01752, consistency_loss_ema: 0.01917, total_loss: 1.514
training 4327 (epoch 8): tem_loss: 1.098, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.01755, consistency_loss_ema: 0.01917, total_loss: 1.513
training 4337 (epoch 8): tem_loss: 1.098, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01758, consistency_loss_ema: 0.01918, total_loss: 1.513
[94mBMN training loss(epoch 8): tem_loss: 1.098, pem class_loss: 0.279, pem reg_loss: 0.014, total_loss: 1.513[0m
[94mBMN val loss(epoch 8): tem_loss: 1.152, pem class_loss: 0.323, pem reg_loss: 0.015, total_loss: 1.628[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.152, pem class_loss: 0.320, pem reg_loss: 0.015, total_loss: 1.625[0m
use Semi !!!
training 4339 (epoch 9): tem_loss: 1.143, pem class_loss: 0.278, pem reg_loss: 0.012, consistency_loss: 0.01925, consistency_loss_ema: 0.02441, total_loss: 1.543
training 4349 (epoch 9): tem_loss: 1.073, pem class_loss: 0.263, pem reg_loss: 0.013, consistency_loss: 0.01877, consistency_loss_ema: 0.01780, total_loss: 1.465
training 4359 (epoch 9): tem_loss: 1.091, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01910, consistency_loss_ema: 0.01879, total_loss: 1.498
training 4369 (epoch 9): tem_loss: 1.090, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01871, consistency_loss_ema: 0.01907, total_loss: 1.493
training 4379 (epoch 9): tem_loss: 1.088, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01848, consistency_loss_ema: 0.01906, total_loss: 1.494
training 4389 (epoch 9): tem_loss: 1.081, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01832, consistency_loss_ema: 0.01919, total_loss: 1.484
training 4399 (epoch 9): tem_loss: 1.083, pem class_loss: 0.269, pem reg_loss: 0.013, consistency_loss: 0.01851, consistency_loss_ema: 0.01936, total_loss: 1.483
training 4409 (epoch 9): tem_loss: 1.080, pem class_loss: 0.267, pem reg_loss: 0.013, consistency_loss: 0.01821, consistency_loss_ema: 0.01936, total_loss: 1.476
training 4419 (epoch 9): tem_loss: 1.087, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01839, consistency_loss_ema: 0.01919, total_loss: 1.489
training 4429 (epoch 9): tem_loss: 1.087, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01831, consistency_loss_ema: 0.01933, total_loss: 1.487
training 4439 (epoch 9): tem_loss: 1.091, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01828, consistency_loss_ema: 0.01926, total_loss: 1.494
training 4449 (epoch 9): tem_loss: 1.091, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01833, consistency_loss_ema: 0.01934, total_loss: 1.496
training 4459 (epoch 9): tem_loss: 1.090, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01826, consistency_loss_ema: 0.01954, total_loss: 1.494
training 4469 (epoch 9): tem_loss: 1.087, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01827, consistency_loss_ema: 0.01957, total_loss: 1.490
training 4479 (epoch 9): tem_loss: 1.088, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01823, consistency_loss_ema: 0.01957, total_loss: 1.493
training 4489 (epoch 9): tem_loss: 1.089, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01825, consistency_loss_ema: 0.01957, total_loss: 1.494
training 4499 (epoch 9): tem_loss: 1.089, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01823, consistency_loss_ema: 0.01961, total_loss: 1.494
training 4509 (epoch 9): tem_loss: 1.090, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01819, consistency_loss_ema: 0.01962, total_loss: 1.496
training 4519 (epoch 9): tem_loss: 1.091, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01810, consistency_loss_ema: 0.01963, total_loss: 1.497
training 4529 (epoch 9): tem_loss: 1.091, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01809, consistency_loss_ema: 0.01957, total_loss: 1.500
training 4539 (epoch 9): tem_loss: 1.093, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01809, consistency_loss_ema: 0.01973, total_loss: 1.504
training 4549 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.01815, consistency_loss_ema: 0.01976, total_loss: 1.503
training 4559 (epoch 9): tem_loss: 1.095, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.01817, consistency_loss_ema: 0.01974, total_loss: 1.506
training 4569 (epoch 9): tem_loss: 1.094, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.01819, consistency_loss_ema: 0.01967, total_loss: 1.504
training 4579 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01818, consistency_loss_ema: 0.01973, total_loss: 1.502
training 4589 (epoch 9): tem_loss: 1.092, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01818, consistency_loss_ema: 0.01976, total_loss: 1.500
training 4599 (epoch 9): tem_loss: 1.093, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01821, consistency_loss_ema: 0.01975, total_loss: 1.501
training 4609 (epoch 9): tem_loss: 1.092, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01825, consistency_loss_ema: 0.01978, total_loss: 1.500
training 4619 (epoch 9): tem_loss: 1.094, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01826, consistency_loss_ema: 0.01993, total_loss: 1.502
training 4629 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01824, consistency_loss_ema: 0.01999, total_loss: 1.501
training 4639 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01828, consistency_loss_ema: 0.01992, total_loss: 1.501
training 4649 (epoch 9): tem_loss: 1.094, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01834, consistency_loss_ema: 0.01990, total_loss: 1.501
training 4659 (epoch 9): tem_loss: 1.092, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01831, consistency_loss_ema: 0.01980, total_loss: 1.499
training 4669 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01832, consistency_loss_ema: 0.01984, total_loss: 1.500
training 4679 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01842, consistency_loss_ema: 0.01980, total_loss: 1.501
training 4689 (epoch 9): tem_loss: 1.093, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01845, consistency_loss_ema: 0.01989, total_loss: 1.502
training 4699 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01841, consistency_loss_ema: 0.01989, total_loss: 1.501
training 4709 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01841, consistency_loss_ema: 0.01982, total_loss: 1.502
training 4719 (epoch 9): tem_loss: 1.094, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01844, consistency_loss_ema: 0.01980, total_loss: 1.503
training 4729 (epoch 9): tem_loss: 1.095, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01843, consistency_loss_ema: 0.01978, total_loss: 1.504
training 4739 (epoch 9): tem_loss: 1.096, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01843, consistency_loss_ema: 0.01977, total_loss: 1.506
training 4749 (epoch 9): tem_loss: 1.096, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01850, consistency_loss_ema: 0.01984, total_loss: 1.505
training 4759 (epoch 9): tem_loss: 1.095, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01850, consistency_loss_ema: 0.01984, total_loss: 1.505
training 4769 (epoch 9): tem_loss: 1.095, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01850, consistency_loss_ema: 0.01982, total_loss: 1.504
training 4779 (epoch 9): tem_loss: 1.094, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01852, consistency_loss_ema: 0.01988, total_loss: 1.503
training 4789 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01853, consistency_loss_ema: 0.01992, total_loss: 1.502
training 4799 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01856, consistency_loss_ema: 0.01995, total_loss: 1.501
training 4809 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01857, consistency_loss_ema: 0.01994, total_loss: 1.502
training 4819 (epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01857, consistency_loss_ema: 0.01991, total_loss: 1.502
[94mBMN training loss(epoch 9): tem_loss: 1.093, pem class_loss: 0.275, pem reg_loss: 0.013, total_loss: 1.502[0m
[94mBMN val loss(epoch 9): tem_loss: 1.152, pem class_loss: 0.323, pem reg_loss: 0.015, total_loss: 1.628[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.152, pem class_loss: 0.323, pem reg_loss: 0.015, total_loss: 1.627[0m
unlabel percent:  0.2
eval student model !!
load : ./checkpoint/Semi-base-0.2-2/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472620
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.49551624845742%
AR@1 is 	 0.3367475661593309
AR@5 is 	 0.49583161936103115
AR@10 is 	 0.5699163581516523
AR@100 is 	 0.7546825723296311
load : ./checkpoint/Semi-base-0.2-2/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472703
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.32420128890718%
AR@1 is 	 0.33626765391471275
AR@5 is 	 0.49625668449197863
AR@10 is 	 0.5704648292883587
AR@100 is 	 0.7532976827094474
eval teacher model !!
load : ./checkpoint/Semi-base-0.2-2/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472620
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.48487590840531%
AR@1 is 	 0.33699437817084876
AR@5 is 	 0.4957904840257781
AR@10 is 	 0.5693130399012752
AR@100 is 	 0.755176196352667
load : ./checkpoint/Semi-base-0.2-2/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472710
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.35399698340875%
AR@1 is 	 0.33602084190319487
AR@5 is 	 0.49638009049773757
AR@10 is 	 0.5691484985602633
AR@100 is 	 0.7525572466748938
#
train subset video numbers: 8688
unlabel unlabeled subset video numbers: 961
validation subset video numbers: 4728
use 0.9 label for training!!!
training batchsize : 16
unlabel_training batchsize : 4
use Semi !!!
training 1 (epoch 0): tem_loss: 1.417, pem class_loss: 0.693, pem reg_loss: 0.040, consistency_loss: 0.00063, consistency_loss_ema: 0.00000, total_loss: 2.513
training 11 (epoch 0): tem_loss: 1.373, pem class_loss: 0.583, pem reg_loss: 0.037, consistency_loss: 0.00013, consistency_loss_ema: 0.00000, total_loss: 2.330
training 21 (epoch 0): tem_loss: 1.354, pem class_loss: 0.493, pem reg_loss: 0.031, consistency_loss: 0.00012, consistency_loss_ema: 0.00004, total_loss: 2.160
training 31 (epoch 0): tem_loss: 1.334, pem class_loss: 0.469, pem reg_loss: 0.029, consistency_loss: 0.00014, consistency_loss_ema: 0.00009, total_loss: 2.097
training 41 (epoch 0): tem_loss: 1.322, pem class_loss: 0.451, pem reg_loss: 0.028, consistency_loss: 0.00017, consistency_loss_ema: 0.00013, total_loss: 2.054
training 51 (epoch 0): tem_loss: 1.311, pem class_loss: 0.448, pem reg_loss: 0.027, consistency_loss: 0.00021, consistency_loss_ema: 0.00016, total_loss: 2.031
training 61 (epoch 0): tem_loss: 1.304, pem class_loss: 0.440, pem reg_loss: 0.027, consistency_loss: 0.00023, consistency_loss_ema: 0.00018, total_loss: 2.011
training 71 (epoch 0): tem_loss: 1.296, pem class_loss: 0.430, pem reg_loss: 0.026, consistency_loss: 0.00025, consistency_loss_ema: 0.00022, total_loss: 1.984
training 81 (epoch 0): tem_loss: 1.287, pem class_loss: 0.424, pem reg_loss: 0.025, consistency_loss: 0.00026, consistency_loss_ema: 0.00024, total_loss: 1.966
training 91 (epoch 0): tem_loss: 1.287, pem class_loss: 0.419, pem reg_loss: 0.025, consistency_loss: 0.00028, consistency_loss_ema: 0.00026, total_loss: 1.955
training 101 (epoch 0): tem_loss: 1.283, pem class_loss: 0.416, pem reg_loss: 0.025, consistency_loss: 0.00029, consistency_loss_ema: 0.00027, total_loss: 1.945
training 111 (epoch 0): tem_loss: 1.280, pem class_loss: 0.412, pem reg_loss: 0.024, consistency_loss: 0.00030, consistency_loss_ema: 0.00028, total_loss: 1.934
training 121 (epoch 0): tem_loss: 1.270, pem class_loss: 0.405, pem reg_loss: 0.024, consistency_loss: 0.00032, consistency_loss_ema: 0.00029, total_loss: 1.915
training 131 (epoch 0): tem_loss: 1.265, pem class_loss: 0.402, pem reg_loss: 0.024, consistency_loss: 0.00033, consistency_loss_ema: 0.00031, total_loss: 1.904
training 141 (epoch 0): tem_loss: 1.264, pem class_loss: 0.399, pem reg_loss: 0.024, consistency_loss: 0.00034, consistency_loss_ema: 0.00031, total_loss: 1.898
training 151 (epoch 0): tem_loss: 1.260, pem class_loss: 0.397, pem reg_loss: 0.023, consistency_loss: 0.00034, consistency_loss_ema: 0.00032, total_loss: 1.892
training 161 (epoch 0): tem_loss: 1.254, pem class_loss: 0.395, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00032, total_loss: 1.882
training 171 (epoch 0): tem_loss: 1.247, pem class_loss: 0.392, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00033, total_loss: 1.870
training 181 (epoch 0): tem_loss: 1.246, pem class_loss: 0.391, pem reg_loss: 0.023, consistency_loss: 0.00035, consistency_loss_ema: 0.00033, total_loss: 1.866
training 191 (epoch 0): tem_loss: 1.245, pem class_loss: 0.390, pem reg_loss: 0.023, consistency_loss: 0.00037, consistency_loss_ema: 0.00035, total_loss: 1.864
training 201 (epoch 0): tem_loss: 1.242, pem class_loss: 0.388, pem reg_loss: 0.023, consistency_loss: 0.00037, consistency_loss_ema: 0.00035, total_loss: 1.857
training 211 (epoch 0): tem_loss: 1.238, pem class_loss: 0.385, pem reg_loss: 0.023, consistency_loss: 0.00038, consistency_loss_ema: 0.00036, total_loss: 1.848
training 221 (epoch 0): tem_loss: 1.237, pem class_loss: 0.385, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.846
training 231 (epoch 0): tem_loss: 1.236, pem class_loss: 0.384, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.844
training 241 (epoch 0): tem_loss: 1.233, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.839
training 251 (epoch 0): tem_loss: 1.231, pem class_loss: 0.382, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.835
training 261 (epoch 0): tem_loss: 1.229, pem class_loss: 0.381, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.831
training 271 (epoch 0): tem_loss: 1.225, pem class_loss: 0.380, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.826
training 281 (epoch 0): tem_loss: 1.222, pem class_loss: 0.379, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.820
training 291 (epoch 0): tem_loss: 1.220, pem class_loss: 0.377, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00037, total_loss: 1.816
training 301 (epoch 0): tem_loss: 1.217, pem class_loss: 0.376, pem reg_loss: 0.022, consistency_loss: 0.00039, consistency_loss_ema: 0.00038, total_loss: 1.810
training 311 (epoch 0): tem_loss: 1.214, pem class_loss: 0.375, pem reg_loss: 0.022, consistency_loss: 0.00040, consistency_loss_ema: 0.00039, total_loss: 1.805
training 321 (epoch 0): tem_loss: 1.215, pem class_loss: 0.373, pem reg_loss: 0.022, consistency_loss: 0.00041, consistency_loss_ema: 0.00039, total_loss: 1.803
training 331 (epoch 0): tem_loss: 1.213, pem class_loss: 0.373, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.801
training 341 (epoch 0): tem_loss: 1.212, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.799
training 351 (epoch 0): tem_loss: 1.211, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.797
training 361 (epoch 0): tem_loss: 1.212, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00042, consistency_loss_ema: 0.00041, total_loss: 1.798
training 371 (epoch 0): tem_loss: 1.210, pem class_loss: 0.371, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.795
training 381 (epoch 0): tem_loss: 1.210, pem class_loss: 0.371, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.794
training 391 (epoch 0): tem_loss: 1.208, pem class_loss: 0.370, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.791
training 401 (epoch 0): tem_loss: 1.207, pem class_loss: 0.371, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.791
training 411 (epoch 0): tem_loss: 1.207, pem class_loss: 0.370, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.788
training 421 (epoch 0): tem_loss: 1.205, pem class_loss: 0.369, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00040, total_loss: 1.785
training 431 (epoch 0): tem_loss: 1.203, pem class_loss: 0.369, pem reg_loss: 0.021, consistency_loss: 0.00041, consistency_loss_ema: 0.00041, total_loss: 1.783
training 441 (epoch 0): tem_loss: 1.202, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00042, consistency_loss_ema: 0.00041, total_loss: 1.781
training 451 (epoch 0): tem_loss: 1.202, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00042, consistency_loss_ema: 0.00041, total_loss: 1.780
training 461 (epoch 0): tem_loss: 1.200, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00042, consistency_loss_ema: 0.00041, total_loss: 1.778
training 471 (epoch 0): tem_loss: 1.200, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00042, consistency_loss_ema: 0.00041, total_loss: 1.778
training 481 (epoch 0): tem_loss: 1.198, pem class_loss: 0.367, pem reg_loss: 0.021, consistency_loss: 0.00042, consistency_loss_ema: 0.00042, total_loss: 1.775
training 491 (epoch 0): tem_loss: 1.197, pem class_loss: 0.366, pem reg_loss: 0.021, consistency_loss: 0.00043, consistency_loss_ema: 0.00043, total_loss: 1.772
training 501 (epoch 0): tem_loss: 1.196, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00044, consistency_loss_ema: 0.00044, total_loss: 1.774
training 511 (epoch 0): tem_loss: 1.196, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00044, consistency_loss_ema: 0.00044, total_loss: 1.773
training 521 (epoch 0): tem_loss: 1.194, pem class_loss: 0.366, pem reg_loss: 0.021, consistency_loss: 0.00044, consistency_loss_ema: 0.00044, total_loss: 1.770
training 531 (epoch 0): tem_loss: 1.194, pem class_loss: 0.367, pem reg_loss: 0.021, consistency_loss: 0.00045, consistency_loss_ema: 0.00045, total_loss: 1.771
training 541 (epoch 0): tem_loss: 1.194, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00045, consistency_loss_ema: 0.00045, total_loss: 1.772
[94mBMN training loss(epoch 0): tem_loss: 1.194, pem class_loss: 0.368, pem reg_loss: 0.021, total_loss: 1.772[0m
[94mBMN val loss(epoch 0): tem_loss: 1.172, pem class_loss: 0.368, pem reg_loss: 0.020, total_loss: 1.742[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.157, pem class_loss: 0.360, pem reg_loss: 0.020, total_loss: 1.713[0m
use Semi !!!
training 544 (epoch 1): tem_loss: 1.149, pem class_loss: 0.441, pem reg_loss: 0.021, consistency_loss: 0.00213, consistency_loss_ema: 0.00437, total_loss: 1.798
training 554 (epoch 1): tem_loss: 1.158, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00337, consistency_loss_ema: 0.00324, total_loss: 1.690
training 564 (epoch 1): tem_loss: 1.155, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00305, consistency_loss_ema: 0.00303, total_loss: 1.684
training 574 (epoch 1): tem_loss: 1.161, pem class_loss: 0.333, pem reg_loss: 0.019, consistency_loss: 0.00290, consistency_loss_ema: 0.00282, total_loss: 1.683
training 584 (epoch 1): tem_loss: 1.152, pem class_loss: 0.334, pem reg_loss: 0.019, consistency_loss: 0.00274, consistency_loss_ema: 0.00266, total_loss: 1.673
training 594 (epoch 1): tem_loss: 1.145, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00281, consistency_loss_ema: 0.00270, total_loss: 1.668
training 604 (epoch 1): tem_loss: 1.145, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.00282, consistency_loss_ema: 0.00270, total_loss: 1.669
training 614 (epoch 1): tem_loss: 1.143, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00278, consistency_loss_ema: 0.00268, total_loss: 1.666
training 624 (epoch 1): tem_loss: 1.137, pem class_loss: 0.336, pem reg_loss: 0.019, consistency_loss: 0.00271, consistency_loss_ema: 0.00265, total_loss: 1.661
training 634 (epoch 1): tem_loss: 1.145, pem class_loss: 0.335, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00270, total_loss: 1.668
training 644 (epoch 1): tem_loss: 1.144, pem class_loss: 0.337, pem reg_loss: 0.019, consistency_loss: 0.00280, consistency_loss_ema: 0.00277, total_loss: 1.669
training 654 (epoch 1): tem_loss: 1.146, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00278, consistency_loss_ema: 0.00277, total_loss: 1.679
training 664 (epoch 1): tem_loss: 1.146, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00275, consistency_loss_ema: 0.00271, total_loss: 1.678
training 674 (epoch 1): tem_loss: 1.144, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00271, consistency_loss_ema: 0.00267, total_loss: 1.680
training 684 (epoch 1): tem_loss: 1.145, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00274, consistency_loss_ema: 0.00268, total_loss: 1.677
training 694 (epoch 1): tem_loss: 1.142, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00275, total_loss: 1.672
training 704 (epoch 1): tem_loss: 1.139, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00272, consistency_loss_ema: 0.00274, total_loss: 1.669
training 714 (epoch 1): tem_loss: 1.140, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00271, consistency_loss_ema: 0.00271, total_loss: 1.670
training 724 (epoch 1): tem_loss: 1.141, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00273, consistency_loss_ema: 0.00273, total_loss: 1.674
training 734 (epoch 1): tem_loss: 1.140, pem class_loss: 0.343, pem reg_loss: 0.019, consistency_loss: 0.00273, consistency_loss_ema: 0.00273, total_loss: 1.672
training 744 (epoch 1): tem_loss: 1.137, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00270, consistency_loss_ema: 0.00270, total_loss: 1.668
training 754 (epoch 1): tem_loss: 1.136, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00270, consistency_loss_ema: 0.00270, total_loss: 1.666
training 764 (epoch 1): tem_loss: 1.134, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00270, consistency_loss_ema: 0.00270, total_loss: 1.661
training 774 (epoch 1): tem_loss: 1.136, pem class_loss: 0.341, pem reg_loss: 0.019, consistency_loss: 0.00268, consistency_loss_ema: 0.00269, total_loss: 1.664
training 784 (epoch 1): tem_loss: 1.135, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00267, consistency_loss_ema: 0.00267, total_loss: 1.662
training 794 (epoch 1): tem_loss: 1.136, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00264, consistency_loss_ema: 0.00266, total_loss: 1.663
training 804 (epoch 1): tem_loss: 1.137, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00263, total_loss: 1.664
training 814 (epoch 1): tem_loss: 1.137, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00262, total_loss: 1.663
training 824 (epoch 1): tem_loss: 1.139, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00259, consistency_loss_ema: 0.00260, total_loss: 1.665
training 834 (epoch 1): tem_loss: 1.137, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00259, consistency_loss_ema: 0.00260, total_loss: 1.664
training 844 (epoch 1): tem_loss: 1.137, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00262, total_loss: 1.664
training 854 (epoch 1): tem_loss: 1.138, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00263, total_loss: 1.664
training 864 (epoch 1): tem_loss: 1.138, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00262, total_loss: 1.663
training 874 (epoch 1): tem_loss: 1.137, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00260, consistency_loss_ema: 0.00263, total_loss: 1.663
training 884 (epoch 1): tem_loss: 1.136, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00263, total_loss: 1.662
training 894 (epoch 1): tem_loss: 1.135, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00264, total_loss: 1.662
training 904 (epoch 1): tem_loss: 1.133, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00265, total_loss: 1.660
training 914 (epoch 1): tem_loss: 1.132, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00265, total_loss: 1.658
training 924 (epoch 1): tem_loss: 1.131, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00266, total_loss: 1.658
training 934 (epoch 1): tem_loss: 1.132, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00265, total_loss: 1.659
training 944 (epoch 1): tem_loss: 1.131, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00265, total_loss: 1.656
training 954 (epoch 1): tem_loss: 1.132, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00266, total_loss: 1.657
training 964 (epoch 1): tem_loss: 1.131, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00267, total_loss: 1.655
training 974 (epoch 1): tem_loss: 1.131, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00267, total_loss: 1.654
training 984 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00263, consistency_loss_ema: 0.00268, total_loss: 1.655
training 994 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00267, total_loss: 1.656
training 1004 (epoch 1): tem_loss: 1.132, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00261, consistency_loss_ema: 0.00266, total_loss: 1.654
training 1014 (epoch 1): tem_loss: 1.131, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00267, total_loss: 1.655
training 1024 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00267, total_loss: 1.655
training 1034 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00261, consistency_loss_ema: 0.00268, total_loss: 1.655
training 1044 (epoch 1): tem_loss: 1.131, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00268, total_loss: 1.656
training 1054 (epoch 1): tem_loss: 1.130, pem class_loss: 0.338, pem reg_loss: 0.019, consistency_loss: 0.00262, consistency_loss_ema: 0.00269, total_loss: 1.653
training 1064 (epoch 1): tem_loss: 1.130, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00263, consistency_loss_ema: 0.00270, total_loss: 1.652
training 1074 (epoch 1): tem_loss: 1.130, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00263, consistency_loss_ema: 0.00270, total_loss: 1.651
training 1084 (epoch 1): tem_loss: 1.129, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00264, consistency_loss_ema: 0.00271, total_loss: 1.651
[94mBMN training loss(epoch 1): tem_loss: 1.129, pem class_loss: 0.337, pem reg_loss: 0.018, total_loss: 1.651[0m
[94mBMN val loss(epoch 1): tem_loss: 1.142, pem class_loss: 0.332, pem reg_loss: 0.018, total_loss: 1.651[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.133, pem class_loss: 0.331, pem reg_loss: 0.018, total_loss: 1.641[0m
use Semi !!!
training 1087 (epoch 2): tem_loss: 0.934, pem class_loss: 0.245, pem reg_loss: 0.013, consistency_loss: 0.01226, consistency_loss_ema: 0.01077, total_loss: 1.304
training 1097 (epoch 2): tem_loss: 1.072, pem class_loss: 0.320, pem reg_loss: 0.018, consistency_loss: 0.00999, consistency_loss_ema: 0.00965, total_loss: 1.573
training 1107 (epoch 2): tem_loss: 1.087, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.00989, consistency_loss_ema: 0.00961, total_loss: 1.573
training 1117 (epoch 2): tem_loss: 1.088, pem class_loss: 0.309, pem reg_loss: 0.017, consistency_loss: 0.00954, consistency_loss_ema: 0.00954, total_loss: 1.567
training 1127 (epoch 2): tem_loss: 1.082, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.00939, consistency_loss_ema: 0.00938, total_loss: 1.549
training 1137 (epoch 2): tem_loss: 1.095, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.00901, consistency_loss_ema: 0.00939, total_loss: 1.562
training 1147 (epoch 2): tem_loss: 1.100, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.00871, consistency_loss_ema: 0.00914, total_loss: 1.571
training 1157 (epoch 2): tem_loss: 1.107, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.00848, consistency_loss_ema: 0.00878, total_loss: 1.584
training 1167 (epoch 2): tem_loss: 1.109, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.00839, consistency_loss_ema: 0.00874, total_loss: 1.585
training 1177 (epoch 2): tem_loss: 1.110, pem class_loss: 0.311, pem reg_loss: 0.017, consistency_loss: 0.00832, consistency_loss_ema: 0.00869, total_loss: 1.587
training 1187 (epoch 2): tem_loss: 1.108, pem class_loss: 0.314, pem reg_loss: 0.017, consistency_loss: 0.00839, consistency_loss_ema: 0.00882, total_loss: 1.589
training 1197 (epoch 2): tem_loss: 1.106, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.00849, consistency_loss_ema: 0.00888, total_loss: 1.589
training 1207 (epoch 2): tem_loss: 1.104, pem class_loss: 0.315, pem reg_loss: 0.017, consistency_loss: 0.00847, consistency_loss_ema: 0.00887, total_loss: 1.588
training 1217 (epoch 2): tem_loss: 1.105, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.00846, consistency_loss_ema: 0.00878, total_loss: 1.593
training 1227 (epoch 2): tem_loss: 1.104, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.00850, consistency_loss_ema: 0.00892, total_loss: 1.590
training 1237 (epoch 2): tem_loss: 1.101, pem class_loss: 0.316, pem reg_loss: 0.017, consistency_loss: 0.00853, consistency_loss_ema: 0.00902, total_loss: 1.585
training 1247 (epoch 2): tem_loss: 1.102, pem class_loss: 0.316, pem reg_loss: 0.017, consistency_loss: 0.00855, consistency_loss_ema: 0.00907, total_loss: 1.586
training 1257 (epoch 2): tem_loss: 1.105, pem class_loss: 0.316, pem reg_loss: 0.017, consistency_loss: 0.00855, consistency_loss_ema: 0.00909, total_loss: 1.589
training 1267 (epoch 2): tem_loss: 1.105, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.00846, consistency_loss_ema: 0.00900, total_loss: 1.590
training 1277 (epoch 2): tem_loss: 1.106, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.00840, consistency_loss_ema: 0.00891, total_loss: 1.592
training 1287 (epoch 2): tem_loss: 1.105, pem class_loss: 0.318, pem reg_loss: 0.017, consistency_loss: 0.00834, consistency_loss_ema: 0.00882, total_loss: 1.592
training 1297 (epoch 2): tem_loss: 1.103, pem class_loss: 0.317, pem reg_loss: 0.017, consistency_loss: 0.00834, consistency_loss_ema: 0.00879, total_loss: 1.587
training 1307 (epoch 2): tem_loss: 1.104, pem class_loss: 0.319, pem reg_loss: 0.017, consistency_loss: 0.00842, consistency_loss_ema: 0.00882, total_loss: 1.592
training 1317 (epoch 2): tem_loss: 1.104, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.00844, consistency_loss_ema: 0.00883, total_loss: 1.593
training 1327 (epoch 2): tem_loss: 1.105, pem class_loss: 0.320, pem reg_loss: 0.017, consistency_loss: 0.00847, consistency_loss_ema: 0.00883, total_loss: 1.594
training 1337 (epoch 2): tem_loss: 1.105, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.00847, consistency_loss_ema: 0.00881, total_loss: 1.596
training 1347 (epoch 2): tem_loss: 1.105, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.00847, consistency_loss_ema: 0.00880, total_loss: 1.596
training 1357 (epoch 2): tem_loss: 1.105, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.00848, consistency_loss_ema: 0.00879, total_loss: 1.596
training 1367 (epoch 2): tem_loss: 1.108, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.00845, consistency_loss_ema: 0.00884, total_loss: 1.598
training 1377 (epoch 2): tem_loss: 1.108, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.00840, consistency_loss_ema: 0.00878, total_loss: 1.600
training 1387 (epoch 2): tem_loss: 1.108, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.00839, consistency_loss_ema: 0.00876, total_loss: 1.600
training 1397 (epoch 2): tem_loss: 1.108, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.00841, consistency_loss_ema: 0.00877, total_loss: 1.598
training 1407 (epoch 2): tem_loss: 1.107, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.00844, consistency_loss_ema: 0.00878, total_loss: 1.598
training 1417 (epoch 2): tem_loss: 1.106, pem class_loss: 0.321, pem reg_loss: 0.017, consistency_loss: 0.00842, consistency_loss_ema: 0.00878, total_loss: 1.596
training 1427 (epoch 2): tem_loss: 1.107, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.00842, consistency_loss_ema: 0.00878, total_loss: 1.598
training 1437 (epoch 2): tem_loss: 1.108, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00842, consistency_loss_ema: 0.00877, total_loss: 1.601
training 1447 (epoch 2): tem_loss: 1.108, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00841, consistency_loss_ema: 0.00876, total_loss: 1.602
training 1457 (epoch 2): tem_loss: 1.107, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.00839, consistency_loss_ema: 0.00872, total_loss: 1.600
training 1467 (epoch 2): tem_loss: 1.108, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.00838, consistency_loss_ema: 0.00871, total_loss: 1.600
training 1477 (epoch 2): tem_loss: 1.109, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00836, consistency_loss_ema: 0.00869, total_loss: 1.602
training 1487 (epoch 2): tem_loss: 1.110, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00834, consistency_loss_ema: 0.00867, total_loss: 1.604
training 1497 (epoch 2): tem_loss: 1.110, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00832, consistency_loss_ema: 0.00866, total_loss: 1.603
training 1507 (epoch 2): tem_loss: 1.111, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00830, consistency_loss_ema: 0.00865, total_loss: 1.605
training 1517 (epoch 2): tem_loss: 1.112, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00829, consistency_loss_ema: 0.00862, total_loss: 1.605
training 1527 (epoch 2): tem_loss: 1.110, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.00829, consistency_loss_ema: 0.00864, total_loss: 1.602
training 1537 (epoch 2): tem_loss: 1.110, pem class_loss: 0.322, pem reg_loss: 0.017, consistency_loss: 0.00829, consistency_loss_ema: 0.00862, total_loss: 1.602
training 1547 (epoch 2): tem_loss: 1.111, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00830, consistency_loss_ema: 0.00863, total_loss: 1.604
training 1557 (epoch 2): tem_loss: 1.111, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00833, consistency_loss_ema: 0.00863, total_loss: 1.604
training 1567 (epoch 2): tem_loss: 1.110, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00833, consistency_loss_ema: 0.00863, total_loss: 1.604
training 1577 (epoch 2): tem_loss: 1.110, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00834, consistency_loss_ema: 0.00864, total_loss: 1.603
training 1587 (epoch 2): tem_loss: 1.110, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00834, consistency_loss_ema: 0.00863, total_loss: 1.604
training 1597 (epoch 2): tem_loss: 1.110, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00836, consistency_loss_ema: 0.00867, total_loss: 1.603
training 1607 (epoch 2): tem_loss: 1.109, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00835, consistency_loss_ema: 0.00867, total_loss: 1.602
training 1617 (epoch 2): tem_loss: 1.110, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00833, consistency_loss_ema: 0.00865, total_loss: 1.603
training 1627 (epoch 2): tem_loss: 1.109, pem class_loss: 0.323, pem reg_loss: 0.017, consistency_loss: 0.00834, consistency_loss_ema: 0.00867, total_loss: 1.602
[94mBMN training loss(epoch 2): tem_loss: 1.109, pem class_loss: 0.322, pem reg_loss: 0.017, total_loss: 1.602[0m
[94mBMN val loss(epoch 2): tem_loss: 1.133, pem class_loss: 0.329, pem reg_loss: 0.017, total_loss: 1.633[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.130, pem class_loss: 0.324, pem reg_loss: 0.017, total_loss: 1.622[0m
use Semi !!!
training 1630 (epoch 3): tem_loss: 0.957, pem class_loss: 0.269, pem reg_loss: 0.011, consistency_loss: 0.01841, consistency_loss_ema: 0.01646, total_loss: 1.340
training 1640 (epoch 3): tem_loss: 1.072, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02052, consistency_loss_ema: 0.01967, total_loss: 1.549
training 1650 (epoch 3): tem_loss: 1.058, pem class_loss: 0.299, pem reg_loss: 0.016, consistency_loss: 0.01830, consistency_loss_ema: 0.01858, total_loss: 1.513
training 1660 (epoch 3): tem_loss: 1.062, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.01845, consistency_loss_ema: 0.01916, total_loss: 1.522
training 1670 (epoch 3): tem_loss: 1.069, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.01869, consistency_loss_ema: 0.01947, total_loss: 1.541
training 1680 (epoch 3): tem_loss: 1.088, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.01837, consistency_loss_ema: 0.01923, total_loss: 1.563
training 1690 (epoch 3): tem_loss: 1.088, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.01865, consistency_loss_ema: 0.01876, total_loss: 1.564
training 1700 (epoch 3): tem_loss: 1.091, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.01844, consistency_loss_ema: 0.01848, total_loss: 1.566
training 1710 (epoch 3): tem_loss: 1.093, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.01823, consistency_loss_ema: 0.01811, total_loss: 1.562
training 1720 (epoch 3): tem_loss: 1.089, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.01815, consistency_loss_ema: 0.01831, total_loss: 1.554
training 1730 (epoch 3): tem_loss: 1.088, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.01808, consistency_loss_ema: 0.01846, total_loss: 1.555
training 1740 (epoch 3): tem_loss: 1.085, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.01813, consistency_loss_ema: 0.01861, total_loss: 1.550
training 1750 (epoch 3): tem_loss: 1.085, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.01815, consistency_loss_ema: 0.01860, total_loss: 1.551
training 1760 (epoch 3): tem_loss: 1.087, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.01812, consistency_loss_ema: 0.01852, total_loss: 1.547
training 1770 (epoch 3): tem_loss: 1.089, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.01814, consistency_loss_ema: 0.01869, total_loss: 1.553
training 1780 (epoch 3): tem_loss: 1.091, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.01814, consistency_loss_ema: 0.01868, total_loss: 1.555
training 1790 (epoch 3): tem_loss: 1.094, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.01797, consistency_loss_ema: 0.01884, total_loss: 1.562
training 1800 (epoch 3): tem_loss: 1.095, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.01788, consistency_loss_ema: 0.01878, total_loss: 1.564
training 1810 (epoch 3): tem_loss: 1.094, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.01777, consistency_loss_ema: 0.01885, total_loss: 1.563
training 1820 (epoch 3): tem_loss: 1.094, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.01776, consistency_loss_ema: 0.01882, total_loss: 1.565
training 1830 (epoch 3): tem_loss: 1.097, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.01773, consistency_loss_ema: 0.01887, total_loss: 1.567
training 1840 (epoch 3): tem_loss: 1.098, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.01771, consistency_loss_ema: 0.01896, total_loss: 1.570
training 1850 (epoch 3): tem_loss: 1.098, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.01775, consistency_loss_ema: 0.01881, total_loss: 1.570
training 1860 (epoch 3): tem_loss: 1.098, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.01774, consistency_loss_ema: 0.01889, total_loss: 1.572
training 1870 (epoch 3): tem_loss: 1.099, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.01778, consistency_loss_ema: 0.01893, total_loss: 1.574
training 1880 (epoch 3): tem_loss: 1.100, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.01775, consistency_loss_ema: 0.01883, total_loss: 1.575
training 1890 (epoch 3): tem_loss: 1.101, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01767, consistency_loss_ema: 0.01861, total_loss: 1.578
training 1900 (epoch 3): tem_loss: 1.101, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01760, consistency_loss_ema: 0.01849, total_loss: 1.580
training 1910 (epoch 3): tem_loss: 1.102, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01757, consistency_loss_ema: 0.01846, total_loss: 1.581
training 1920 (epoch 3): tem_loss: 1.102, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01750, consistency_loss_ema: 0.01844, total_loss: 1.581
training 1930 (epoch 3): tem_loss: 1.103, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01746, consistency_loss_ema: 0.01835, total_loss: 1.582
training 1940 (epoch 3): tem_loss: 1.105, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.01745, consistency_loss_ema: 0.01833, total_loss: 1.585
training 1950 (epoch 3): tem_loss: 1.105, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01737, consistency_loss_ema: 0.01830, total_loss: 1.584
training 1960 (epoch 3): tem_loss: 1.105, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01739, consistency_loss_ema: 0.01824, total_loss: 1.583
training 1970 (epoch 3): tem_loss: 1.104, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01738, consistency_loss_ema: 0.01820, total_loss: 1.582
training 1980 (epoch 3): tem_loss: 1.104, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01742, consistency_loss_ema: 0.01824, total_loss: 1.582
training 1990 (epoch 3): tem_loss: 1.104, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01735, consistency_loss_ema: 0.01816, total_loss: 1.582
training 2000 (epoch 3): tem_loss: 1.103, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01732, consistency_loss_ema: 0.01810, total_loss: 1.580
training 2010 (epoch 3): tem_loss: 1.104, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01724, consistency_loss_ema: 0.01803, total_loss: 1.581
training 2020 (epoch 3): tem_loss: 1.104, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01721, consistency_loss_ema: 0.01798, total_loss: 1.583
training 2030 (epoch 3): tem_loss: 1.103, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01723, consistency_loss_ema: 0.01801, total_loss: 1.580
training 2040 (epoch 3): tem_loss: 1.103, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.01725, consistency_loss_ema: 0.01798, total_loss: 1.581
training 2050 (epoch 3): tem_loss: 1.102, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01723, consistency_loss_ema: 0.01805, total_loss: 1.580
training 2060 (epoch 3): tem_loss: 1.102, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01726, consistency_loss_ema: 0.01809, total_loss: 1.578
training 2070 (epoch 3): tem_loss: 1.101, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01723, consistency_loss_ema: 0.01803, total_loss: 1.577
training 2080 (epoch 3): tem_loss: 1.101, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01718, consistency_loss_ema: 0.01797, total_loss: 1.576
training 2090 (epoch 3): tem_loss: 1.101, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.01715, consistency_loss_ema: 0.01790, total_loss: 1.574
training 2100 (epoch 3): tem_loss: 1.101, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.01714, consistency_loss_ema: 0.01788, total_loss: 1.573
training 2110 (epoch 3): tem_loss: 1.102, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01714, consistency_loss_ema: 0.01789, total_loss: 1.576
training 2120 (epoch 3): tem_loss: 1.102, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01713, consistency_loss_ema: 0.01783, total_loss: 1.577
training 2130 (epoch 3): tem_loss: 1.102, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01709, consistency_loss_ema: 0.01780, total_loss: 1.578
training 2140 (epoch 3): tem_loss: 1.102, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01706, consistency_loss_ema: 0.01774, total_loss: 1.577
training 2150 (epoch 3): tem_loss: 1.102, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01705, consistency_loss_ema: 0.01769, total_loss: 1.577
training 2160 (epoch 3): tem_loss: 1.102, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.01701, consistency_loss_ema: 0.01765, total_loss: 1.578
training 2170 (epoch 3): tem_loss: 1.102, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.01699, consistency_loss_ema: 0.01760, total_loss: 1.578
[94mBMN training loss(epoch 3): tem_loss: 1.102, pem class_loss: 0.314, pem reg_loss: 0.016, total_loss: 1.578[0m
[94mBMN val loss(epoch 3): tem_loss: 1.138, pem class_loss: 0.326, pem reg_loss: 0.017, total_loss: 1.630[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.134, pem class_loss: 0.321, pem reg_loss: 0.016, total_loss: 1.617[0m
use Semi !!!
training 2173 (epoch 4): tem_loss: 1.074, pem class_loss: 0.293, pem reg_loss: 0.020, consistency_loss: 0.02274, consistency_loss_ema: 0.03807, total_loss: 1.565
training 2183 (epoch 4): tem_loss: 1.105, pem class_loss: 0.297, pem reg_loss: 0.016, consistency_loss: 0.02594, consistency_loss_ema: 0.02779, total_loss: 1.559
training 2193 (epoch 4): tem_loss: 1.093, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02484, consistency_loss_ema: 0.02697, total_loss: 1.561
training 2203 (epoch 4): tem_loss: 1.087, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02464, consistency_loss_ema: 0.02694, total_loss: 1.550
training 2213 (epoch 4): tem_loss: 1.089, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.02451, consistency_loss_ema: 0.02583, total_loss: 1.556
training 2223 (epoch 4): tem_loss: 1.083, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02438, consistency_loss_ema: 0.02657, total_loss: 1.548
training 2233 (epoch 4): tem_loss: 1.079, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02459, consistency_loss_ema: 0.02581, total_loss: 1.537
training 2243 (epoch 4): tem_loss: 1.081, pem class_loss: 0.300, pem reg_loss: 0.016, consistency_loss: 0.02456, consistency_loss_ema: 0.02620, total_loss: 1.539
training 2253 (epoch 4): tem_loss: 1.081, pem class_loss: 0.298, pem reg_loss: 0.016, consistency_loss: 0.02466, consistency_loss_ema: 0.02605, total_loss: 1.535
training 2263 (epoch 4): tem_loss: 1.079, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02437, consistency_loss_ema: 0.02588, total_loss: 1.529
training 2273 (epoch 4): tem_loss: 1.085, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02430, consistency_loss_ema: 0.02566, total_loss: 1.536
training 2283 (epoch 4): tem_loss: 1.084, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02444, consistency_loss_ema: 0.02557, total_loss: 1.539
training 2293 (epoch 4): tem_loss: 1.085, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02485, consistency_loss_ema: 0.02645, total_loss: 1.540
training 2303 (epoch 4): tem_loss: 1.086, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02510, consistency_loss_ema: 0.02658, total_loss: 1.542
training 2313 (epoch 4): tem_loss: 1.088, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02664, total_loss: 1.545
training 2323 (epoch 4): tem_loss: 1.088, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.02500, consistency_loss_ema: 0.02664, total_loss: 1.545
training 2333 (epoch 4): tem_loss: 1.090, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02489, consistency_loss_ema: 0.02642, total_loss: 1.548
training 2343 (epoch 4): tem_loss: 1.091, pem class_loss: 0.303, pem reg_loss: 0.016, consistency_loss: 0.02476, consistency_loss_ema: 0.02626, total_loss: 1.550
training 2353 (epoch 4): tem_loss: 1.093, pem class_loss: 0.304, pem reg_loss: 0.016, consistency_loss: 0.02473, consistency_loss_ema: 0.02614, total_loss: 1.553
training 2363 (epoch 4): tem_loss: 1.093, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02465, consistency_loss_ema: 0.02596, total_loss: 1.554
training 2373 (epoch 4): tem_loss: 1.095, pem class_loss: 0.306, pem reg_loss: 0.016, consistency_loss: 0.02471, consistency_loss_ema: 0.02599, total_loss: 1.556
training 2383 (epoch 4): tem_loss: 1.095, pem class_loss: 0.305, pem reg_loss: 0.016, consistency_loss: 0.02461, consistency_loss_ema: 0.02589, total_loss: 1.557
training 2393 (epoch 4): tem_loss: 1.098, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02452, consistency_loss_ema: 0.02587, total_loss: 1.561
training 2403 (epoch 4): tem_loss: 1.099, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02441, consistency_loss_ema: 0.02578, total_loss: 1.561
training 2413 (epoch 4): tem_loss: 1.098, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02452, consistency_loss_ema: 0.02576, total_loss: 1.561
training 2423 (epoch 4): tem_loss: 1.099, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02443, consistency_loss_ema: 0.02566, total_loss: 1.561
training 2433 (epoch 4): tem_loss: 1.100, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02436, consistency_loss_ema: 0.02566, total_loss: 1.563
training 2443 (epoch 4): tem_loss: 1.101, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02433, consistency_loss_ema: 0.02571, total_loss: 1.564
training 2453 (epoch 4): tem_loss: 1.102, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02436, consistency_loss_ema: 0.02577, total_loss: 1.565
training 2463 (epoch 4): tem_loss: 1.102, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02432, consistency_loss_ema: 0.02575, total_loss: 1.565
training 2473 (epoch 4): tem_loss: 1.101, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02426, consistency_loss_ema: 0.02565, total_loss: 1.566
training 2483 (epoch 4): tem_loss: 1.100, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02423, consistency_loss_ema: 0.02567, total_loss: 1.563
training 2493 (epoch 4): tem_loss: 1.100, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02429, consistency_loss_ema: 0.02564, total_loss: 1.562
training 2503 (epoch 4): tem_loss: 1.101, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02428, consistency_loss_ema: 0.02557, total_loss: 1.563
training 2513 (epoch 4): tem_loss: 1.101, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02424, consistency_loss_ema: 0.02550, total_loss: 1.563
training 2523 (epoch 4): tem_loss: 1.103, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02421, consistency_loss_ema: 0.02547, total_loss: 1.564
training 2533 (epoch 4): tem_loss: 1.103, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02419, consistency_loss_ema: 0.02541, total_loss: 1.564
training 2543 (epoch 4): tem_loss: 1.102, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02415, consistency_loss_ema: 0.02530, total_loss: 1.563
training 2553 (epoch 4): tem_loss: 1.102, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02412, consistency_loss_ema: 0.02524, total_loss: 1.561
training 2563 (epoch 4): tem_loss: 1.102, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02415, consistency_loss_ema: 0.02522, total_loss: 1.561
training 2573 (epoch 4): tem_loss: 1.102, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.02412, consistency_loss_ema: 0.02519, total_loss: 1.561
training 2583 (epoch 4): tem_loss: 1.103, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02405, consistency_loss_ema: 0.02512, total_loss: 1.563
training 2593 (epoch 4): tem_loss: 1.103, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02398, consistency_loss_ema: 0.02495, total_loss: 1.562
training 2603 (epoch 4): tem_loss: 1.103, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02394, consistency_loss_ema: 0.02491, total_loss: 1.564
training 2613 (epoch 4): tem_loss: 1.104, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02390, consistency_loss_ema: 0.02488, total_loss: 1.564
training 2623 (epoch 4): tem_loss: 1.105, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02384, consistency_loss_ema: 0.02483, total_loss: 1.565
training 2633 (epoch 4): tem_loss: 1.106, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02381, consistency_loss_ema: 0.02486, total_loss: 1.567
training 2643 (epoch 4): tem_loss: 1.105, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02378, consistency_loss_ema: 0.02487, total_loss: 1.566
training 2653 (epoch 4): tem_loss: 1.105, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02382, consistency_loss_ema: 0.02494, total_loss: 1.566
training 2663 (epoch 4): tem_loss: 1.105, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02379, consistency_loss_ema: 0.02494, total_loss: 1.566
training 2673 (epoch 4): tem_loss: 1.106, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02376, consistency_loss_ema: 0.02487, total_loss: 1.567
training 2683 (epoch 4): tem_loss: 1.106, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02371, consistency_loss_ema: 0.02485, total_loss: 1.567
training 2693 (epoch 4): tem_loss: 1.107, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02368, consistency_loss_ema: 0.02490, total_loss: 1.567
training 2703 (epoch 4): tem_loss: 1.106, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.02361, consistency_loss_ema: 0.02489, total_loss: 1.566
training 2713 (epoch 4): tem_loss: 1.106, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.02355, consistency_loss_ema: 0.02480, total_loss: 1.567
[94mBMN training loss(epoch 4): tem_loss: 1.106, pem class_loss: 0.307, pem reg_loss: 0.015, total_loss: 1.567[0m
[94mBMN val loss(epoch 4): tem_loss: 1.144, pem class_loss: 0.323, pem reg_loss: 0.016, total_loss: 1.626[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.144, pem class_loss: 0.318, pem reg_loss: 0.016, total_loss: 1.618[0m
use Semi !!!
training 2716 (epoch 5): tem_loss: 1.002, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02492, consistency_loss_ema: 0.03092, total_loss: 1.420
training 2726 (epoch 5): tem_loss: 1.120, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.02571, consistency_loss_ema: 0.03180, total_loss: 1.601
training 2736 (epoch 5): tem_loss: 1.121, pem class_loss: 0.312, pem reg_loss: 0.015, consistency_loss: 0.02515, consistency_loss_ema: 0.02736, total_loss: 1.587
training 2746 (epoch 5): tem_loss: 1.114, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02542, consistency_loss_ema: 0.02672, total_loss: 1.577
training 2756 (epoch 5): tem_loss: 1.122, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.02571, consistency_loss_ema: 0.02678, total_loss: 1.588
training 2766 (epoch 5): tem_loss: 1.114, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.02545, consistency_loss_ema: 0.02677, total_loss: 1.580
training 2776 (epoch 5): tem_loss: 1.106, pem class_loss: 0.302, pem reg_loss: 0.016, consistency_loss: 0.02570, consistency_loss_ema: 0.02754, total_loss: 1.562
training 2786 (epoch 5): tem_loss: 1.103, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02542, consistency_loss_ema: 0.02721, total_loss: 1.552
training 2796 (epoch 5): tem_loss: 1.109, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02543, consistency_loss_ema: 0.02731, total_loss: 1.562
training 2806 (epoch 5): tem_loss: 1.101, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02572, consistency_loss_ema: 0.02718, total_loss: 1.544
training 2816 (epoch 5): tem_loss: 1.102, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02581, consistency_loss_ema: 0.02743, total_loss: 1.546
training 2826 (epoch 5): tem_loss: 1.102, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02575, consistency_loss_ema: 0.02719, total_loss: 1.546
training 2836 (epoch 5): tem_loss: 1.100, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02586, consistency_loss_ema: 0.02702, total_loss: 1.542
training 2846 (epoch 5): tem_loss: 1.102, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02583, consistency_loss_ema: 0.02707, total_loss: 1.544
training 2856 (epoch 5): tem_loss: 1.102, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02590, consistency_loss_ema: 0.02702, total_loss: 1.544
training 2866 (epoch 5): tem_loss: 1.100, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02588, consistency_loss_ema: 0.02687, total_loss: 1.543
training 2876 (epoch 5): tem_loss: 1.104, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02583, consistency_loss_ema: 0.02706, total_loss: 1.549
training 2886 (epoch 5): tem_loss: 1.105, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02580, consistency_loss_ema: 0.02709, total_loss: 1.549
training 2896 (epoch 5): tem_loss: 1.105, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02585, consistency_loss_ema: 0.02717, total_loss: 1.550
training 2906 (epoch 5): tem_loss: 1.106, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02587, consistency_loss_ema: 0.02718, total_loss: 1.552
training 2916 (epoch 5): tem_loss: 1.107, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02580, consistency_loss_ema: 0.02720, total_loss: 1.552
training 2926 (epoch 5): tem_loss: 1.106, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02589, consistency_loss_ema: 0.02732, total_loss: 1.551
training 2936 (epoch 5): tem_loss: 1.105, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02589, consistency_loss_ema: 0.02731, total_loss: 1.549
training 2946 (epoch 5): tem_loss: 1.106, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02582, consistency_loss_ema: 0.02730, total_loss: 1.549
training 2956 (epoch 5): tem_loss: 1.106, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02568, consistency_loss_ema: 0.02731, total_loss: 1.550
training 2966 (epoch 5): tem_loss: 1.107, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02563, consistency_loss_ema: 0.02722, total_loss: 1.551
training 2976 (epoch 5): tem_loss: 1.106, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02574, consistency_loss_ema: 0.02748, total_loss: 1.549
training 2986 (epoch 5): tem_loss: 1.107, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02578, consistency_loss_ema: 0.02763, total_loss: 1.551
training 2996 (epoch 5): tem_loss: 1.107, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02578, consistency_loss_ema: 0.02769, total_loss: 1.553
training 3006 (epoch 5): tem_loss: 1.108, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.02576, consistency_loss_ema: 0.02766, total_loss: 1.553
training 3016 (epoch 5): tem_loss: 1.109, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02570, consistency_loss_ema: 0.02749, total_loss: 1.557
training 3026 (epoch 5): tem_loss: 1.109, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02563, consistency_loss_ema: 0.02742, total_loss: 1.556
training 3036 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02567, consistency_loss_ema: 0.02740, total_loss: 1.559
training 3046 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02562, consistency_loss_ema: 0.02736, total_loss: 1.558
training 3056 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02560, consistency_loss_ema: 0.02731, total_loss: 1.558
training 3066 (epoch 5): tem_loss: 1.109, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02566, consistency_loss_ema: 0.02726, total_loss: 1.559
training 3076 (epoch 5): tem_loss: 1.109, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02561, consistency_loss_ema: 0.02730, total_loss: 1.558
training 3086 (epoch 5): tem_loss: 1.109, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02557, consistency_loss_ema: 0.02724, total_loss: 1.557
training 3096 (epoch 5): tem_loss: 1.109, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02558, consistency_loss_ema: 0.02723, total_loss: 1.556
training 3106 (epoch 5): tem_loss: 1.109, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02555, consistency_loss_ema: 0.02719, total_loss: 1.555
training 3116 (epoch 5): tem_loss: 1.109, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02552, consistency_loss_ema: 0.02720, total_loss: 1.555
training 3126 (epoch 5): tem_loss: 1.110, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02552, consistency_loss_ema: 0.02714, total_loss: 1.557
training 3136 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02549, consistency_loss_ema: 0.02710, total_loss: 1.558
training 3146 (epoch 5): tem_loss: 1.111, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02548, consistency_loss_ema: 0.02704, total_loss: 1.559
training 3156 (epoch 5): tem_loss: 1.111, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02548, consistency_loss_ema: 0.02700, total_loss: 1.560
training 3166 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02552, consistency_loss_ema: 0.02693, total_loss: 1.559
training 3176 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02548, consistency_loss_ema: 0.02690, total_loss: 1.559
training 3186 (epoch 5): tem_loss: 1.110, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02545, consistency_loss_ema: 0.02685, total_loss: 1.559
training 3196 (epoch 5): tem_loss: 1.110, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02537, consistency_loss_ema: 0.02674, total_loss: 1.559
training 3206 (epoch 5): tem_loss: 1.109, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02538, consistency_loss_ema: 0.02669, total_loss: 1.559
training 3216 (epoch 5): tem_loss: 1.110, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02537, consistency_loss_ema: 0.02677, total_loss: 1.561
training 3226 (epoch 5): tem_loss: 1.110, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02534, consistency_loss_ema: 0.02675, total_loss: 1.561
training 3236 (epoch 5): tem_loss: 1.110, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.02532, consistency_loss_ema: 0.02670, total_loss: 1.560
training 3246 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02530, consistency_loss_ema: 0.02669, total_loss: 1.559
training 3256 (epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.02526, consistency_loss_ema: 0.02665, total_loss: 1.559
[94mBMN training loss(epoch 5): tem_loss: 1.110, pem class_loss: 0.300, pem reg_loss: 0.015, total_loss: 1.559[0m
[94mBMN val loss(epoch 5): tem_loss: 1.155, pem class_loss: 0.321, pem reg_loss: 0.016, total_loss: 1.633[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.150, pem class_loss: 0.317, pem reg_loss: 0.015, total_loss: 1.620[0m
use Semi !!!
training 3259 (epoch 6): tem_loss: 1.259, pem class_loss: 0.319, pem reg_loss: 0.018, consistency_loss: 0.02640, consistency_loss_ema: 0.02771, total_loss: 1.759
training 3269 (epoch 6): tem_loss: 1.161, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.02618, consistency_loss_ema: 0.02332, total_loss: 1.627
training 3279 (epoch 6): tem_loss: 1.147, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02467, consistency_loss_ema: 0.02552, total_loss: 1.601
training 3289 (epoch 6): tem_loss: 1.141, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02462, consistency_loss_ema: 0.02561, total_loss: 1.593
training 3299 (epoch 6): tem_loss: 1.142, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02417, consistency_loss_ema: 0.02528, total_loss: 1.583
training 3309 (epoch 6): tem_loss: 1.135, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.02441, consistency_loss_ema: 0.02517, total_loss: 1.580
training 3319 (epoch 6): tem_loss: 1.130, pem class_loss: 0.297, pem reg_loss: 0.014, consistency_loss: 0.02425, consistency_loss_ema: 0.02486, total_loss: 1.571
training 3329 (epoch 6): tem_loss: 1.125, pem class_loss: 0.295, pem reg_loss: 0.014, consistency_loss: 0.02433, consistency_loss_ema: 0.02490, total_loss: 1.564
training 3339 (epoch 6): tem_loss: 1.124, pem class_loss: 0.297, pem reg_loss: 0.014, consistency_loss: 0.02437, consistency_loss_ema: 0.02532, total_loss: 1.565
training 3349 (epoch 6): tem_loss: 1.120, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.02428, consistency_loss_ema: 0.02501, total_loss: 1.562
training 3359 (epoch 6): tem_loss: 1.114, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02434, consistency_loss_ema: 0.02502, total_loss: 1.556
training 3369 (epoch 6): tem_loss: 1.111, pem class_loss: 0.295, pem reg_loss: 0.014, consistency_loss: 0.02477, consistency_loss_ema: 0.02551, total_loss: 1.550
training 3379 (epoch 6): tem_loss: 1.108, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02478, consistency_loss_ema: 0.02563, total_loss: 1.544
training 3389 (epoch 6): tem_loss: 1.105, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02490, consistency_loss_ema: 0.02584, total_loss: 1.542
training 3399 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02514, consistency_loss_ema: 0.02599, total_loss: 1.546
training 3409 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.014, consistency_loss: 0.02504, consistency_loss_ema: 0.02595, total_loss: 1.545
training 3419 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.014, consistency_loss: 0.02505, consistency_loss_ema: 0.02610, total_loss: 1.545
training 3429 (epoch 6): tem_loss: 1.109, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02489, consistency_loss_ema: 0.02587, total_loss: 1.550
training 3439 (epoch 6): tem_loss: 1.107, pem class_loss: 0.294, pem reg_loss: 0.014, consistency_loss: 0.02493, consistency_loss_ema: 0.02601, total_loss: 1.546
training 3449 (epoch 6): tem_loss: 1.107, pem class_loss: 0.294, pem reg_loss: 0.014, consistency_loss: 0.02503, consistency_loss_ema: 0.02609, total_loss: 1.545
training 3459 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02503, consistency_loss_ema: 0.02604, total_loss: 1.545
training 3469 (epoch 6): tem_loss: 1.106, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02501, consistency_loss_ema: 0.02610, total_loss: 1.546
training 3479 (epoch 6): tem_loss: 1.104, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02500, consistency_loss_ema: 0.02631, total_loss: 1.542
training 3489 (epoch 6): tem_loss: 1.104, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02513, consistency_loss_ema: 0.02632, total_loss: 1.543
training 3499 (epoch 6): tem_loss: 1.104, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02526, consistency_loss_ema: 0.02651, total_loss: 1.540
training 3509 (epoch 6): tem_loss: 1.104, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02539, consistency_loss_ema: 0.02671, total_loss: 1.542
training 3519 (epoch 6): tem_loss: 1.105, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02562, consistency_loss_ema: 0.02701, total_loss: 1.542
training 3529 (epoch 6): tem_loss: 1.105, pem class_loss: 0.292, pem reg_loss: 0.015, consistency_loss: 0.02575, consistency_loss_ema: 0.02727, total_loss: 1.543
training 3539 (epoch 6): tem_loss: 1.104, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02590, consistency_loss_ema: 0.02747, total_loss: 1.542
training 3549 (epoch 6): tem_loss: 1.103, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02595, consistency_loss_ema: 0.02747, total_loss: 1.541
training 3559 (epoch 6): tem_loss: 1.103, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02589, consistency_loss_ema: 0.02753, total_loss: 1.540
training 3569 (epoch 6): tem_loss: 1.103, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02601, consistency_loss_ema: 0.02771, total_loss: 1.539
training 3579 (epoch 6): tem_loss: 1.104, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02599, consistency_loss_ema: 0.02758, total_loss: 1.540
training 3589 (epoch 6): tem_loss: 1.105, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02600, consistency_loss_ema: 0.02765, total_loss: 1.542
training 3599 (epoch 6): tem_loss: 1.105, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02593, consistency_loss_ema: 0.02776, total_loss: 1.543
training 3609 (epoch 6): tem_loss: 1.107, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02593, consistency_loss_ema: 0.02774, total_loss: 1.543
training 3619 (epoch 6): tem_loss: 1.106, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02603, consistency_loss_ema: 0.02786, total_loss: 1.543
training 3629 (epoch 6): tem_loss: 1.106, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02613, consistency_loss_ema: 0.02800, total_loss: 1.544
training 3639 (epoch 6): tem_loss: 1.106, pem class_loss: 0.293, pem reg_loss: 0.015, consistency_loss: 0.02621, consistency_loss_ema: 0.02814, total_loss: 1.545
training 3649 (epoch 6): tem_loss: 1.106, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02625, consistency_loss_ema: 0.02809, total_loss: 1.544
training 3659 (epoch 6): tem_loss: 1.106, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02626, consistency_loss_ema: 0.02801, total_loss: 1.543
training 3669 (epoch 6): tem_loss: 1.105, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02632, consistency_loss_ema: 0.02811, total_loss: 1.542
training 3679 (epoch 6): tem_loss: 1.105, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02637, consistency_loss_ema: 0.02825, total_loss: 1.543
training 3689 (epoch 6): tem_loss: 1.105, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.02637, consistency_loss_ema: 0.02818, total_loss: 1.542
training 3699 (epoch 6): tem_loss: 1.105, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02636, consistency_loss_ema: 0.02813, total_loss: 1.544
training 3709 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.014, consistency_loss: 0.02634, consistency_loss_ema: 0.02806, total_loss: 1.544
training 3719 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02640, consistency_loss_ema: 0.02818, total_loss: 1.546
training 3729 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02640, consistency_loss_ema: 0.02826, total_loss: 1.546
training 3739 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02638, consistency_loss_ema: 0.02826, total_loss: 1.546
training 3749 (epoch 6): tem_loss: 1.107, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02637, consistency_loss_ema: 0.02828, total_loss: 1.546
training 3759 (epoch 6): tem_loss: 1.106, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02635, consistency_loss_ema: 0.02825, total_loss: 1.547
training 3769 (epoch 6): tem_loss: 1.107, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02637, consistency_loss_ema: 0.02818, total_loss: 1.547
training 3779 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02636, consistency_loss_ema: 0.02816, total_loss: 1.546
training 3789 (epoch 6): tem_loss: 1.106, pem class_loss: 0.294, pem reg_loss: 0.015, consistency_loss: 0.02633, consistency_loss_ema: 0.02811, total_loss: 1.546
training 3799 (epoch 6): tem_loss: 1.107, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.02630, consistency_loss_ema: 0.02808, total_loss: 1.548
[94mBMN training loss(epoch 6): tem_loss: 1.107, pem class_loss: 0.295, pem reg_loss: 0.015, total_loss: 1.548[0m
[94mBMN val loss(epoch 6): tem_loss: 1.155, pem class_loss: 0.320, pem reg_loss: 0.015, total_loss: 1.629[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.152, pem class_loss: 0.317, pem reg_loss: 0.015, total_loss: 1.621[0m
use Semi !!!
training 3802 (epoch 7): tem_loss: 1.107, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02566, consistency_loss_ema: 0.02225, total_loss: 1.536
training 3812 (epoch 7): tem_loss: 1.115, pem class_loss: 0.296, pem reg_loss: 0.016, consistency_loss: 0.02535, consistency_loss_ema: 0.02391, total_loss: 1.567
training 3822 (epoch 7): tem_loss: 1.113, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.02478, consistency_loss_ema: 0.02318, total_loss: 1.559
training 3832 (epoch 7): tem_loss: 1.112, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02387, consistency_loss_ema: 0.02336, total_loss: 1.549
training 3842 (epoch 7): tem_loss: 1.106, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.02263, consistency_loss_ema: 0.02213, total_loss: 1.528
training 3852 (epoch 7): tem_loss: 1.108, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02186, consistency_loss_ema: 0.02230, total_loss: 1.526
training 3862 (epoch 7): tem_loss: 1.106, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.02117, consistency_loss_ema: 0.02167, total_loss: 1.526
training 3872 (epoch 7): tem_loss: 1.104, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.02051, consistency_loss_ema: 0.02175, total_loss: 1.527
training 3882 (epoch 7): tem_loss: 1.106, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.02007, consistency_loss_ema: 0.02126, total_loss: 1.532
training 3892 (epoch 7): tem_loss: 1.108, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01968, consistency_loss_ema: 0.02075, total_loss: 1.531
training 3902 (epoch 7): tem_loss: 1.107, pem class_loss: 0.284, pem reg_loss: 0.014, consistency_loss: 0.01944, consistency_loss_ema: 0.02068, total_loss: 1.529
training 3912 (epoch 7): tem_loss: 1.102, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01924, consistency_loss_ema: 0.02034, total_loss: 1.519
training 3922 (epoch 7): tem_loss: 1.098, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01909, consistency_loss_ema: 0.02023, total_loss: 1.512
training 3932 (epoch 7): tem_loss: 1.097, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01902, consistency_loss_ema: 0.02017, total_loss: 1.514
training 3942 (epoch 7): tem_loss: 1.095, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.01873, consistency_loss_ema: 0.01987, total_loss: 1.510
training 3952 (epoch 7): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01870, consistency_loss_ema: 0.01981, total_loss: 1.504
training 3962 (epoch 7): tem_loss: 1.092, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01868, consistency_loss_ema: 0.01969, total_loss: 1.506
training 3972 (epoch 7): tem_loss: 1.093, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01851, consistency_loss_ema: 0.01971, total_loss: 1.508
training 3982 (epoch 7): tem_loss: 1.092, pem class_loss: 0.281, pem reg_loss: 0.013, consistency_loss: 0.01846, consistency_loss_ema: 0.01946, total_loss: 1.507
training 3992 (epoch 7): tem_loss: 1.092, pem class_loss: 0.281, pem reg_loss: 0.013, consistency_loss: 0.01834, consistency_loss_ema: 0.01948, total_loss: 1.508
training 4002 (epoch 7): tem_loss: 1.094, pem class_loss: 0.281, pem reg_loss: 0.013, consistency_loss: 0.01832, consistency_loss_ema: 0.01938, total_loss: 1.510
training 4012 (epoch 7): tem_loss: 1.094, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01824, consistency_loss_ema: 0.01927, total_loss: 1.511
training 4022 (epoch 7): tem_loss: 1.094, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01817, consistency_loss_ema: 0.01928, total_loss: 1.513
training 4032 (epoch 7): tem_loss: 1.095, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01813, consistency_loss_ema: 0.01928, total_loss: 1.514
training 4042 (epoch 7): tem_loss: 1.095, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01800, consistency_loss_ema: 0.01924, total_loss: 1.512
training 4052 (epoch 7): tem_loss: 1.093, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01794, consistency_loss_ema: 0.01936, total_loss: 1.512
training 4062 (epoch 7): tem_loss: 1.094, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01792, consistency_loss_ema: 0.01934, total_loss: 1.512
training 4072 (epoch 7): tem_loss: 1.094, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.01788, consistency_loss_ema: 0.01941, total_loss: 1.512
training 4082 (epoch 7): tem_loss: 1.095, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01784, consistency_loss_ema: 0.01937, total_loss: 1.514
training 4092 (epoch 7): tem_loss: 1.096, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01780, consistency_loss_ema: 0.01932, total_loss: 1.514
training 4102 (epoch 7): tem_loss: 1.096, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01779, consistency_loss_ema: 0.01933, total_loss: 1.516
training 4112 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01778, consistency_loss_ema: 0.01929, total_loss: 1.516
training 4122 (epoch 7): tem_loss: 1.098, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01788, consistency_loss_ema: 0.01920, total_loss: 1.519
training 4132 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01782, consistency_loss_ema: 0.01915, total_loss: 1.518
training 4142 (epoch 7): tem_loss: 1.096, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01780, consistency_loss_ema: 0.01914, total_loss: 1.516
training 4152 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01777, consistency_loss_ema: 0.01913, total_loss: 1.517
training 4162 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01778, consistency_loss_ema: 0.01912, total_loss: 1.517
training 4172 (epoch 7): tem_loss: 1.098, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01774, consistency_loss_ema: 0.01910, total_loss: 1.518
training 4182 (epoch 7): tem_loss: 1.098, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01774, consistency_loss_ema: 0.01905, total_loss: 1.517
training 4192 (epoch 7): tem_loss: 1.098, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01772, consistency_loss_ema: 0.01917, total_loss: 1.518
training 4202 (epoch 7): tem_loss: 1.098, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01772, consistency_loss_ema: 0.01915, total_loss: 1.517
training 4212 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01771, consistency_loss_ema: 0.01912, total_loss: 1.517
training 4222 (epoch 7): tem_loss: 1.098, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01772, consistency_loss_ema: 0.01909, total_loss: 1.517
training 4232 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01770, consistency_loss_ema: 0.01911, total_loss: 1.517
training 4242 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01772, consistency_loss_ema: 0.01923, total_loss: 1.516
training 4252 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01779, consistency_loss_ema: 0.01921, total_loss: 1.516
training 4262 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01780, consistency_loss_ema: 0.01923, total_loss: 1.518
training 4272 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01780, consistency_loss_ema: 0.01930, total_loss: 1.518
training 4282 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01775, consistency_loss_ema: 0.01923, total_loss: 1.519
training 4292 (epoch 7): tem_loss: 1.098, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01774, consistency_loss_ema: 0.01924, total_loss: 1.519
training 4302 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01773, consistency_loss_ema: 0.01921, total_loss: 1.519
training 4312 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01768, consistency_loss_ema: 0.01919, total_loss: 1.518
training 4322 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01766, consistency_loss_ema: 0.01928, total_loss: 1.518
training 4332 (epoch 7): tem_loss: 1.097, pem class_loss: 0.283, pem reg_loss: 0.014, consistency_loss: 0.01765, consistency_loss_ema: 0.01926, total_loss: 1.517
training 4342 (epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.01764, consistency_loss_ema: 0.01921, total_loss: 1.517
[94mBMN training loss(epoch 7): tem_loss: 1.097, pem class_loss: 0.282, pem reg_loss: 0.014, total_loss: 1.516[0m
[94mBMN val loss(epoch 7): tem_loss: 1.150, pem class_loss: 0.320, pem reg_loss: 0.015, total_loss: 1.621[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.151, pem class_loss: 0.318, pem reg_loss: 0.015, total_loss: 1.620[0m
use Semi !!!
training 4345 (epoch 8): tem_loss: 1.067, pem class_loss: 0.333, pem reg_loss: 0.014, consistency_loss: 0.01611, consistency_loss_ema: 0.01608, total_loss: 1.538
training 4355 (epoch 8): tem_loss: 1.027, pem class_loss: 0.244, pem reg_loss: 0.012, consistency_loss: 0.01761, consistency_loss_ema: 0.02002, total_loss: 1.387
training 4365 (epoch 8): tem_loss: 1.051, pem class_loss: 0.251, pem reg_loss: 0.012, consistency_loss: 0.01834, consistency_loss_ema: 0.01926, total_loss: 1.422
training 4375 (epoch 8): tem_loss: 1.052, pem class_loss: 0.246, pem reg_loss: 0.012, consistency_loss: 0.01814, consistency_loss_ema: 0.01983, total_loss: 1.418
training 4385 (epoch 8): tem_loss: 1.068, pem class_loss: 0.259, pem reg_loss: 0.013, consistency_loss: 0.01831, consistency_loss_ema: 0.01989, total_loss: 1.454
training 4395 (epoch 8): tem_loss: 1.076, pem class_loss: 0.266, pem reg_loss: 0.013, consistency_loss: 0.01804, consistency_loss_ema: 0.01977, total_loss: 1.471
training 4405 (epoch 8): tem_loss: 1.083, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01793, consistency_loss_ema: 0.01950, total_loss: 1.491
training 4415 (epoch 8): tem_loss: 1.083, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01793, consistency_loss_ema: 0.01940, total_loss: 1.488
training 4425 (epoch 8): tem_loss: 1.086, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01776, consistency_loss_ema: 0.01907, total_loss: 1.498
training 4435 (epoch 8): tem_loss: 1.092, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01782, consistency_loss_ema: 0.01916, total_loss: 1.504
training 4445 (epoch 8): tem_loss: 1.088, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01774, consistency_loss_ema: 0.01925, total_loss: 1.501
training 4455 (epoch 8): tem_loss: 1.091, pem class_loss: 0.281, pem reg_loss: 0.013, consistency_loss: 0.01775, consistency_loss_ema: 0.01911, total_loss: 1.504
training 4465 (epoch 8): tem_loss: 1.090, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01772, consistency_loss_ema: 0.01912, total_loss: 1.501
training 4475 (epoch 8): tem_loss: 1.091, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01771, consistency_loss_ema: 0.01926, total_loss: 1.504
training 4485 (epoch 8): tem_loss: 1.087, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01780, consistency_loss_ema: 0.01911, total_loss: 1.497
training 4495 (epoch 8): tem_loss: 1.086, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01774, consistency_loss_ema: 0.01914, total_loss: 1.494
training 4505 (epoch 8): tem_loss: 1.089, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01779, consistency_loss_ema: 0.01905, total_loss: 1.498
training 4515 (epoch 8): tem_loss: 1.088, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01777, consistency_loss_ema: 0.01903, total_loss: 1.499
training 4525 (epoch 8): tem_loss: 1.089, pem class_loss: 0.281, pem reg_loss: 0.013, consistency_loss: 0.01783, consistency_loss_ema: 0.01903, total_loss: 1.504
training 4535 (epoch 8): tem_loss: 1.090, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01781, consistency_loss_ema: 0.01916, total_loss: 1.503
training 4545 (epoch 8): tem_loss: 1.091, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01786, consistency_loss_ema: 0.01908, total_loss: 1.504
training 4555 (epoch 8): tem_loss: 1.093, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01784, consistency_loss_ema: 0.01905, total_loss: 1.507
training 4565 (epoch 8): tem_loss: 1.092, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01782, consistency_loss_ema: 0.01900, total_loss: 1.507
training 4575 (epoch 8): tem_loss: 1.092, pem class_loss: 0.281, pem reg_loss: 0.013, consistency_loss: 0.01779, consistency_loss_ema: 0.01884, total_loss: 1.508
training 4585 (epoch 8): tem_loss: 1.091, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01788, consistency_loss_ema: 0.01886, total_loss: 1.505
training 4595 (epoch 8): tem_loss: 1.092, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01789, consistency_loss_ema: 0.01894, total_loss: 1.505
training 4605 (epoch 8): tem_loss: 1.091, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01792, consistency_loss_ema: 0.01897, total_loss: 1.505
training 4615 (epoch 8): tem_loss: 1.093, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01796, consistency_loss_ema: 0.01908, total_loss: 1.507
training 4625 (epoch 8): tem_loss: 1.094, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.01800, consistency_loss_ema: 0.01905, total_loss: 1.508
training 4635 (epoch 8): tem_loss: 1.093, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01797, consistency_loss_ema: 0.01910, total_loss: 1.508
training 4645 (epoch 8): tem_loss: 1.092, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01797, consistency_loss_ema: 0.01905, total_loss: 1.505
training 4655 (epoch 8): tem_loss: 1.093, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01803, consistency_loss_ema: 0.01922, total_loss: 1.506
training 4665 (epoch 8): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01808, consistency_loss_ema: 0.01927, total_loss: 1.504
training 4675 (epoch 8): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01813, consistency_loss_ema: 0.01931, total_loss: 1.504
training 4685 (epoch 8): tem_loss: 1.091, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01810, consistency_loss_ema: 0.01934, total_loss: 1.503
training 4695 (epoch 8): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01816, consistency_loss_ema: 0.01934, total_loss: 1.504
training 4705 (epoch 8): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01819, consistency_loss_ema: 0.01930, total_loss: 1.503
training 4715 (epoch 8): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01819, consistency_loss_ema: 0.01934, total_loss: 1.503
training 4725 (epoch 8): tem_loss: 1.091, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01821, consistency_loss_ema: 0.01936, total_loss: 1.504
training 4735 (epoch 8): tem_loss: 1.090, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01819, consistency_loss_ema: 0.01932, total_loss: 1.503
training 4745 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01816, consistency_loss_ema: 0.01932, total_loss: 1.501
training 4755 (epoch 8): tem_loss: 1.091, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01816, consistency_loss_ema: 0.01933, total_loss: 1.502
training 4765 (epoch 8): tem_loss: 1.090, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01817, consistency_loss_ema: 0.01935, total_loss: 1.502
training 4775 (epoch 8): tem_loss: 1.091, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01815, consistency_loss_ema: 0.01937, total_loss: 1.503
training 4785 (epoch 8): tem_loss: 1.092, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01816, consistency_loss_ema: 0.01940, total_loss: 1.504
training 4795 (epoch 8): tem_loss: 1.092, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01817, consistency_loss_ema: 0.01944, total_loss: 1.503
training 4805 (epoch 8): tem_loss: 1.091, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01817, consistency_loss_ema: 0.01956, total_loss: 1.502
training 4815 (epoch 8): tem_loss: 1.091, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01816, consistency_loss_ema: 0.01952, total_loss: 1.502
training 4825 (epoch 8): tem_loss: 1.092, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01814, consistency_loss_ema: 0.01951, total_loss: 1.502
training 4835 (epoch 8): tem_loss: 1.091, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01814, consistency_loss_ema: 0.01950, total_loss: 1.501
training 4845 (epoch 8): tem_loss: 1.091, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01819, consistency_loss_ema: 0.01943, total_loss: 1.502
training 4855 (epoch 8): tem_loss: 1.092, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01823, consistency_loss_ema: 0.01947, total_loss: 1.502
training 4865 (epoch 8): tem_loss: 1.092, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01824, consistency_loss_ema: 0.01947, total_loss: 1.502
training 4875 (epoch 8): tem_loss: 1.091, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01824, consistency_loss_ema: 0.01952, total_loss: 1.501
training 4885 (epoch 8): tem_loss: 1.091, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01828, consistency_loss_ema: 0.01954, total_loss: 1.502
[94mBMN training loss(epoch 8): tem_loss: 1.092, pem class_loss: 0.277, pem reg_loss: 0.013, total_loss: 1.503[0m
[94mBMN val loss(epoch 8): tem_loss: 1.148, pem class_loss: 0.322, pem reg_loss: 0.015, total_loss: 1.623[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.150, pem class_loss: 0.321, pem reg_loss: 0.015, total_loss: 1.622[0m
use Semi !!!
training 4888 (epoch 9): tem_loss: 1.123, pem class_loss: 0.283, pem reg_loss: 0.015, consistency_loss: 0.01679, consistency_loss_ema: 0.02046, total_loss: 1.552
training 4898 (epoch 9): tem_loss: 1.069, pem class_loss: 0.262, pem reg_loss: 0.013, consistency_loss: 0.01839, consistency_loss_ema: 0.02093, total_loss: 1.462
training 4908 (epoch 9): tem_loss: 1.078, pem class_loss: 0.285, pem reg_loss: 0.014, consistency_loss: 0.01960, consistency_loss_ema: 0.01984, total_loss: 1.503
training 4918 (epoch 9): tem_loss: 1.076, pem class_loss: 0.279, pem reg_loss: 0.013, consistency_loss: 0.01939, consistency_loss_ema: 0.02116, total_loss: 1.486
training 4928 (epoch 9): tem_loss: 1.082, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01941, consistency_loss_ema: 0.02057, total_loss: 1.490
training 4938 (epoch 9): tem_loss: 1.089, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.01937, consistency_loss_ema: 0.02041, total_loss: 1.501
training 4948 (epoch 9): tem_loss: 1.084, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01916, consistency_loss_ema: 0.02050, total_loss: 1.487
training 4958 (epoch 9): tem_loss: 1.082, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01913, consistency_loss_ema: 0.02101, total_loss: 1.484
training 4968 (epoch 9): tem_loss: 1.078, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01920, consistency_loss_ema: 0.02062, total_loss: 1.484
training 4978 (epoch 9): tem_loss: 1.079, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01935, consistency_loss_ema: 0.02088, total_loss: 1.483
training 4988 (epoch 9): tem_loss: 1.081, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02093, total_loss: 1.492
training 4998 (epoch 9): tem_loss: 1.084, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.01934, consistency_loss_ema: 0.02094, total_loss: 1.494
training 5008 (epoch 9): tem_loss: 1.083, pem class_loss: 0.277, pem reg_loss: 0.013, consistency_loss: 0.01931, consistency_loss_ema: 0.02094, total_loss: 1.495
training 5018 (epoch 9): tem_loss: 1.082, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02075, total_loss: 1.488
training 5028 (epoch 9): tem_loss: 1.080, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01927, consistency_loss_ema: 0.02093, total_loss: 1.484
training 5038 (epoch 9): tem_loss: 1.081, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01930, consistency_loss_ema: 0.02072, total_loss: 1.484
training 5048 (epoch 9): tem_loss: 1.080, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01927, consistency_loss_ema: 0.02078, total_loss: 1.485
training 5058 (epoch 9): tem_loss: 1.081, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01919, consistency_loss_ema: 0.02104, total_loss: 1.486
training 5068 (epoch 9): tem_loss: 1.081, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01917, consistency_loss_ema: 0.02092, total_loss: 1.486
training 5078 (epoch 9): tem_loss: 1.080, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01914, consistency_loss_ema: 0.02104, total_loss: 1.484
training 5088 (epoch 9): tem_loss: 1.082, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01927, consistency_loss_ema: 0.02097, total_loss: 1.485
training 5098 (epoch 9): tem_loss: 1.083, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01928, consistency_loss_ema: 0.02093, total_loss: 1.484
training 5108 (epoch 9): tem_loss: 1.083, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01927, consistency_loss_ema: 0.02104, total_loss: 1.484
training 5118 (epoch 9): tem_loss: 1.083, pem class_loss: 0.270, pem reg_loss: 0.013, consistency_loss: 0.01927, consistency_loss_ema: 0.02117, total_loss: 1.484
training 5128 (epoch 9): tem_loss: 1.083, pem class_loss: 0.271, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02112, total_loss: 1.484
training 5138 (epoch 9): tem_loss: 1.086, pem class_loss: 0.272, pem reg_loss: 0.013, consistency_loss: 0.01932, consistency_loss_ema: 0.02113, total_loss: 1.489
training 5148 (epoch 9): tem_loss: 1.087, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01929, consistency_loss_ema: 0.02116, total_loss: 1.491
training 5158 (epoch 9): tem_loss: 1.088, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02121, total_loss: 1.495
training 5168 (epoch 9): tem_loss: 1.088, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01923, consistency_loss_ema: 0.02118, total_loss: 1.494
training 5178 (epoch 9): tem_loss: 1.087, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02115, total_loss: 1.493
training 5188 (epoch 9): tem_loss: 1.087, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01930, consistency_loss_ema: 0.02115, total_loss: 1.494
training 5198 (epoch 9): tem_loss: 1.088, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01932, consistency_loss_ema: 0.02114, total_loss: 1.495
training 5208 (epoch 9): tem_loss: 1.089, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01931, consistency_loss_ema: 0.02111, total_loss: 1.495
training 5218 (epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01932, consistency_loss_ema: 0.02109, total_loss: 1.494
training 5228 (epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01931, consistency_loss_ema: 0.02113, total_loss: 1.494
training 5238 (epoch 9): tem_loss: 1.088, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01926, consistency_loss_ema: 0.02113, total_loss: 1.494
training 5248 (epoch 9): tem_loss: 1.088, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01927, consistency_loss_ema: 0.02122, total_loss: 1.496
training 5258 (epoch 9): tem_loss: 1.088, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01921, consistency_loss_ema: 0.02117, total_loss: 1.495
training 5268 (epoch 9): tem_loss: 1.089, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01923, consistency_loss_ema: 0.02116, total_loss: 1.498
training 5278 (epoch 9): tem_loss: 1.089, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01924, consistency_loss_ema: 0.02115, total_loss: 1.497
training 5288 (epoch 9): tem_loss: 1.089, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02119, total_loss: 1.498
training 5298 (epoch 9): tem_loss: 1.089, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02109, total_loss: 1.497
training 5308 (epoch 9): tem_loss: 1.090, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01926, consistency_loss_ema: 0.02116, total_loss: 1.498
training 5318 (epoch 9): tem_loss: 1.090, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02116, total_loss: 1.497
training 5328 (epoch 9): tem_loss: 1.090, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01925, consistency_loss_ema: 0.02115, total_loss: 1.498
training 5338 (epoch 9): tem_loss: 1.090, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01924, consistency_loss_ema: 0.02110, total_loss: 1.498
training 5348 (epoch 9): tem_loss: 1.091, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01921, consistency_loss_ema: 0.02109, total_loss: 1.498
training 5358 (epoch 9): tem_loss: 1.090, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01919, consistency_loss_ema: 0.02107, total_loss: 1.498
training 5368 (epoch 9): tem_loss: 1.090, pem class_loss: 0.275, pem reg_loss: 0.013, consistency_loss: 0.01920, consistency_loss_ema: 0.02100, total_loss: 1.498
training 5378 (epoch 9): tem_loss: 1.090, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01920, consistency_loss_ema: 0.02098, total_loss: 1.497
training 5388 (epoch 9): tem_loss: 1.090, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01922, consistency_loss_ema: 0.02106, total_loss: 1.497
training 5398 (epoch 9): tem_loss: 1.089, pem class_loss: 0.274, pem reg_loss: 0.013, consistency_loss: 0.01924, consistency_loss_ema: 0.02106, total_loss: 1.496
training 5408 (epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01923, consistency_loss_ema: 0.02110, total_loss: 1.495
training 5418 (epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01926, consistency_loss_ema: 0.02114, total_loss: 1.495
training 5428 (epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, consistency_loss: 0.01928, consistency_loss_ema: 0.02118, total_loss: 1.494
[94mBMN training loss(epoch 9): tem_loss: 1.088, pem class_loss: 0.273, pem reg_loss: 0.013, total_loss: 1.494[0m
[94mBMN val loss(epoch 9): tem_loss: 1.149, pem class_loss: 0.322, pem reg_loss: 0.015, total_loss: 1.623[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.149, pem class_loss: 0.322, pem reg_loss: 0.015, total_loss: 1.623[0m
unlabel percent:  0.1
eval student model !!
load : ./checkpoint/Semi-base-0.1-2/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472621
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.50316742081449%
AR@1 is 	 0.3369121075003428
AR@5 is 	 0.49356917592211713
AR@10 is 	 0.5701083230494995
AR@100 is 	 0.7536130536130536
load : ./checkpoint/Semi-base-0.1-2/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472619
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.5774852598382%
AR@1 is 	 0.3366515837104072
AR@5 is 	 0.49546140134375427
AR@10 is 	 0.5715891951186068
AR@100 is 	 0.7542575071986837
eval teacher model !!
load : ./checkpoint/Semi-base-0.1-2/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472623
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.52058137940492%
AR@1 is 	 0.336418483477307
AR@5 is 	 0.49474838886603595
AR@10 is 	 0.5709584533113945
AR@100 is 	 0.7540792540792541
load : ./checkpoint/Semi-base-0.1-2/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472618
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.16240230357877%
AR@1 is 	 0.33570547099958864
AR@5 is 	 0.49008638420403133
AR@10 is 	 0.564870423693953
AR@100 is 	 0.7508706979295214
#
train subset video numbers: 9649
validation subset video numbers: 4728
use 1.0 label for training!!!
training batchsize : 16
unlabel_training batchsize : 4
use Semi !!! use all label !!!
training 1 (epoch 0): tem_loss: 1.399, pem class_loss: 0.693, pem reg_loss: 0.039, consistency_loss: 0.00047, total_loss: 2.483
training 11 (epoch 0): tem_loss: 1.373, pem class_loss: 0.536, pem reg_loss: 0.034, consistency_loss: 0.00013, total_loss: 2.248
training 21 (epoch 0): tem_loss: 1.342, pem class_loss: 0.475, pem reg_loss: 0.030, consistency_loss: 0.00013, total_loss: 2.113
training 31 (epoch 0): tem_loss: 1.321, pem class_loss: 0.452, pem reg_loss: 0.028, consistency_loss: 0.00016, total_loss: 2.049
training 41 (epoch 0): tem_loss: 1.308, pem class_loss: 0.441, pem reg_loss: 0.027, consistency_loss: 0.00020, total_loss: 2.015
training 51 (epoch 0): tem_loss: 1.304, pem class_loss: 0.428, pem reg_loss: 0.026, consistency_loss: 0.00023, total_loss: 1.994
training 61 (epoch 0): tem_loss: 1.292, pem class_loss: 0.416, pem reg_loss: 0.025, consistency_loss: 0.00025, total_loss: 1.959
training 71 (epoch 0): tem_loss: 1.283, pem class_loss: 0.411, pem reg_loss: 0.025, consistency_loss: 0.00026, total_loss: 1.942
training 81 (epoch 0): tem_loss: 1.276, pem class_loss: 0.408, pem reg_loss: 0.024, consistency_loss: 0.00027, total_loss: 1.928
training 91 (epoch 0): tem_loss: 1.275, pem class_loss: 0.407, pem reg_loss: 0.024, consistency_loss: 0.00028, total_loss: 1.924
training 101 (epoch 0): tem_loss: 1.272, pem class_loss: 0.403, pem reg_loss: 0.024, consistency_loss: 0.00030, total_loss: 1.918
training 111 (epoch 0): tem_loss: 1.268, pem class_loss: 0.400, pem reg_loss: 0.024, consistency_loss: 0.00030, total_loss: 1.908
training 121 (epoch 0): tem_loss: 1.264, pem class_loss: 0.399, pem reg_loss: 0.024, consistency_loss: 0.00031, total_loss: 1.899
training 131 (epoch 0): tem_loss: 1.259, pem class_loss: 0.398, pem reg_loss: 0.024, consistency_loss: 0.00032, total_loss: 1.892
training 141 (epoch 0): tem_loss: 1.255, pem class_loss: 0.397, pem reg_loss: 0.023, consistency_loss: 0.00033, total_loss: 1.887
training 151 (epoch 0): tem_loss: 1.250, pem class_loss: 0.394, pem reg_loss: 0.023, consistency_loss: 0.00033, total_loss: 1.877
training 161 (epoch 0): tem_loss: 1.244, pem class_loss: 0.394, pem reg_loss: 0.023, consistency_loss: 0.00034, total_loss: 1.869
training 171 (epoch 0): tem_loss: 1.239, pem class_loss: 0.390, pem reg_loss: 0.023, consistency_loss: 0.00035, total_loss: 1.858
training 181 (epoch 0): tem_loss: 1.234, pem class_loss: 0.390, pem reg_loss: 0.023, consistency_loss: 0.00035, total_loss: 1.852
training 191 (epoch 0): tem_loss: 1.231, pem class_loss: 0.388, pem reg_loss: 0.023, consistency_loss: 0.00036, total_loss: 1.846
training 201 (epoch 0): tem_loss: 1.231, pem class_loss: 0.389, pem reg_loss: 0.023, consistency_loss: 0.00036, total_loss: 1.847
training 211 (epoch 0): tem_loss: 1.227, pem class_loss: 0.388, pem reg_loss: 0.023, consistency_loss: 0.00037, total_loss: 1.841
training 221 (epoch 0): tem_loss: 1.226, pem class_loss: 0.386, pem reg_loss: 0.022, consistency_loss: 0.00038, total_loss: 1.836
training 231 (epoch 0): tem_loss: 1.224, pem class_loss: 0.385, pem reg_loss: 0.022, consistency_loss: 0.00038, total_loss: 1.831
training 241 (epoch 0): tem_loss: 1.223, pem class_loss: 0.384, pem reg_loss: 0.022, consistency_loss: 0.00039, total_loss: 1.830
training 251 (epoch 0): tem_loss: 1.218, pem class_loss: 0.383, pem reg_loss: 0.022, consistency_loss: 0.00039, total_loss: 1.823
training 261 (epoch 0): tem_loss: 1.216, pem class_loss: 0.381, pem reg_loss: 0.022, consistency_loss: 0.00039, total_loss: 1.818
training 271 (epoch 0): tem_loss: 1.213, pem class_loss: 0.381, pem reg_loss: 0.022, consistency_loss: 0.00039, total_loss: 1.814
training 281 (epoch 0): tem_loss: 1.212, pem class_loss: 0.381, pem reg_loss: 0.022, consistency_loss: 0.00039, total_loss: 1.812
training 291 (epoch 0): tem_loss: 1.211, pem class_loss: 0.379, pem reg_loss: 0.022, consistency_loss: 0.00040, total_loss: 1.809
training 301 (epoch 0): tem_loss: 1.207, pem class_loss: 0.378, pem reg_loss: 0.022, consistency_loss: 0.00040, total_loss: 1.804
training 311 (epoch 0): tem_loss: 1.205, pem class_loss: 0.378, pem reg_loss: 0.022, consistency_loss: 0.00041, total_loss: 1.801
training 321 (epoch 0): tem_loss: 1.204, pem class_loss: 0.376, pem reg_loss: 0.022, consistency_loss: 0.00042, total_loss: 1.798
training 331 (epoch 0): tem_loss: 1.203, pem class_loss: 0.376, pem reg_loss: 0.022, consistency_loss: 0.00042, total_loss: 1.796
training 341 (epoch 0): tem_loss: 1.202, pem class_loss: 0.375, pem reg_loss: 0.022, consistency_loss: 0.00043, total_loss: 1.794
training 351 (epoch 0): tem_loss: 1.200, pem class_loss: 0.373, pem reg_loss: 0.022, consistency_loss: 0.00043, total_loss: 1.789
training 361 (epoch 0): tem_loss: 1.199, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.785
training 371 (epoch 0): tem_loss: 1.199, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.785
training 381 (epoch 0): tem_loss: 1.198, pem class_loss: 0.371, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.783
training 391 (epoch 0): tem_loss: 1.199, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.785
training 401 (epoch 0): tem_loss: 1.200, pem class_loss: 0.372, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.786
training 411 (epoch 0): tem_loss: 1.200, pem class_loss: 0.371, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.784
training 421 (epoch 0): tem_loss: 1.198, pem class_loss: 0.370, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.781
training 431 (epoch 0): tem_loss: 1.199, pem class_loss: 0.371, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.782
training 441 (epoch 0): tem_loss: 1.198, pem class_loss: 0.370, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.780
training 451 (epoch 0): tem_loss: 1.197, pem class_loss: 0.369, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.777
training 461 (epoch 0): tem_loss: 1.196, pem class_loss: 0.369, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.775
training 471 (epoch 0): tem_loss: 1.195, pem class_loss: 0.368, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.773
training 481 (epoch 0): tem_loss: 1.194, pem class_loss: 0.367, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.771
training 491 (epoch 0): tem_loss: 1.194, pem class_loss: 0.367, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.771
training 501 (epoch 0): tem_loss: 1.193, pem class_loss: 0.366, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.768
training 511 (epoch 0): tem_loss: 1.192, pem class_loss: 0.366, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.766
training 521 (epoch 0): tem_loss: 1.189, pem class_loss: 0.365, pem reg_loss: 0.021, consistency_loss: 0.00043, total_loss: 1.762
training 531 (epoch 0): tem_loss: 1.189, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.760
training 541 (epoch 0): tem_loss: 1.188, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.758
training 551 (epoch 0): tem_loss: 1.188, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.757
training 561 (epoch 0): tem_loss: 1.187, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.757
training 571 (epoch 0): tem_loss: 1.187, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.757
training 581 (epoch 0): tem_loss: 1.186, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.756
training 591 (epoch 0): tem_loss: 1.185, pem class_loss: 0.364, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.755
training 601 (epoch 0): tem_loss: 1.184, pem class_loss: 0.363, pem reg_loss: 0.021, consistency_loss: 0.00044, total_loss: 1.753
[94mBMN training loss(epoch 0): tem_loss: 1.184, pem class_loss: 0.363, pem reg_loss: 0.021, total_loss: 1.753[0m
[94mBMN val loss(epoch 0): tem_loss: 1.162, pem class_loss: 0.359, pem reg_loss: 0.019, total_loss: 1.713[0m
[94mBMN val_ema loss(epoch 0): tem_loss: 1.150, pem class_loss: 0.340, pem reg_loss: 0.018, total_loss: 1.675[0m
use Semi !!! use all label !!!
training 604 (epoch 1): tem_loss: 1.127, pem class_loss: 0.493, pem reg_loss: 0.025, consistency_loss: 0.00357, total_loss: 1.870
training 614 (epoch 1): tem_loss: 1.192, pem class_loss: 0.363, pem reg_loss: 0.019, consistency_loss: 0.00402, total_loss: 1.748
training 624 (epoch 1): tem_loss: 1.170, pem class_loss: 0.351, pem reg_loss: 0.019, consistency_loss: 0.00373, total_loss: 1.710
training 634 (epoch 1): tem_loss: 1.175, pem class_loss: 0.352, pem reg_loss: 0.019, consistency_loss: 0.00340, total_loss: 1.721
training 644 (epoch 1): tem_loss: 1.158, pem class_loss: 0.350, pem reg_loss: 0.019, consistency_loss: 0.00321, total_loss: 1.696
training 654 (epoch 1): tem_loss: 1.149, pem class_loss: 0.339, pem reg_loss: 0.019, consistency_loss: 0.00315, total_loss: 1.674
training 664 (epoch 1): tem_loss: 1.146, pem class_loss: 0.340, pem reg_loss: 0.019, consistency_loss: 0.00316, total_loss: 1.673
training 674 (epoch 1): tem_loss: 1.148, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00308, total_loss: 1.677
training 684 (epoch 1): tem_loss: 1.148, pem class_loss: 0.344, pem reg_loss: 0.019, consistency_loss: 0.00303, total_loss: 1.678
training 694 (epoch 1): tem_loss: 1.149, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00307, total_loss: 1.681
training 704 (epoch 1): tem_loss: 1.146, pem class_loss: 0.345, pem reg_loss: 0.019, consistency_loss: 0.00306, total_loss: 1.678
training 714 (epoch 1): tem_loss: 1.145, pem class_loss: 0.346, pem reg_loss: 0.019, consistency_loss: 0.00309, total_loss: 1.677
training 724 (epoch 1): tem_loss: 1.143, pem class_loss: 0.342, pem reg_loss: 0.019, consistency_loss: 0.00311, total_loss: 1.670
training 734 (epoch 1): tem_loss: 1.141, pem class_loss: 0.340, pem reg_loss: 0.018, consistency_loss: 0.00307, total_loss: 1.666
training 744 (epoch 1): tem_loss: 1.139, pem class_loss: 0.341, pem reg_loss: 0.018, consistency_loss: 0.00302, total_loss: 1.663
training 754 (epoch 1): tem_loss: 1.136, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.657
training 764 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00297, total_loss: 1.652
training 774 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.650
training 784 (epoch 1): tem_loss: 1.134, pem class_loss: 0.340, pem reg_loss: 0.018, consistency_loss: 0.00296, total_loss: 1.657
training 794 (epoch 1): tem_loss: 1.133, pem class_loss: 0.340, pem reg_loss: 0.018, consistency_loss: 0.00292, total_loss: 1.655
training 804 (epoch 1): tem_loss: 1.134, pem class_loss: 0.340, pem reg_loss: 0.018, consistency_loss: 0.00294, total_loss: 1.656
training 814 (epoch 1): tem_loss: 1.136, pem class_loss: 0.341, pem reg_loss: 0.018, consistency_loss: 0.00292, total_loss: 1.659
training 824 (epoch 1): tem_loss: 1.134, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00290, total_loss: 1.655
training 834 (epoch 1): tem_loss: 1.135, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00290, total_loss: 1.656
training 844 (epoch 1): tem_loss: 1.134, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00291, total_loss: 1.655
training 854 (epoch 1): tem_loss: 1.134, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00292, total_loss: 1.651
training 864 (epoch 1): tem_loss: 1.135, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00294, total_loss: 1.650
training 874 (epoch 1): tem_loss: 1.134, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00293, total_loss: 1.649
training 884 (epoch 1): tem_loss: 1.136, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00293, total_loss: 1.652
training 894 (epoch 1): tem_loss: 1.135, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00293, total_loss: 1.650
training 904 (epoch 1): tem_loss: 1.135, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00294, total_loss: 1.650
training 914 (epoch 1): tem_loss: 1.135, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.650
training 924 (epoch 1): tem_loss: 1.137, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.655
training 934 (epoch 1): tem_loss: 1.138, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.656
training 944 (epoch 1): tem_loss: 1.137, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.655
training 954 (epoch 1): tem_loss: 1.136, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.654
training 964 (epoch 1): tem_loss: 1.136, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.654
training 974 (epoch 1): tem_loss: 1.135, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.653
training 984 (epoch 1): tem_loss: 1.136, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.655
training 994 (epoch 1): tem_loss: 1.135, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.654
training 1004 (epoch 1): tem_loss: 1.135, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.654
training 1014 (epoch 1): tem_loss: 1.135, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.654
training 1024 (epoch 1): tem_loss: 1.135, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.654
training 1034 (epoch 1): tem_loss: 1.134, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00300, total_loss: 1.652
training 1044 (epoch 1): tem_loss: 1.134, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00300, total_loss: 1.651
training 1054 (epoch 1): tem_loss: 1.132, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00301, total_loss: 1.650
training 1064 (epoch 1): tem_loss: 1.133, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00301, total_loss: 1.650
training 1074 (epoch 1): tem_loss: 1.132, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00300, total_loss: 1.649
training 1084 (epoch 1): tem_loss: 1.133, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.649
training 1094 (epoch 1): tem_loss: 1.133, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.650
training 1104 (epoch 1): tem_loss: 1.134, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.651
training 1114 (epoch 1): tem_loss: 1.134, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00297, total_loss: 1.652
training 1124 (epoch 1): tem_loss: 1.133, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00296, total_loss: 1.650
training 1134 (epoch 1): tem_loss: 1.134, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00295, total_loss: 1.651
training 1144 (epoch 1): tem_loss: 1.134, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.00295, total_loss: 1.651
training 1154 (epoch 1): tem_loss: 1.134, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00295, total_loss: 1.651
training 1164 (epoch 1): tem_loss: 1.133, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00296, total_loss: 1.650
training 1174 (epoch 1): tem_loss: 1.132, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00298, total_loss: 1.647
training 1184 (epoch 1): tem_loss: 1.132, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.648
training 1194 (epoch 1): tem_loss: 1.132, pem class_loss: 0.337, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.648
training 1204 (epoch 1): tem_loss: 1.131, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.00299, total_loss: 1.646
[94mBMN training loss(epoch 1): tem_loss: 1.131, pem class_loss: 0.336, pem reg_loss: 0.018, total_loss: 1.646[0m
[94mBMN val loss(epoch 1): tem_loss: 1.143, pem class_loss: 0.336, pem reg_loss: 0.017, total_loss: 1.650[0m
[94mBMN val_ema loss(epoch 1): tem_loss: 1.134, pem class_loss: 0.330, pem reg_loss: 0.017, total_loss: 1.632[0m
use Semi !!! use all label !!!
training 1207 (epoch 2): tem_loss: 1.152, pem class_loss: 0.315, pem reg_loss: 0.013, consistency_loss: 0.01469, total_loss: 1.597
training 1217 (epoch 2): tem_loss: 1.121, pem class_loss: 0.310, pem reg_loss: 0.017, consistency_loss: 0.01304, total_loss: 1.597
training 1227 (epoch 2): tem_loss: 1.123, pem class_loss: 0.324, pem reg_loss: 0.018, consistency_loss: 0.01209, total_loss: 1.624
training 1237 (epoch 2): tem_loss: 1.132, pem class_loss: 0.339, pem reg_loss: 0.018, consistency_loss: 0.01136, total_loss: 1.650
training 1247 (epoch 2): tem_loss: 1.126, pem class_loss: 0.336, pem reg_loss: 0.018, consistency_loss: 0.01106, total_loss: 1.640
training 1257 (epoch 2): tem_loss: 1.126, pem class_loss: 0.334, pem reg_loss: 0.017, consistency_loss: 0.01147, total_loss: 1.634
training 1267 (epoch 2): tem_loss: 1.126, pem class_loss: 0.334, pem reg_loss: 0.017, consistency_loss: 0.01154, total_loss: 1.635
training 1277 (epoch 2): tem_loss: 1.126, pem class_loss: 0.338, pem reg_loss: 0.018, consistency_loss: 0.01125, total_loss: 1.644
training 1287 (epoch 2): tem_loss: 1.125, pem class_loss: 0.341, pem reg_loss: 0.018, consistency_loss: 0.01095, total_loss: 1.644
training 1297 (epoch 2): tem_loss: 1.119, pem class_loss: 0.335, pem reg_loss: 0.017, consistency_loss: 0.01106, total_loss: 1.629
training 1307 (epoch 2): tem_loss: 1.117, pem class_loss: 0.331, pem reg_loss: 0.017, consistency_loss: 0.01105, total_loss: 1.622
training 1317 (epoch 2): tem_loss: 1.118, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.01096, total_loss: 1.618
training 1327 (epoch 2): tem_loss: 1.117, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01080, total_loss: 1.620
training 1337 (epoch 2): tem_loss: 1.121, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01079, total_loss: 1.625
training 1347 (epoch 2): tem_loss: 1.119, pem class_loss: 0.331, pem reg_loss: 0.017, consistency_loss: 0.01082, total_loss: 1.624
training 1357 (epoch 2): tem_loss: 1.120, pem class_loss: 0.331, pem reg_loss: 0.017, consistency_loss: 0.01077, total_loss: 1.625
training 1367 (epoch 2): tem_loss: 1.119, pem class_loss: 0.331, pem reg_loss: 0.017, consistency_loss: 0.01081, total_loss: 1.623
training 1377 (epoch 2): tem_loss: 1.116, pem class_loss: 0.331, pem reg_loss: 0.017, consistency_loss: 0.01077, total_loss: 1.621
training 1387 (epoch 2): tem_loss: 1.117, pem class_loss: 0.331, pem reg_loss: 0.017, consistency_loss: 0.01075, total_loss: 1.621
training 1397 (epoch 2): tem_loss: 1.116, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01079, total_loss: 1.619
training 1407 (epoch 2): tem_loss: 1.117, pem class_loss: 0.329, pem reg_loss: 0.017, consistency_loss: 0.01079, total_loss: 1.618
training 1417 (epoch 2): tem_loss: 1.118, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01076, total_loss: 1.620
training 1427 (epoch 2): tem_loss: 1.118, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01074, total_loss: 1.620
training 1437 (epoch 2): tem_loss: 1.118, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01071, total_loss: 1.619
training 1447 (epoch 2): tem_loss: 1.116, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01078, total_loss: 1.619
training 1457 (epoch 2): tem_loss: 1.117, pem class_loss: 0.330, pem reg_loss: 0.017, consistency_loss: 0.01076, total_loss: 1.620
training 1467 (epoch 2): tem_loss: 1.117, pem class_loss: 0.329, pem reg_loss: 0.017, consistency_loss: 0.01076, total_loss: 1.618
training 1477 (epoch 2): tem_loss: 1.117, pem class_loss: 0.328, pem reg_loss: 0.017, consistency_loss: 0.01071, total_loss: 1.616
training 1487 (epoch 2): tem_loss: 1.116, pem class_loss: 0.327, pem reg_loss: 0.017, consistency_loss: 0.01068, total_loss: 1.615
training 1497 (epoch 2): tem_loss: 1.118, pem class_loss: 0.327, pem reg_loss: 0.017, consistency_loss: 0.01064, total_loss: 1.616
training 1507 (epoch 2): tem_loss: 1.117, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01065, total_loss: 1.614
training 1517 (epoch 2): tem_loss: 1.116, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01063, total_loss: 1.612
training 1527 (epoch 2): tem_loss: 1.114, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01077, total_loss: 1.609
training 1537 (epoch 2): tem_loss: 1.115, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01076, total_loss: 1.610
training 1547 (epoch 2): tem_loss: 1.113, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01078, total_loss: 1.607
training 1557 (epoch 2): tem_loss: 1.113, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01074, total_loss: 1.607
training 1567 (epoch 2): tem_loss: 1.112, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01069, total_loss: 1.605
training 1577 (epoch 2): tem_loss: 1.113, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01069, total_loss: 1.608
training 1587 (epoch 2): tem_loss: 1.115, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01075, total_loss: 1.610
training 1597 (epoch 2): tem_loss: 1.113, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01080, total_loss: 1.608
training 1607 (epoch 2): tem_loss: 1.114, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01081, total_loss: 1.609
training 1617 (epoch 2): tem_loss: 1.114, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01080, total_loss: 1.609
training 1627 (epoch 2): tem_loss: 1.114, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01081, total_loss: 1.610
training 1637 (epoch 2): tem_loss: 1.113, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01081, total_loss: 1.609
training 1647 (epoch 2): tem_loss: 1.113, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01085, total_loss: 1.607
training 1657 (epoch 2): tem_loss: 1.113, pem class_loss: 0.326, pem reg_loss: 0.017, consistency_loss: 0.01082, total_loss: 1.607
training 1667 (epoch 2): tem_loss: 1.112, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01082, total_loss: 1.606
training 1677 (epoch 2): tem_loss: 1.112, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01079, total_loss: 1.605
training 1687 (epoch 2): tem_loss: 1.111, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01074, total_loss: 1.605
training 1697 (epoch 2): tem_loss: 1.111, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01072, total_loss: 1.605
training 1707 (epoch 2): tem_loss: 1.110, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01073, total_loss: 1.603
training 1717 (epoch 2): tem_loss: 1.110, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01073, total_loss: 1.603
training 1727 (epoch 2): tem_loss: 1.110, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01071, total_loss: 1.603
training 1737 (epoch 2): tem_loss: 1.110, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01068, total_loss: 1.604
training 1747 (epoch 2): tem_loss: 1.109, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01071, total_loss: 1.602
training 1757 (epoch 2): tem_loss: 1.109, pem class_loss: 0.325, pem reg_loss: 0.017, consistency_loss: 0.01074, total_loss: 1.602
training 1767 (epoch 2): tem_loss: 1.109, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01075, total_loss: 1.601
training 1777 (epoch 2): tem_loss: 1.109, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01071, total_loss: 1.602
training 1787 (epoch 2): tem_loss: 1.109, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01071, total_loss: 1.601
training 1797 (epoch 2): tem_loss: 1.108, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01071, total_loss: 1.599
training 1807 (epoch 2): tem_loss: 1.109, pem class_loss: 0.324, pem reg_loss: 0.017, consistency_loss: 0.01069, total_loss: 1.600
[94mBMN training loss(epoch 2): tem_loss: 1.109, pem class_loss: 0.324, pem reg_loss: 0.017, total_loss: 1.600[0m
[94mBMN val loss(epoch 2): tem_loss: 1.132, pem class_loss: 0.335, pem reg_loss: 0.017, total_loss: 1.636[0m
[94mBMN val_ema loss(epoch 2): tem_loss: 1.125, pem class_loss: 0.323, pem reg_loss: 0.016, total_loss: 1.609[0m
use Semi !!! use all label !!!
training 1810 (epoch 3): tem_loss: 1.104, pem class_loss: 0.347, pem reg_loss: 0.018, consistency_loss: 0.02880, total_loss: 1.629
training 1820 (epoch 3): tem_loss: 1.087, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.02783, total_loss: 1.535
training 1830 (epoch 3): tem_loss: 1.077, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.02795, total_loss: 1.533
training 1840 (epoch 3): tem_loss: 1.083, pem class_loss: 0.316, pem reg_loss: 0.015, consistency_loss: 0.02696, total_loss: 1.552
training 1850 (epoch 3): tem_loss: 1.076, pem class_loss: 0.311, pem reg_loss: 0.015, consistency_loss: 0.02712, total_loss: 1.540
training 1860 (epoch 3): tem_loss: 1.078, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02793, total_loss: 1.548
training 1870 (epoch 3): tem_loss: 1.078, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.02762, total_loss: 1.552
training 1880 (epoch 3): tem_loss: 1.082, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.02727, total_loss: 1.553
training 1890 (epoch 3): tem_loss: 1.079, pem class_loss: 0.313, pem reg_loss: 0.016, consistency_loss: 0.02702, total_loss: 1.547
training 1900 (epoch 3): tem_loss: 1.081, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02688, total_loss: 1.558
training 1910 (epoch 3): tem_loss: 1.080, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02666, total_loss: 1.560
training 1920 (epoch 3): tem_loss: 1.084, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02643, total_loss: 1.565
training 1930 (epoch 3): tem_loss: 1.082, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02597, total_loss: 1.562
training 1940 (epoch 3): tem_loss: 1.082, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02580, total_loss: 1.559
training 1950 (epoch 3): tem_loss: 1.085, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02559, total_loss: 1.561
training 1960 (epoch 3): tem_loss: 1.085, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.02554, total_loss: 1.559
training 1970 (epoch 3): tem_loss: 1.089, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.02548, total_loss: 1.562
training 1980 (epoch 3): tem_loss: 1.089, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02516, total_loss: 1.561
training 1990 (epoch 3): tem_loss: 1.089, pem class_loss: 0.315, pem reg_loss: 0.016, consistency_loss: 0.02503, total_loss: 1.562
training 2000 (epoch 3): tem_loss: 1.088, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.02527, total_loss: 1.560
training 2010 (epoch 3): tem_loss: 1.089, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02524, total_loss: 1.564
training 2020 (epoch 3): tem_loss: 1.087, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02516, total_loss: 1.563
training 2030 (epoch 3): tem_loss: 1.088, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02514, total_loss: 1.564
training 2040 (epoch 3): tem_loss: 1.089, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02519, total_loss: 1.565
training 2050 (epoch 3): tem_loss: 1.090, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.02508, total_loss: 1.567
training 2060 (epoch 3): tem_loss: 1.089, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02504, total_loss: 1.564
training 2070 (epoch 3): tem_loss: 1.088, pem class_loss: 0.316, pem reg_loss: 0.016, consistency_loss: 0.02526, total_loss: 1.563
training 2080 (epoch 3): tem_loss: 1.090, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.02543, total_loss: 1.567
training 2090 (epoch 3): tem_loss: 1.089, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.02556, total_loss: 1.567
training 2100 (epoch 3): tem_loss: 1.089, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.02563, total_loss: 1.567
training 2110 (epoch 3): tem_loss: 1.089, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.02573, total_loss: 1.567
training 2120 (epoch 3): tem_loss: 1.089, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.02567, total_loss: 1.567
training 2130 (epoch 3): tem_loss: 1.089, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02567, total_loss: 1.569
training 2140 (epoch 3): tem_loss: 1.089, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02578, total_loss: 1.571
training 2150 (epoch 3): tem_loss: 1.089, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02580, total_loss: 1.570
training 2160 (epoch 3): tem_loss: 1.090, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02579, total_loss: 1.572
training 2170 (epoch 3): tem_loss: 1.091, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02583, total_loss: 1.572
training 2180 (epoch 3): tem_loss: 1.091, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02582, total_loss: 1.572
training 2190 (epoch 3): tem_loss: 1.091, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02577, total_loss: 1.571
training 2200 (epoch 3): tem_loss: 1.092, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02572, total_loss: 1.573
training 2210 (epoch 3): tem_loss: 1.092, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02562, total_loss: 1.574
training 2220 (epoch 3): tem_loss: 1.092, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02552, total_loss: 1.574
training 2230 (epoch 3): tem_loss: 1.093, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02544, total_loss: 1.575
training 2240 (epoch 3): tem_loss: 1.094, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02538, total_loss: 1.575
training 2250 (epoch 3): tem_loss: 1.094, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02534, total_loss: 1.575
training 2260 (epoch 3): tem_loss: 1.094, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.02529, total_loss: 1.574
training 2270 (epoch 3): tem_loss: 1.094, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02520, total_loss: 1.574
training 2280 (epoch 3): tem_loss: 1.094, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02511, total_loss: 1.575
training 2290 (epoch 3): tem_loss: 1.095, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02509, total_loss: 1.576
training 2300 (epoch 3): tem_loss: 1.095, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02505, total_loss: 1.577
training 2310 (epoch 3): tem_loss: 1.096, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02506, total_loss: 1.579
training 2320 (epoch 3): tem_loss: 1.096, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02513, total_loss: 1.579
training 2330 (epoch 3): tem_loss: 1.096, pem class_loss: 0.320, pem reg_loss: 0.016, consistency_loss: 0.02510, total_loss: 1.578
training 2340 (epoch 3): tem_loss: 1.096, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02508, total_loss: 1.577
training 2350 (epoch 3): tem_loss: 1.095, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02508, total_loss: 1.576
training 2360 (epoch 3): tem_loss: 1.096, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02504, total_loss: 1.578
training 2370 (epoch 3): tem_loss: 1.096, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02501, total_loss: 1.577
training 2380 (epoch 3): tem_loss: 1.096, pem class_loss: 0.319, pem reg_loss: 0.016, consistency_loss: 0.02501, total_loss: 1.576
training 2390 (epoch 3): tem_loss: 1.095, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.02501, total_loss: 1.575
training 2400 (epoch 3): tem_loss: 1.095, pem class_loss: 0.318, pem reg_loss: 0.016, consistency_loss: 0.02502, total_loss: 1.574
training 2410 (epoch 3): tem_loss: 1.095, pem class_loss: 0.317, pem reg_loss: 0.016, consistency_loss: 0.02502, total_loss: 1.574
[94mBMN training loss(epoch 3): tem_loss: 1.095, pem class_loss: 0.317, pem reg_loss: 0.016, total_loss: 1.573[0m
[94mBMN val loss(epoch 3): tem_loss: 1.133, pem class_loss: 0.328, pem reg_loss: 0.016, total_loss: 1.623[0m
[94mBMN val_ema loss(epoch 3): tem_loss: 1.126, pem class_loss: 0.320, pem reg_loss: 0.016, total_loss: 1.602[0m
use Semi !!! use all label !!!
training 2413 (epoch 4): tem_loss: 1.126, pem class_loss: 0.315, pem reg_loss: 0.020, consistency_loss: 0.03423, total_loss: 1.642
training 2423 (epoch 4): tem_loss: 1.074, pem class_loss: 0.316, pem reg_loss: 0.015, consistency_loss: 0.04010, total_loss: 1.541
training 2433 (epoch 4): tem_loss: 1.077, pem class_loss: 0.313, pem reg_loss: 0.015, consistency_loss: 0.03916, total_loss: 1.538
training 2443 (epoch 4): tem_loss: 1.095, pem class_loss: 0.317, pem reg_loss: 0.015, consistency_loss: 0.04029, total_loss: 1.565
training 2453 (epoch 4): tem_loss: 1.087, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.04058, total_loss: 1.558
training 2463 (epoch 4): tem_loss: 1.087, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.04208, total_loss: 1.559
training 2473 (epoch 4): tem_loss: 1.084, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.04234, total_loss: 1.551
training 2483 (epoch 4): tem_loss: 1.083, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.04162, total_loss: 1.552
training 2493 (epoch 4): tem_loss: 1.087, pem class_loss: 0.314, pem reg_loss: 0.016, consistency_loss: 0.04098, total_loss: 1.560
training 2503 (epoch 4): tem_loss: 1.081, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.04069, total_loss: 1.545
training 2513 (epoch 4): tem_loss: 1.081, pem class_loss: 0.307, pem reg_loss: 0.016, consistency_loss: 0.04065, total_loss: 1.544
training 2523 (epoch 4): tem_loss: 1.082, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.04030, total_loss: 1.550
training 2533 (epoch 4): tem_loss: 1.082, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.04008, total_loss: 1.549
training 2543 (epoch 4): tem_loss: 1.085, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03955, total_loss: 1.553
training 2553 (epoch 4): tem_loss: 1.086, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03935, total_loss: 1.555
training 2563 (epoch 4): tem_loss: 1.083, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03915, total_loss: 1.550
training 2573 (epoch 4): tem_loss: 1.087, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03890, total_loss: 1.554
training 2583 (epoch 4): tem_loss: 1.084, pem class_loss: 0.308, pem reg_loss: 0.016, consistency_loss: 0.03868, total_loss: 1.548
training 2593 (epoch 4): tem_loss: 1.084, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03854, total_loss: 1.549
training 2603 (epoch 4): tem_loss: 1.084, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03840, total_loss: 1.549
training 2613 (epoch 4): tem_loss: 1.083, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03843, total_loss: 1.548
training 2623 (epoch 4): tem_loss: 1.083, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03862, total_loss: 1.549
training 2633 (epoch 4): tem_loss: 1.081, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03871, total_loss: 1.547
training 2643 (epoch 4): tem_loss: 1.084, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03880, total_loss: 1.551
training 2653 (epoch 4): tem_loss: 1.086, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03859, total_loss: 1.555
training 2663 (epoch 4): tem_loss: 1.086, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03856, total_loss: 1.554
training 2673 (epoch 4): tem_loss: 1.085, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03873, total_loss: 1.551
training 2683 (epoch 4): tem_loss: 1.086, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03863, total_loss: 1.552
training 2693 (epoch 4): tem_loss: 1.086, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03855, total_loss: 1.550
training 2703 (epoch 4): tem_loss: 1.085, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.03861, total_loss: 1.549
training 2713 (epoch 4): tem_loss: 1.085, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03860, total_loss: 1.550
training 2723 (epoch 4): tem_loss: 1.085, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.03849, total_loss: 1.549
training 2733 (epoch 4): tem_loss: 1.084, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.03850, total_loss: 1.548
training 2743 (epoch 4): tem_loss: 1.086, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03841, total_loss: 1.550
training 2753 (epoch 4): tem_loss: 1.085, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.03838, total_loss: 1.549
training 2763 (epoch 4): tem_loss: 1.086, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03853, total_loss: 1.550
training 2773 (epoch 4): tem_loss: 1.087, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03849, total_loss: 1.551
training 2783 (epoch 4): tem_loss: 1.086, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03855, total_loss: 1.550
training 2793 (epoch 4): tem_loss: 1.085, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03849, total_loss: 1.549
training 2803 (epoch 4): tem_loss: 1.084, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.03840, total_loss: 1.548
training 2813 (epoch 4): tem_loss: 1.085, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.03836, total_loss: 1.549
training 2823 (epoch 4): tem_loss: 1.084, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03819, total_loss: 1.549
training 2833 (epoch 4): tem_loss: 1.086, pem class_loss: 0.310, pem reg_loss: 0.016, consistency_loss: 0.03809, total_loss: 1.552
training 2843 (epoch 4): tem_loss: 1.087, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03805, total_loss: 1.553
training 2853 (epoch 4): tem_loss: 1.086, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03789, total_loss: 1.553
training 2863 (epoch 4): tem_loss: 1.087, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03787, total_loss: 1.554
training 2873 (epoch 4): tem_loss: 1.087, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03791, total_loss: 1.555
training 2883 (epoch 4): tem_loss: 1.087, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03787, total_loss: 1.555
training 2893 (epoch 4): tem_loss: 1.087, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03796, total_loss: 1.555
training 2903 (epoch 4): tem_loss: 1.086, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03801, total_loss: 1.554
training 2913 (epoch 4): tem_loss: 1.087, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03800, total_loss: 1.554
training 2923 (epoch 4): tem_loss: 1.087, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03803, total_loss: 1.554
training 2933 (epoch 4): tem_loss: 1.087, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03797, total_loss: 1.555
training 2943 (epoch 4): tem_loss: 1.088, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03785, total_loss: 1.555
training 2953 (epoch 4): tem_loss: 1.088, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03771, total_loss: 1.556
training 2963 (epoch 4): tem_loss: 1.090, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03763, total_loss: 1.557
training 2973 (epoch 4): tem_loss: 1.089, pem class_loss: 0.311, pem reg_loss: 0.016, consistency_loss: 0.03753, total_loss: 1.556
training 2983 (epoch 4): tem_loss: 1.089, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03748, total_loss: 1.557
training 2993 (epoch 4): tem_loss: 1.090, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03739, total_loss: 1.558
training 3003 (epoch 4): tem_loss: 1.090, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03729, total_loss: 1.557
training 3013 (epoch 4): tem_loss: 1.091, pem class_loss: 0.312, pem reg_loss: 0.016, consistency_loss: 0.03723, total_loss: 1.557
[94mBMN training loss(epoch 4): tem_loss: 1.091, pem class_loss: 0.312, pem reg_loss: 0.016, total_loss: 1.558[0m
[94mBMN val loss(epoch 4): tem_loss: 1.136, pem class_loss: 0.329, pem reg_loss: 0.016, total_loss: 1.624[0m
[94mBMN val_ema loss(epoch 4): tem_loss: 1.132, pem class_loss: 0.317, pem reg_loss: 0.015, total_loss: 1.603[0m
use Semi !!! use all label !!!
training 3016 (epoch 5): tem_loss: 1.088, pem class_loss: 0.267, pem reg_loss: 0.011, consistency_loss: 0.05645, total_loss: 1.461
training 3026 (epoch 5): tem_loss: 1.080, pem class_loss: 0.308, pem reg_loss: 0.014, consistency_loss: 0.04827, total_loss: 1.532
training 3036 (epoch 5): tem_loss: 1.087, pem class_loss: 0.309, pem reg_loss: 0.016, consistency_loss: 0.04527, total_loss: 1.552
training 3046 (epoch 5): tem_loss: 1.084, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04546, total_loss: 1.542
training 3056 (epoch 5): tem_loss: 1.080, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04491, total_loss: 1.532
training 3066 (epoch 5): tem_loss: 1.079, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04365, total_loss: 1.532
training 3076 (epoch 5): tem_loss: 1.073, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04255, total_loss: 1.524
training 3086 (epoch 5): tem_loss: 1.074, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04295, total_loss: 1.533
training 3096 (epoch 5): tem_loss: 1.072, pem class_loss: 0.310, pem reg_loss: 0.015, consistency_loss: 0.04361, total_loss: 1.535
training 3106 (epoch 5): tem_loss: 1.077, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04333, total_loss: 1.540
training 3116 (epoch 5): tem_loss: 1.081, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04329, total_loss: 1.539
training 3126 (epoch 5): tem_loss: 1.083, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.04322, total_loss: 1.540
training 3136 (epoch 5): tem_loss: 1.085, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04309, total_loss: 1.542
training 3146 (epoch 5): tem_loss: 1.088, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04307, total_loss: 1.546
training 3156 (epoch 5): tem_loss: 1.086, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.04313, total_loss: 1.543
training 3166 (epoch 5): tem_loss: 1.085, pem class_loss: 0.305, pem reg_loss: 0.015, consistency_loss: 0.04318, total_loss: 1.541
training 3176 (epoch 5): tem_loss: 1.086, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.04343, total_loss: 1.542
training 3186 (epoch 5): tem_loss: 1.083, pem class_loss: 0.304, pem reg_loss: 0.015, consistency_loss: 0.04402, total_loss: 1.539
training 3196 (epoch 5): tem_loss: 1.088, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04401, total_loss: 1.546
training 3206 (epoch 5): tem_loss: 1.087, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04391, total_loss: 1.544
training 3216 (epoch 5): tem_loss: 1.088, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04376, total_loss: 1.546
training 3226 (epoch 5): tem_loss: 1.086, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04381, total_loss: 1.545
training 3236 (epoch 5): tem_loss: 1.089, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04391, total_loss: 1.548
training 3246 (epoch 5): tem_loss: 1.088, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04371, total_loss: 1.547
training 3256 (epoch 5): tem_loss: 1.091, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04370, total_loss: 1.552
training 3266 (epoch 5): tem_loss: 1.092, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04375, total_loss: 1.554
training 3276 (epoch 5): tem_loss: 1.092, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04368, total_loss: 1.553
training 3286 (epoch 5): tem_loss: 1.092, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04356, total_loss: 1.553
training 3296 (epoch 5): tem_loss: 1.091, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04343, total_loss: 1.554
training 3306 (epoch 5): tem_loss: 1.089, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04345, total_loss: 1.550
training 3316 (epoch 5): tem_loss: 1.088, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04343, total_loss: 1.549
training 3326 (epoch 5): tem_loss: 1.089, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04334, total_loss: 1.551
training 3336 (epoch 5): tem_loss: 1.091, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04314, total_loss: 1.554
training 3346 (epoch 5): tem_loss: 1.092, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04301, total_loss: 1.554
training 3356 (epoch 5): tem_loss: 1.092, pem class_loss: 0.310, pem reg_loss: 0.015, consistency_loss: 0.04292, total_loss: 1.556
training 3366 (epoch 5): tem_loss: 1.092, pem class_loss: 0.310, pem reg_loss: 0.015, consistency_loss: 0.04281, total_loss: 1.556
training 3376 (epoch 5): tem_loss: 1.090, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04280, total_loss: 1.553
training 3386 (epoch 5): tem_loss: 1.090, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04289, total_loss: 1.553
training 3396 (epoch 5): tem_loss: 1.091, pem class_loss: 0.310, pem reg_loss: 0.015, consistency_loss: 0.04293, total_loss: 1.555
training 3406 (epoch 5): tem_loss: 1.093, pem class_loss: 0.310, pem reg_loss: 0.015, consistency_loss: 0.04296, total_loss: 1.557
training 3416 (epoch 5): tem_loss: 1.094, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04300, total_loss: 1.556
training 3426 (epoch 5): tem_loss: 1.094, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04303, total_loss: 1.555
training 3436 (epoch 5): tem_loss: 1.093, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04304, total_loss: 1.555
training 3446 (epoch 5): tem_loss: 1.094, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04296, total_loss: 1.555
training 3456 (epoch 5): tem_loss: 1.094, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04288, total_loss: 1.554
training 3466 (epoch 5): tem_loss: 1.093, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04276, total_loss: 1.553
training 3476 (epoch 5): tem_loss: 1.093, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04284, total_loss: 1.551
training 3486 (epoch 5): tem_loss: 1.093, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04287, total_loss: 1.553
training 3496 (epoch 5): tem_loss: 1.093, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04284, total_loss: 1.554
training 3506 (epoch 5): tem_loss: 1.094, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04283, total_loss: 1.556
training 3516 (epoch 5): tem_loss: 1.094, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04286, total_loss: 1.555
training 3526 (epoch 5): tem_loss: 1.095, pem class_loss: 0.309, pem reg_loss: 0.015, consistency_loss: 0.04288, total_loss: 1.556
training 3536 (epoch 5): tem_loss: 1.094, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04277, total_loss: 1.555
training 3546 (epoch 5): tem_loss: 1.093, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04279, total_loss: 1.554
training 3556 (epoch 5): tem_loss: 1.093, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04278, total_loss: 1.552
training 3566 (epoch 5): tem_loss: 1.092, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04265, total_loss: 1.552
training 3576 (epoch 5): tem_loss: 1.091, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04267, total_loss: 1.551
training 3586 (epoch 5): tem_loss: 1.091, pem class_loss: 0.308, pem reg_loss: 0.015, consistency_loss: 0.04276, total_loss: 1.551
training 3596 (epoch 5): tem_loss: 1.091, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04279, total_loss: 1.550
training 3606 (epoch 5): tem_loss: 1.091, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04267, total_loss: 1.550
training 3616 (epoch 5): tem_loss: 1.090, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04266, total_loss: 1.549
[94mBMN training loss(epoch 5): tem_loss: 1.090, pem class_loss: 0.306, pem reg_loss: 0.015, total_loss: 1.548[0m
[94mBMN val loss(epoch 5): tem_loss: 1.138, pem class_loss: 0.319, pem reg_loss: 0.016, total_loss: 1.616[0m
[94mBMN val_ema loss(epoch 5): tem_loss: 1.139, pem class_loss: 0.316, pem reg_loss: 0.015, total_loss: 1.607[0m
use Semi !!! use all label !!!
training 3619 (epoch 6): tem_loss: 1.048, pem class_loss: 0.304, pem reg_loss: 0.014, consistency_loss: 0.03589, total_loss: 1.495
training 3629 (epoch 6): tem_loss: 1.062, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.03967, total_loss: 1.507
training 3639 (epoch 6): tem_loss: 1.061, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.03815, total_loss: 1.505
training 3649 (epoch 6): tem_loss: 1.063, pem class_loss: 0.287, pem reg_loss: 0.014, consistency_loss: 0.03891, total_loss: 1.493
training 3659 (epoch 6): tem_loss: 1.056, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.04019, total_loss: 1.477
training 3669 (epoch 6): tem_loss: 1.067, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.04086, total_loss: 1.493
training 3679 (epoch 6): tem_loss: 1.066, pem class_loss: 0.290, pem reg_loss: 0.015, consistency_loss: 0.04052, total_loss: 1.500
training 3689 (epoch 6): tem_loss: 1.072, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.04030, total_loss: 1.514
training 3699 (epoch 6): tem_loss: 1.076, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04040, total_loss: 1.526
training 3709 (epoch 6): tem_loss: 1.071, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.04036, total_loss: 1.517
training 3719 (epoch 6): tem_loss: 1.071, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.04064, total_loss: 1.516
training 3729 (epoch 6): tem_loss: 1.068, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.04074, total_loss: 1.514
training 3739 (epoch 6): tem_loss: 1.064, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.04126, total_loss: 1.507
training 3749 (epoch 6): tem_loss: 1.062, pem class_loss: 0.295, pem reg_loss: 0.014, consistency_loss: 0.04165, total_loss: 1.501
training 3759 (epoch 6): tem_loss: 1.063, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.04187, total_loss: 1.504
training 3769 (epoch 6): tem_loss: 1.066, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.04200, total_loss: 1.508
training 3779 (epoch 6): tem_loss: 1.068, pem class_loss: 0.296, pem reg_loss: 0.015, consistency_loss: 0.04176, total_loss: 1.511
training 3789 (epoch 6): tem_loss: 1.069, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.04180, total_loss: 1.514
training 3799 (epoch 6): tem_loss: 1.072, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.04155, total_loss: 1.516
training 3809 (epoch 6): tem_loss: 1.074, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.04146, total_loss: 1.518
training 3819 (epoch 6): tem_loss: 1.074, pem class_loss: 0.298, pem reg_loss: 0.015, consistency_loss: 0.04137, total_loss: 1.520
training 3829 (epoch 6): tem_loss: 1.076, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.04116, total_loss: 1.523
training 3839 (epoch 6): tem_loss: 1.076, pem class_loss: 0.299, pem reg_loss: 0.015, consistency_loss: 0.04108, total_loss: 1.524
training 3849 (epoch 6): tem_loss: 1.078, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.04089, total_loss: 1.527
training 3859 (epoch 6): tem_loss: 1.080, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04081, total_loss: 1.529
training 3869 (epoch 6): tem_loss: 1.080, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.04096, total_loss: 1.529
training 3879 (epoch 6): tem_loss: 1.082, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04093, total_loss: 1.533
training 3889 (epoch 6): tem_loss: 1.082, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04085, total_loss: 1.533
training 3899 (epoch 6): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04081, total_loss: 1.533
training 3909 (epoch 6): tem_loss: 1.084, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04111, total_loss: 1.534
training 3919 (epoch 6): tem_loss: 1.083, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04124, total_loss: 1.534
training 3929 (epoch 6): tem_loss: 1.084, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04120, total_loss: 1.535
training 3939 (epoch 6): tem_loss: 1.084, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.04151, total_loss: 1.537
training 3949 (epoch 6): tem_loss: 1.084, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.04158, total_loss: 1.536
training 3959 (epoch 6): tem_loss: 1.085, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.04172, total_loss: 1.538
training 3969 (epoch 6): tem_loss: 1.084, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04172, total_loss: 1.536
training 3979 (epoch 6): tem_loss: 1.084, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04182, total_loss: 1.534
training 3989 (epoch 6): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04184, total_loss: 1.534
training 3999 (epoch 6): tem_loss: 1.083, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04186, total_loss: 1.535
training 4009 (epoch 6): tem_loss: 1.082, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04182, total_loss: 1.533
training 4019 (epoch 6): tem_loss: 1.083, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04183, total_loss: 1.534
training 4029 (epoch 6): tem_loss: 1.086, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.04178, total_loss: 1.539
training 4039 (epoch 6): tem_loss: 1.084, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.04176, total_loss: 1.536
training 4049 (epoch 6): tem_loss: 1.084, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.04180, total_loss: 1.537
training 4059 (epoch 6): tem_loss: 1.084, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04198, total_loss: 1.536
training 4069 (epoch 6): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04199, total_loss: 1.533
training 4079 (epoch 6): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04195, total_loss: 1.533
training 4089 (epoch 6): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04183, total_loss: 1.533
training 4099 (epoch 6): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04180, total_loss: 1.532
training 4109 (epoch 6): tem_loss: 1.083, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04188, total_loss: 1.532
training 4119 (epoch 6): tem_loss: 1.084, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.04187, total_loss: 1.532
training 4129 (epoch 6): tem_loss: 1.084, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.04183, total_loss: 1.533
training 4139 (epoch 6): tem_loss: 1.084, pem class_loss: 0.300, pem reg_loss: 0.015, consistency_loss: 0.04178, total_loss: 1.533
training 4149 (epoch 6): tem_loss: 1.086, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04174, total_loss: 1.535
training 4159 (epoch 6): tem_loss: 1.087, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04171, total_loss: 1.536
training 4169 (epoch 6): tem_loss: 1.088, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04176, total_loss: 1.537
training 4179 (epoch 6): tem_loss: 1.088, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04176, total_loss: 1.537
training 4189 (epoch 6): tem_loss: 1.088, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04175, total_loss: 1.537
training 4199 (epoch 6): tem_loss: 1.089, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.04179, total_loss: 1.539
training 4209 (epoch 6): tem_loss: 1.090, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04180, total_loss: 1.541
training 4219 (epoch 6): tem_loss: 1.090, pem class_loss: 0.302, pem reg_loss: 0.015, consistency_loss: 0.04184, total_loss: 1.541
[94mBMN training loss(epoch 6): tem_loss: 1.090, pem class_loss: 0.302, pem reg_loss: 0.015, total_loss: 1.541[0m
[94mBMN val loss(epoch 6): tem_loss: 1.138, pem class_loss: 0.318, pem reg_loss: 0.016, total_loss: 1.614[0m
[94mBMN val_ema loss(epoch 6): tem_loss: 1.146, pem class_loss: 0.314, pem reg_loss: 0.015, total_loss: 1.612[0m
use Semi !!! use all label !!!
training 4222 (epoch 7): tem_loss: 1.135, pem class_loss: 0.306, pem reg_loss: 0.015, consistency_loss: 0.04913, total_loss: 1.590
training 4232 (epoch 7): tem_loss: 1.045, pem class_loss: 0.295, pem reg_loss: 0.015, consistency_loss: 0.04436, total_loss: 1.490
training 4242 (epoch 7): tem_loss: 1.073, pem class_loss: 0.307, pem reg_loss: 0.015, consistency_loss: 0.04116, total_loss: 1.528
training 4252 (epoch 7): tem_loss: 1.065, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.03961, total_loss: 1.518
training 4262 (epoch 7): tem_loss: 1.066, pem class_loss: 0.303, pem reg_loss: 0.015, consistency_loss: 0.03740, total_loss: 1.517
training 4272 (epoch 7): tem_loss: 1.073, pem class_loss: 0.301, pem reg_loss: 0.015, consistency_loss: 0.03652, total_loss: 1.518
training 4282 (epoch 7): tem_loss: 1.069, pem class_loss: 0.297, pem reg_loss: 0.015, consistency_loss: 0.03566, total_loss: 1.511
training 4292 (epoch 7): tem_loss: 1.071, pem class_loss: 0.295, pem reg_loss: 0.014, consistency_loss: 0.03476, total_loss: 1.510
training 4302 (epoch 7): tem_loss: 1.073, pem class_loss: 0.295, pem reg_loss: 0.014, consistency_loss: 0.03412, total_loss: 1.512
training 4312 (epoch 7): tem_loss: 1.073, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.03364, total_loss: 1.505
training 4322 (epoch 7): tem_loss: 1.067, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.03302, total_loss: 1.499
training 4332 (epoch 7): tem_loss: 1.071, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.03251, total_loss: 1.503
training 4342 (epoch 7): tem_loss: 1.072, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.03213, total_loss: 1.507
training 4352 (epoch 7): tem_loss: 1.071, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.03159, total_loss: 1.506
training 4362 (epoch 7): tem_loss: 1.072, pem class_loss: 0.295, pem reg_loss: 0.014, consistency_loss: 0.03130, total_loss: 1.511
training 4372 (epoch 7): tem_loss: 1.068, pem class_loss: 0.294, pem reg_loss: 0.014, consistency_loss: 0.03093, total_loss: 1.506
training 4382 (epoch 7): tem_loss: 1.068, pem class_loss: 0.293, pem reg_loss: 0.014, consistency_loss: 0.03063, total_loss: 1.504
training 4392 (epoch 7): tem_loss: 1.067, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.03038, total_loss: 1.501
training 4402 (epoch 7): tem_loss: 1.065, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.03033, total_loss: 1.498
training 4412 (epoch 7): tem_loss: 1.068, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.03011, total_loss: 1.502
training 4422 (epoch 7): tem_loss: 1.066, pem class_loss: 0.292, pem reg_loss: 0.014, consistency_loss: 0.02988, total_loss: 1.500
training 4432 (epoch 7): tem_loss: 1.064, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.02968, total_loss: 1.498
training 4442 (epoch 7): tem_loss: 1.064, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.02952, total_loss: 1.497
training 4452 (epoch 7): tem_loss: 1.062, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.02944, total_loss: 1.495
training 4462 (epoch 7): tem_loss: 1.063, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02932, total_loss: 1.494
training 4472 (epoch 7): tem_loss: 1.065, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02918, total_loss: 1.497
training 4482 (epoch 7): tem_loss: 1.067, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02910, total_loss: 1.499
training 4492 (epoch 7): tem_loss: 1.067, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02893, total_loss: 1.499
training 4502 (epoch 7): tem_loss: 1.069, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02883, total_loss: 1.500
training 4512 (epoch 7): tem_loss: 1.068, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02871, total_loss: 1.499
training 4522 (epoch 7): tem_loss: 1.066, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02863, total_loss: 1.497
training 4532 (epoch 7): tem_loss: 1.066, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02851, total_loss: 1.497
training 4542 (epoch 7): tem_loss: 1.068, pem class_loss: 0.291, pem reg_loss: 0.014, consistency_loss: 0.02846, total_loss: 1.499
training 4552 (epoch 7): tem_loss: 1.066, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02843, total_loss: 1.497
training 4562 (epoch 7): tem_loss: 1.066, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02837, total_loss: 1.497
training 4572 (epoch 7): tem_loss: 1.066, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02837, total_loss: 1.496
training 4582 (epoch 7): tem_loss: 1.066, pem class_loss: 0.290, pem reg_loss: 0.014, consistency_loss: 0.02836, total_loss: 1.497
training 4592 (epoch 7): tem_loss: 1.066, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02831, total_loss: 1.496
training 4602 (epoch 7): tem_loss: 1.066, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02823, total_loss: 1.495
training 4612 (epoch 7): tem_loss: 1.066, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02822, total_loss: 1.496
training 4622 (epoch 7): tem_loss: 1.068, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02818, total_loss: 1.498
training 4632 (epoch 7): tem_loss: 1.068, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02817, total_loss: 1.497
training 4642 (epoch 7): tem_loss: 1.068, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02813, total_loss: 1.497
training 4652 (epoch 7): tem_loss: 1.070, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02811, total_loss: 1.498
training 4662 (epoch 7): tem_loss: 1.069, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02809, total_loss: 1.497
training 4672 (epoch 7): tem_loss: 1.069, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02807, total_loss: 1.497
training 4682 (epoch 7): tem_loss: 1.069, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02806, total_loss: 1.499
training 4692 (epoch 7): tem_loss: 1.069, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02805, total_loss: 1.499
training 4702 (epoch 7): tem_loss: 1.068, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02802, total_loss: 1.498
training 4712 (epoch 7): tem_loss: 1.067, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02802, total_loss: 1.497
training 4722 (epoch 7): tem_loss: 1.068, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02802, total_loss: 1.498
training 4732 (epoch 7): tem_loss: 1.069, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02803, total_loss: 1.498
training 4742 (epoch 7): tem_loss: 1.069, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02802, total_loss: 1.498
training 4752 (epoch 7): tem_loss: 1.069, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02802, total_loss: 1.497
training 4762 (epoch 7): tem_loss: 1.069, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02802, total_loss: 1.498
training 4772 (epoch 7): tem_loss: 1.069, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02799, total_loss: 1.498
training 4782 (epoch 7): tem_loss: 1.070, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02799, total_loss: 1.499
training 4792 (epoch 7): tem_loss: 1.070, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02798, total_loss: 1.498
training 4802 (epoch 7): tem_loss: 1.071, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02797, total_loss: 1.500
training 4812 (epoch 7): tem_loss: 1.071, pem class_loss: 0.288, pem reg_loss: 0.014, consistency_loss: 0.02796, total_loss: 1.500
training 4822 (epoch 7): tem_loss: 1.071, pem class_loss: 0.289, pem reg_loss: 0.014, consistency_loss: 0.02797, total_loss: 1.501
[94mBMN training loss(epoch 7): tem_loss: 1.071, pem class_loss: 0.288, pem reg_loss: 0.014, total_loss: 1.500[0m
[94mBMN val loss(epoch 7): tem_loss: 1.147, pem class_loss: 0.316, pem reg_loss: 0.015, total_loss: 1.614[0m
[94mBMN val_ema loss(epoch 7): tem_loss: 1.145, pem class_loss: 0.316, pem reg_loss: 0.015, total_loss: 1.612[0m
use Semi !!! use all label !!!
training 4825 (epoch 8): tem_loss: 0.951, pem class_loss: 0.271, pem reg_loss: 0.020, consistency_loss: 0.03180, total_loss: 1.426
training 4835 (epoch 8): tem_loss: 1.084, pem class_loss: 0.283, pem reg_loss: 0.015, consistency_loss: 0.02983, total_loss: 1.518
training 4845 (epoch 8): tem_loss: 1.062, pem class_loss: 0.271, pem reg_loss: 0.014, consistency_loss: 0.02833, total_loss: 1.475
training 4855 (epoch 8): tem_loss: 1.058, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02787, total_loss: 1.474
training 4865 (epoch 8): tem_loss: 1.053, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02807, total_loss: 1.468
training 4875 (epoch 8): tem_loss: 1.050, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02776, total_loss: 1.464
training 4885 (epoch 8): tem_loss: 1.043, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.02817, total_loss: 1.456
training 4895 (epoch 8): tem_loss: 1.052, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02820, total_loss: 1.472
training 4905 (epoch 8): tem_loss: 1.049, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02829, total_loss: 1.467
training 4915 (epoch 8): tem_loss: 1.051, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02842, total_loss: 1.468
training 4925 (epoch 8): tem_loss: 1.050, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02847, total_loss: 1.465
training 4935 (epoch 8): tem_loss: 1.048, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.02836, total_loss: 1.460
training 4945 (epoch 8): tem_loss: 1.048, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02843, total_loss: 1.462
training 4955 (epoch 8): tem_loss: 1.051, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02859, total_loss: 1.467
training 4965 (epoch 8): tem_loss: 1.053, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02863, total_loss: 1.468
training 4975 (epoch 8): tem_loss: 1.054, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02859, total_loss: 1.469
training 4985 (epoch 8): tem_loss: 1.052, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02861, total_loss: 1.467
training 4995 (epoch 8): tem_loss: 1.055, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02867, total_loss: 1.472
training 5005 (epoch 8): tem_loss: 1.055, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02861, total_loss: 1.470
training 5015 (epoch 8): tem_loss: 1.053, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02852, total_loss: 1.469
training 5025 (epoch 8): tem_loss: 1.055, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02853, total_loss: 1.474
training 5035 (epoch 8): tem_loss: 1.056, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02853, total_loss: 1.473
training 5045 (epoch 8): tem_loss: 1.055, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02862, total_loss: 1.471
training 5055 (epoch 8): tem_loss: 1.056, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02869, total_loss: 1.473
training 5065 (epoch 8): tem_loss: 1.056, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02873, total_loss: 1.472
training 5075 (epoch 8): tem_loss: 1.055, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02870, total_loss: 1.471
training 5085 (epoch 8): tem_loss: 1.055, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02880, total_loss: 1.470
training 5095 (epoch 8): tem_loss: 1.055, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02884, total_loss: 1.471
training 5105 (epoch 8): tem_loss: 1.055, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02891, total_loss: 1.471
training 5115 (epoch 8): tem_loss: 1.056, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02887, total_loss: 1.472
training 5125 (epoch 8): tem_loss: 1.058, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02890, total_loss: 1.474
training 5135 (epoch 8): tem_loss: 1.058, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02888, total_loss: 1.476
training 5145 (epoch 8): tem_loss: 1.058, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02883, total_loss: 1.475
training 5155 (epoch 8): tem_loss: 1.060, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02882, total_loss: 1.476
training 5165 (epoch 8): tem_loss: 1.061, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02879, total_loss: 1.476
training 5175 (epoch 8): tem_loss: 1.060, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.02883, total_loss: 1.475
training 5185 (epoch 8): tem_loss: 1.060, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02885, total_loss: 1.476
training 5195 (epoch 8): tem_loss: 1.060, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02884, total_loss: 1.476
training 5205 (epoch 8): tem_loss: 1.059, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.02881, total_loss: 1.474
training 5215 (epoch 8): tem_loss: 1.059, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02882, total_loss: 1.476
training 5225 (epoch 8): tem_loss: 1.059, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02885, total_loss: 1.477
training 5235 (epoch 8): tem_loss: 1.059, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02886, total_loss: 1.477
training 5245 (epoch 8): tem_loss: 1.061, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02886, total_loss: 1.480
training 5255 (epoch 8): tem_loss: 1.061, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02891, total_loss: 1.479
training 5265 (epoch 8): tem_loss: 1.061, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02890, total_loss: 1.478
training 5275 (epoch 8): tem_loss: 1.061, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02897, total_loss: 1.479
training 5285 (epoch 8): tem_loss: 1.060, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02901, total_loss: 1.477
training 5295 (epoch 8): tem_loss: 1.059, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02902, total_loss: 1.476
training 5305 (epoch 8): tem_loss: 1.058, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02905, total_loss: 1.474
training 5315 (epoch 8): tem_loss: 1.057, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02906, total_loss: 1.473
training 5325 (epoch 8): tem_loss: 1.057, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02907, total_loss: 1.473
training 5335 (epoch 8): tem_loss: 1.058, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02911, total_loss: 1.475
training 5345 (epoch 8): tem_loss: 1.060, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02908, total_loss: 1.476
training 5355 (epoch 8): tem_loss: 1.060, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02907, total_loss: 1.476
training 5365 (epoch 8): tem_loss: 1.061, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02910, total_loss: 1.477
training 5375 (epoch 8): tem_loss: 1.060, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02911, total_loss: 1.477
training 5385 (epoch 8): tem_loss: 1.059, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02911, total_loss: 1.476
training 5395 (epoch 8): tem_loss: 1.059, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.02915, total_loss: 1.476
training 5405 (epoch 8): tem_loss: 1.060, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02920, total_loss: 1.478
training 5415 (epoch 8): tem_loss: 1.060, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.02925, total_loss: 1.478
training 5425 (epoch 8): tem_loss: 1.060, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.02924, total_loss: 1.479
[94mBMN training loss(epoch 8): tem_loss: 1.060, pem class_loss: 0.282, pem reg_loss: 0.014, total_loss: 1.479[0m
[94mBMN val loss(epoch 8): tem_loss: 1.150, pem class_loss: 0.319, pem reg_loss: 0.015, total_loss: 1.621[0m
[94mBMN val_ema loss(epoch 8): tem_loss: 1.148, pem class_loss: 0.317, pem reg_loss: 0.015, total_loss: 1.616[0m
use Semi !!! use all label !!!
training 5428 (epoch 9): tem_loss: 1.259, pem class_loss: 0.476, pem reg_loss: 0.023, consistency_loss: 0.02888, total_loss: 1.962
training 5438 (epoch 9): tem_loss: 1.070, pem class_loss: 0.286, pem reg_loss: 0.013, consistency_loss: 0.02977, total_loss: 1.485
training 5448 (epoch 9): tem_loss: 1.069, pem class_loss: 0.296, pem reg_loss: 0.014, consistency_loss: 0.03042, total_loss: 1.506
training 5458 (epoch 9): tem_loss: 1.061, pem class_loss: 0.284, pem reg_loss: 0.013, consistency_loss: 0.02992, total_loss: 1.478
training 5468 (epoch 9): tem_loss: 1.063, pem class_loss: 0.278, pem reg_loss: 0.013, consistency_loss: 0.03000, total_loss: 1.472
training 5478 (epoch 9): tem_loss: 1.059, pem class_loss: 0.280, pem reg_loss: 0.013, consistency_loss: 0.03007, total_loss: 1.473
training 5488 (epoch 9): tem_loss: 1.061, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03013, total_loss: 1.473
training 5498 (epoch 9): tem_loss: 1.051, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.03002, total_loss: 1.462
training 5508 (epoch 9): tem_loss: 1.055, pem class_loss: 0.276, pem reg_loss: 0.013, consistency_loss: 0.03013, total_loss: 1.465
training 5518 (epoch 9): tem_loss: 1.049, pem class_loss: 0.275, pem reg_loss: 0.014, consistency_loss: 0.03046, total_loss: 1.460
training 5528 (epoch 9): tem_loss: 1.054, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03069, total_loss: 1.468
training 5538 (epoch 9): tem_loss: 1.057, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03078, total_loss: 1.472
training 5548 (epoch 9): tem_loss: 1.063, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03089, total_loss: 1.478
training 5558 (epoch 9): tem_loss: 1.065, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.03081, total_loss: 1.478
training 5568 (epoch 9): tem_loss: 1.064, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.03074, total_loss: 1.478
training 5578 (epoch 9): tem_loss: 1.062, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03069, total_loss: 1.478
training 5588 (epoch 9): tem_loss: 1.061, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03083, total_loss: 1.479
training 5598 (epoch 9): tem_loss: 1.061, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03081, total_loss: 1.477
training 5608 (epoch 9): tem_loss: 1.058, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03085, total_loss: 1.473
training 5618 (epoch 9): tem_loss: 1.060, pem class_loss: 0.276, pem reg_loss: 0.014, consistency_loss: 0.03089, total_loss: 1.475
training 5628 (epoch 9): tem_loss: 1.062, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03094, total_loss: 1.476
training 5638 (epoch 9): tem_loss: 1.063, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03092, total_loss: 1.479
training 5648 (epoch 9): tem_loss: 1.065, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03091, total_loss: 1.483
training 5658 (epoch 9): tem_loss: 1.068, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.03097, total_loss: 1.488
training 5668 (epoch 9): tem_loss: 1.069, pem class_loss: 0.282, pem reg_loss: 0.014, consistency_loss: 0.03090, total_loss: 1.490
training 5678 (epoch 9): tem_loss: 1.066, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03088, total_loss: 1.484
training 5688 (epoch 9): tem_loss: 1.065, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03091, total_loss: 1.483
training 5698 (epoch 9): tem_loss: 1.065, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03098, total_loss: 1.484
training 5708 (epoch 9): tem_loss: 1.064, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03095, total_loss: 1.483
training 5718 (epoch 9): tem_loss: 1.063, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03089, total_loss: 1.482
training 5728 (epoch 9): tem_loss: 1.063, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03087, total_loss: 1.482
training 5738 (epoch 9): tem_loss: 1.062, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.03079, total_loss: 1.481
training 5748 (epoch 9): tem_loss: 1.063, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.03081, total_loss: 1.483
training 5758 (epoch 9): tem_loss: 1.062, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03087, total_loss: 1.481
training 5768 (epoch 9): tem_loss: 1.063, pem class_loss: 0.281, pem reg_loss: 0.014, consistency_loss: 0.03090, total_loss: 1.483
training 5778 (epoch 9): tem_loss: 1.063, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03087, total_loss: 1.482
training 5788 (epoch 9): tem_loss: 1.062, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03081, total_loss: 1.480
training 5798 (epoch 9): tem_loss: 1.061, pem class_loss: 0.280, pem reg_loss: 0.014, consistency_loss: 0.03077, total_loss: 1.479
training 5808 (epoch 9): tem_loss: 1.061, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03077, total_loss: 1.478
training 5818 (epoch 9): tem_loss: 1.060, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03083, total_loss: 1.477
training 5828 (epoch 9): tem_loss: 1.058, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03087, total_loss: 1.475
training 5838 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03093, total_loss: 1.472
training 5848 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03087, total_loss: 1.472
training 5858 (epoch 9): tem_loss: 1.059, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03088, total_loss: 1.475
training 5868 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03090, total_loss: 1.472
training 5878 (epoch 9): tem_loss: 1.056, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03090, total_loss: 1.472
training 5888 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03093, total_loss: 1.473
training 5898 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03096, total_loss: 1.472
training 5908 (epoch 9): tem_loss: 1.058, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03100, total_loss: 1.474
training 5918 (epoch 9): tem_loss: 1.058, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03099, total_loss: 1.474
training 5928 (epoch 9): tem_loss: 1.058, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03103, total_loss: 1.474
training 5938 (epoch 9): tem_loss: 1.057, pem class_loss: 0.279, pem reg_loss: 0.014, consistency_loss: 0.03111, total_loss: 1.473
training 5948 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03118, total_loss: 1.471
training 5958 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03121, total_loss: 1.471
training 5968 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03125, total_loss: 1.471
training 5978 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03125, total_loss: 1.471
training 5988 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03128, total_loss: 1.471
training 5998 (epoch 9): tem_loss: 1.057, pem class_loss: 0.277, pem reg_loss: 0.014, consistency_loss: 0.03129, total_loss: 1.470
training 6008 (epoch 9): tem_loss: 1.057, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03132, total_loss: 1.471
training 6018 (epoch 9): tem_loss: 1.058, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03133, total_loss: 1.472
training 6028 (epoch 9): tem_loss: 1.058, pem class_loss: 0.278, pem reg_loss: 0.014, consistency_loss: 0.03134, total_loss: 1.472
[94mBMN training loss(epoch 9): tem_loss: 1.058, pem class_loss: 0.278, pem reg_loss: 0.014, total_loss: 1.473[0m
[94mBMN val loss(epoch 9): tem_loss: 1.149, pem class_loss: 0.318, pem reg_loss: 0.015, total_loss: 1.618[0m
[94mBMN val_ema loss(epoch 9): tem_loss: 1.150, pem class_loss: 0.319, pem reg_loss: 0.015, total_loss: 1.619[0m
unlabel percent:  0.0
eval student model !!
load : ./checkpoint/Semi-base-0.0/BMN_checkpoint.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472605
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.4719662690251%
AR@1 is 	 0.33695324283559575
AR@5 is 	 0.496201837378308
AR@10 is 	 0.5697655285890579
AR@100 is 	 0.7541066776360894
load : ./checkpoint/Semi-base-0.0/BMN_best.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472616
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.58977786918963%
AR@1 is 	 0.33585630056218296
AR@5 is 	 0.49762786233374473
AR@10 is 	 0.5695735636912108
AR@100 is 	 0.7561360208419032
eval teacher model !!
load : ./checkpoint/Semi-base-0.0/BMN_checkpoint_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472605
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.61198409433703%
AR@1 is 	 0.33706293706293705
AR@5 is 	 0.4976964212258331
AR@10 is 	 0.5716166186754422
AR@100 is 	 0.7556286850404497
load : ./checkpoint/Semi-base-0.0/BMN_best_ema.pth.tar  OK !
validation subset video numbers: 4728
Post processing start
Post processing finished
[INIT] Loaded annotations from validation subset.
	Number of ground truth instances: 7293
	Number of proposals: 472616
	Fixed threshold for tiou score: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]
[RESULTS] Performance on ActivityNet proposal task.
	Area Under the AR vs AN curve: 67.29064856711915%
AR@1 is 	 0.334882764294529
AR@5 is 	 0.4905662964486493
AR@10 is 	 0.5665569724393253
AR@100 is 	 0.75246126422597
#
